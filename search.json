[{"title":"Hexo+NexT搭建个人博客","url":"/%E6%8A%80%E6%9C%AF%E6%95%99%E7%A8%8B/Hexo/Hexo+NexT%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/","content":"概述什么是 Hexo？Hexo 是一个快速、简洁且高效的博客框架。Hexo 使用 Markdown（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。\n准备环境NodeJs安装从官网https://nodejs.org/en/ 下载，直接安装即可，测试一下\nnode -v# v11.15.0npm -v# 6.7.0\n\n\nnpm修改源获取npm源\nnpm get registry\n\n\n\n修改npm源\nnpm config set registry http://registry.npm.taobao.org/\n\n\n\n如果想重置回去\nnpm config set registry https://registry.npmjs.org/\n\n\n\n安装Git从官网https://git-scm.com/download/win 下载，直接安装即可\n设置邮箱和用户名\ngit config --global user.name  ****\t\t\t# 设置用户名（gitee的注册昵称）git config --global user.email *****@**.com\t # 设置gitee邮箱（gitee的注册邮箱）\n\n\n\n安装hexonpm install -g hexo-cli\n\n\n\n\n\n建站部署安装 Hexo 完成后，请执行下列命令，Hexo 将会在指定文件夹中新建所需要的文件。\n# 初始化博客文件夹hexo init &lt;folder&gt;# 进入博客目录cd &lt;folder&gt;# 安装npm install\n\n新建完成后，指定文件夹的目录如下：\n.├── _config.yml├── package.json├── scaffolds├── source|   ├── _drafts|   └── _posts└── themes\n\n这样hexo就安装完成了，接下来就可以启动hexo了\nhexo clean\t\t    # 清除所有记录hexo generate\t\t# 生成静态网页hexo server -p 80\t# 启动服务\n\n\n\n本地预览# 清除所有记录hexo clean# 编译项目，输入命令：hexo g# 运行项目，输入命令：hexo s\n\n在浏览器地址栏输入 http://localhost:4000/ 就能看到效果啦\n部署到Gitee安装插件npm install hexo-deployer-git --save \n\n\n\n修改站点配置文件# URLurl: https://gitee.com/valten/blogroot: /blog/# Deployment## Docs: https://hexo.io/docs/deployment.htmldeploy:  type: git  repo: git@gitee.com:valten/blog.git  branch: develop\n\n部署hexo clean &amp;&amp; hexo g &amp;&amp; hexo d\n\n进入gitee仓库，找到服务，选择Gitee Pages\n\n选择部署分支，我这里是develop分支，然后点击更新即可\n\n测试浏览器地址输入 https://gitee.com/valten/blog\n部署到Gihub安装插件npm install hexo-deployer-git --save \n\n修改站点配置文件# URLurl: https://valtenhyl.github.ioroot: /# Deployment## Docs: https://hexo.io/docs/deployment.htmldeploy:  type: git  repo: git@github.com:valten-hyl/valtenhyl.github.io.git  branch: deploy\n\n部署hexo clean &amp;&amp; hexo g &amp;&amp; hexo d\n\n进入github仓库，找到项目，选择Settings，选择Pages，Source选择部署的时候的分支，点击Save按钮保存即可\n\n测试浏览器地址输入 https://valtenhyl.github.io\n最后我还是选择了Gitee。\n为什么使用Gitee而不使用GitHub\n\n1、GitHub Pages访问龟速不稳定；\n2、GitHub私有仓库收费，而Gitee私有仓库免费；\n\n配置优化分类和标签定义分类页hexo new page categories\n\n\n\n---title: 分类date: 2019-12-14 10:56:27type: &quot;categories&quot;---\n\n\n\n定义分类页hexo new page tags\n\n\n\n---title: 标签date: 2019-12-14 10:56:27type: &quot;tags&quot;---\n\n\n\n文章添加分类和标签属性---title: SpringBoot+Mybatis 通过databaseIdProvider支持多数据库date: 2019-12-14 16:42:51tags:  - Spring Boot  - Mybatis  - databaseIdProvider  - 多数据库categories:  - [Java,Spring Boot]  # 多级标签  - Mybatis---\n\n\n\n修改主题配置文件，显示分类和标签菜单\n# External url should start with http:// or https://menu:  home: / || home  categories: /categories/ || th  tags: /tags/ || tags  archives: /archives/ || archive  #about: /about/ || user  #schedule: /schedule/ || calendar  #sitemap: /sitemap.xml || sitemap  #commonweal: /404/ || heartbeat\n\n\n\n\n\n关于hexo new page about\n\n修改主题配置文件，显示关于\n# External url should start with http:// or https://menu:  home: / || home  categories: /categories/ || th  tags: /tags/ || tags  archives: /archives/ || archive  about: /about/ || user  #schedule: /schedule/ || calendar  #sitemap: /sitemap.xml || sitemap  #commonweal: /404/ || heartbeat\n\n编辑about目录下的index.md。\n公益404hexo new page commonweal\n\n修改主题配置文件，#commonweal: /404/ || heartbeat改成commonweal: /404.html || heartbeat。\n# External url should start with http:// or https://menu:  home: / || home  categories: /categories/ || th  tags: /tags/ || tags  archives: /archives/ || archive  about: /about/ || user  #schedule: /schedule/ || calendar  #sitemap: /sitemap.xml || sitemap  commonweal: /404.html || heartbeat\n\n附上index.md\n---title: 404 Not Found：该页无法显示date: 2019-12-14 17:40:17permalink: /404---&lt;!DOCTYPE html&gt;&lt;html lang=&quot;zh-cn&quot;&gt;&lt;head&gt;&lt;meta charset=&quot;UTF-8&quot; /&gt;&lt;title&gt;404&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;script type=&quot;text/javascript&quot;         src=&quot;//qzonestyle.gtimg.cn/qzone/hybrid/app/404/search_children.js&quot; \t    homePageName=&quot;返回宝贝回家&quot; homePageUrl=&quot;https://valten.gitee.io/blog&quot;&gt;&lt;/script&gt;&lt;/body&gt;&lt;/html&gt;\n\n\n\n\n\n阅读全文按钮在文章中想要预览的文字后加&lt;!--more--&gt;，这在之后的内容就会隐藏起来，点击Read More就会显示全文。\n添加图片---title: Hello Worldtags: - Hello  - Worldcategories: - Hello photos:     - &quot;http://q2gep6iwb.bkt.clouddn.com/blog/20191213/7Jk7p7nSUWpC.jpg&quot; ---\n\n\n\n\n\n文章置顶移除默认安装的插件：\nnpm uninstall hexo-generator-index --save\n\n安装新插件:\nnpm install hexo-generator-index-pin-top --save\n\n最后编辑有这需求的相关文章时，在Front-matter（文件最上方以—分隔的区域）加上一行：top: true如果你置顶了多篇，怎么控制顺序呢？设置top的值（大的在前面），比如：\n# Post a.mdtitle: atop: 1# Post b.mdtitle: btop: 10\n\n 文章 b 便会显示在文章 a 的前面。 \n添加萌宠看板娘安装插件\nnpm install hexo-helper-live2d --save\n\n安装想要的模型\nnpm install live2d-widget-model-shizuku --save\n\n站点配置文件添加以下配置\n# Live2D## https://github.com/EYHN/hexo-helper-live2dlive2d:  enable: true # 开启live2d  scriptFrom: local # 默认  pluginRootPath: live2dw/ # 插件在站点上的根目录(相对路径)  pluginJsPath: lib/ # 脚本文件相对与插件根目录路径  pluginModelPath: assets/ # 模型文件相对与插件根目录路径  tagMode: false # 标签模式, 是否仅替换 live2d tag标签而非插入到所有页面中  debug: false # 调试, 是否在控制台输出日志  model:    # 选择哪种模型 https://huaji8.top/post/live2d-plugin-2.0/    # shizuku、wanko、hibiki、z16、haru、Epsilon2.1、koharu、haruto、       # npm install live2d-widget-model-wanko --save    use: live2d-widget-model-shizuku  display: #放置位置和大小    position: left    width: 150    height: 300  mobile:    show: false # 是否在手机端显示\n\n\n\n\n\n修改站点基本信息# Sitetitle: 青衫不改  # 标题subtitle: 小白の博客  # 副标题description: 浮生若梦，为欢几何  # 描述keywords: &#x27;Hexo, NexT&#x27;  # 网站默认关键词author: valtenlanguage: entimezone: &#x27;&#x27;\n\n\n\n\n\n文章永久链接修改站点配置文件\n#permalink: :year/:month/:day/:title/permalink: :category/:title/\n\n\n\n\n\n更换主题# 下载主题git clone https://github.com/theme-next/hexo-theme-next.git themes/next\n\n修改站点配置文件\n# Extensions## Plugins: https://hexo.io/plugins/## Themes: https://hexo.io/themes/theme: next # 值为themes目录下主题文件夹的名称\n\n查看效果\nhexo clean &amp;&amp; hexo g &amp;&amp; hexo s\n\n\n\n\n\n社交链接social:  GitHub: https://github.com/valten-hyl || github  E-Mail: mailto:valtenhyl@163.com || envelope  Weibo: https://weibo.com/3114281855 || weibo  简书: https://www.jianshu.com/u/9f816d1869d4 || book  掘金: https://juejin.im/user/5baa5f9d5188255c5d569951 || ils  #Google: https://plus.google.com/yourname || google  #Twitter: https://twitter.com/yourname || twitter  #FB Page: https://www.facebook.com/yourname || facebook  #StackOverflow: https://stackoverflow.com/yourname || stack-overflow  #YouTube: https://youtube.com/yourname || youtube  #Instagram: https://instagram.com/yourname || instagram  #Skype: skype:yourname?call|chat || skype  #RSS: /atom.xml || rss  social_icons:  enable: true       # 是否在社交链接标签上显示图标  icons_only: true   # 只显示图标  transition: false  # 是否显示过渡效果  \n\n\n\n\n\n友情链接# Blog rollslinks_settings:  icon: link                           # 链接图标  title: 友情链接                       # 链接文字  # Available values: block | inline  layout: inline                       # 链接样式links:  圣豪Boy: https://xshcloudy.gitee.io/blog/  BootCDN: https://www.bootcdn.cn/  易百教程: https://www.yiibai.com/\n\n\n\n\n\n代码高亮codeblock:  # Code Highlight theme  # Available values: normal | night | night eighties | night blue | night bright | solarized | solarized dark | galactic  # See: https://github.com/chriskempson/tomorrow-theme  highlight_theme: night  # Add copy button on codeblock  copy_button:    enable: true    # Show text copy result.    show_result: true    # Available values: default | flat | mac    style: default\n\n\n\n\n\n图片浏览放大cd themes/next/source/libgit clone https://github.com/theme-next/theme-next-fancybox3 fancybox\n\n修改主题配置文件\n# FancyBox is a tool that offers a nice and elegant way to add zooming functionality for images.# For more information: https://fancyapps.com/fancyboxfancybox: true\n\n\n\n\n\n站点访问统计# Show Views / Visitors of the website / page with busuanzi.# Get more information on http://ibruce.info/2015/04/04/busuanzibusuanzi_count: # 不蒜子统计，用于在页脚显示总访客数和总浏览量  enable: true  total_visitors: true  total_visitors_icon: user  total_views: true  total_views_icon: eye  post_views: true  post_views_icon: eye\n\n\n\n\n\n评论系统 Valine 诞生于2017年8月7日，是一款基于Leancloud的快速、简洁且高效的无后端评论系统。 \n 登录 Leancloud 官网，注册之后创建一个应用 ，【设置】-&gt;【应用Keys】，根据显示的内容修改主题配置文件\n# Valine# For more information: https://valine.js.org, https://github.com/xCss/Valinevaline: # 评论  enable: true  appid: jflkasjdklfjlajsdlkfklsd-sdfasdf # Your leancloud application appid  appkey: ahskfdhlkasdkfjkalsdflasdf # Your leancloud application appkey  notify: true # 评论回复邮件提醒, See: https://github.com/xCss/Valine/wiki  verify: false # 验证码服务 Verification code  placeholder: 留言区 # 留言区 Comment box placeholder  avatar: mm # 头像配置 Gravatar style  guest_info: nick,mail,link # 回复填写的信息 Custom comment header  pageSize: 10 # Pagination size  language: # Language, available values: en, zh-cn  visitor: false # Article reading statistic  comment_count: true # If false, comment count will only be displayed in post page, not in home page  recordIP: false # Whether to record the commenter IP  serverURLs: # When the custom domain name is enabled, fill it in here (it will be detected automatically by default, no need to fill in)  #post_meta_order: 0\n\n\n\n\n\n本地搜索npm install hexo-generator-searchdb --save\n\n修改站点配置文件\n# 本地搜索search:  path: search.xml  field: post  format: html  limit: 10000  \n\n修改主题配置文件，开启本地搜索\n# Local Search# Dependencies: https://github.com/theme-next/hexo-generator-searchdblocal_search:  enable: true\n\n\n\n\n\n文字数量和阅读时长npm install hexo-symbols-count-time --save\n\n修改主题配置文件\n# Post wordcount display settings# Dependencies: https://github.com/theme-next/hexo-symbols-count-timesymbols_count_time:  separated_meta: true  item_text_post: true  item_text_total: true  awl: 4  wpm: 275\n\n\n\n\n\n开启RRS订阅npm install hexo-generator-feed --save\n\n站点配置文件添加以下配置\n# RSS订阅feed:  type: atom  path: atom.xml  limit: 20  hub:  content:  content_limit: 140  content_limit_delim: &#x27; &#x27;\n\n主题配置文件\n# Social Links# Usage: `Key: permalink || icon`# Key is the link label showing to end users.# Value before `||` delimiter is the target permalink, value after `||` delimiter is the name of Font Awesome icon.social:  GitHub: https://github.com/valten-hyl || github  E-Mail: mailto:valtenhyl@163.com || envelope  Weibo: https://weibo.com/3114281855 || weibo  简书: https://www.jianshu.com/u/9f816d1869d4 || book  掘金: https://juejin.im/user/5baa5f9d5188255c5d569951 || ils  #Google: https://plus.google.com/yourname || google  #Twitter: https://twitter.com/yourname || twitter  #FB Page: https://www.facebook.com/yourname || facebook  #StackOverflow: https://stackoverflow.com/yourname || stack-overflow  #YouTube: https://youtube.com/yourname || youtube  #Instagram: https://instagram.com/yourname || instagram  #Skype: skype:yourname?call|chat || skype  RSS: /atom.xml || rss\n\n\n\n\n\n标签云配色# TagCloud settings for tags page.tagcloud:  # All values below are same as default, change them by yourself.  min: 12 # Minimun font size in px  max: 31 # Maxium font size in px  start: &quot;#381096&quot; # Start color (hex, rgba, hsla or color keywords)  end: &quot;#922a4b&quot; # End color (hex, rgba, hsla or color keywords)  amount: 200 # Amount of tags, change it if you have more than 200 tags\n\n\n\n\n\n禁止页面评论在不需要评论的页面或者文章Front-matter（文件最上方以—分隔的区域）加上comments: false\n---title: categoriesdate: 2019-12-14 17:22:21type: &quot;categories&quot;comments: false---\n\n\n\n\n\nAddThis分享首先在AddThis官网注册账号，选择并配置分享按钮，激活，获取pubid，修改主题配置文件\n# AddThis Share. See: https://www.addthis.com# Go to https://www.addthis.com/dashboard to customize your tools.add_this_id: ra-2341234445555\n\n\n\n\n\nFork me on GitHub修改主题配置文件\n# `Follow me on GitHub` banner in the top-right corner.github_banner:  enable: true  permalink: https://github.com/valten-hyl  title: Follow me on GitHub\n\n\n\n\n\n隐藏强力驱动和主题信息powered:  # Hexo link (Powered by Hexo).  enable: false  # Version info of Hexo after Hexo link (vX.X.X).  version: falsetheme:  # Theme &amp; scheme info link (Theme - NexT.scheme).  enable: false  # Version info of NexT after scheme info (vX.X.X).  version: false\n\n\n\n在线聊天 首先到DaoVoice上注册一个账号,注册完成后会得到一个app_id，修改主题配置文件\n# DaoVoice# Online contactdaovoice: truedaovoice_app_id: 123sfa # 这里填你刚才获得的 app_id\n\n打开themes/next/layout/_partials/head/head.swig，在文件中添加\n&#123;% if theme.daovoice %&#125;  &lt;script&gt;  (function(i,s,o,g,r,a,m)&#123;i[&quot;DaoVoiceObject&quot;]=r;i[r]=i[r]||function()&#123;(i[r].q=i[r].q||[]).push(arguments)&#125;,i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;a.charset=&quot;utf-8&quot;;m.parentNode.insertBefore(a,m)&#125;)(window,document,&quot;script&quot;,(&#x27;https:&#x27; == document.location.protocol ? &#x27;https:&#x27; : &#x27;http:&#x27;) + &quot;//widget.daovoice.io/widget/e30c3408.js&quot;,&quot;daovoice&quot;)  daovoice(&#x27;init&#x27;, &#123;      app_id: &quot;&#123;&#123; theme.daovoice_app_id &#125;&#125;&quot;    &#125;);  daovoice(&#x27;update&#x27;);  &lt;/script&gt;&#123;% endif %&#125;\n\n\n\n嵌入歌单新建歌单页面---title: palylistdate: 2019-12-15 01:04:41type: &quot;playlist&quot;comments: false---\n\n安装播放器npm install hexo-tag-aplayer --save\n\n修改站点配置文件其中id是歌单生成的外链的id\n# metingjsmetingjs:  server: netease  id: 3111577471 # 歌单id 8537501  type: playlist  theme: &#x27;#2980b9&#x27;  loop: all  autoplay: false  order: random   \n\n修改模板打开themes/next/layout/page.swig，在文件中加入以下代码\n&#123;% elif page.type === &#x27;playlist&#x27; %&#125;          &#123;&#123; page.content &#125;&#125;           &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css&quot;&gt;            &lt;script src=&quot;https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js&quot;&gt;&lt;/script&gt;            &lt;!-- require MetingJS --&gt;            &lt;script src=&quot;https://cdn.jsdelivr.net/npm/meting@2/dist/Meting.min.js&quot;&gt;&lt;/script&gt;            &lt;meting-js style=&quot;margin-top: 1.5rem; width: auto; height: auto;&quot; server=&quot;&#123;&#123; config.metingjs.server &#125;&#125;&quot; type=&quot;&#123;&#123; config.metingjs.type &#125;&#125;&quot; id=&quot;&#123;&#123; config.metingjs.id &#125;&#125;&quot; theme=&quot;&#123;&#123; config.metingjs.theme &#125;&#125;&quot; loop=&quot;&#123;&#123; config.metingjs.loop &#125;&#125;&quot; autoplay=&quot;&#123;&#123; config.metingjs.autoplay &#125;&#125;&quot; order=&quot;&#123;&#123; config.metingjs.order &#125;&#125;&quot; storageName=&quot;aplayer-setting&quot; lrctype=0 /&gt;&#123;% elif page.type === &#x27;schedule&#x27; %&#125;\n\n\n\n动态标签云安装插件npm install hexo-tag-cloud --save\n\n修改站点配置文件# hexo-tag-cloudtag_cloud:  textFont: Trebuchet MS, Helvetica  textColor: &#x27;#192e4d&#x27;  textHeight: 25  outlineColor: &#x27;#5f7a74&#x27;  maxSpeed: 0.5 # [0.01, 1]   \n\n修改页面模板打开themes/next/layout/page.swig，找到class=&quot;tag-cloud&quot;，在里面添加以下代码\n# hexo-tag-cloudtag_cloud:  textFont: Trebuchet MS, Helvetica  textColor: &#x27;#192e4d&#x27;  textHeight: 25  outlineColor: &#x27;#5f7a74&#x27;  maxSpeed: 0.5 # [0.01, 1]   \n\n\n\n\n\n添加背景图片打开themes/next/source/css/_common/scaffolding/base.styl\nbody &#123;  background: $body-bg-color;  color: $text-color;  font-family: $font-family-base;  font-size: $font-size-base;  line-height: $line-height-base;  // 背景图片  background: url(http://q2gep6iwb.bkt.clouddn.com/blog/20191215/s6j9RkCgHaW4.jpg);  background-size: cover;  background-repeat: no-repeat;  background-attachment: fixed;  background-position: 50% 50%;  +tablet-mobile() &#123;    // Remove the padding of body when the sidebar is open.    padding-left: 0 !important;    padding-right: 0 !important;  &#125;&#125;// 修改主体透明度.main-inner &#123;  background: #0a1627;  opacity: 0.9;&#125;// 修改菜单栏透明度.header-inner &#123;  opacity: 0.8;&#125;\n\n\n\n\n\n动态背景cd themes/nextgit clone https://github.com/theme-next/theme-next-canvas-nest source/lib/canvas-nest\n\n修改主题配置文件\n# Canvas-nest# Dependencies: https://github.com/theme-next/theme-next-canvas-nest# For more information: https://github.com/hustcc/canvas-nest.jscanvas_nest:  enable: true  onmobile: true # Display on mobile or not  color: &quot;0,0,255&quot; # RGB values, use `,` to separate  opacity: 0.5 # The opacity of line: 0~1  zIndex: -1 # z-index property of the background  count: 99 # The number of lines\n\n\n\n\n\n加载进度条修改主题配置文件，开启进度条，选择进度条样式\n# Progress bar in the top during page loading.# Dependencies: https://github.com/theme-next/theme-next-pace# For more information: https://github.com/HubSpot/pacepace:  enable: true  # Themes list:  # big-counter | bounce | barber-shop | center-atom | center-circle | center-radar | center-simple  # corner-indicator | fill-left | flat-top | flash | loading-bar | mac-osx | material | minimal  theme: pace-theme-bounce #选择进度条样式\n\n修改主题配置文件，引入对应的js和css\nvendors:  pace: //cdn.bootcss.com/pace/1.0.2/pace.min.js  pace_css: //cdn.bootcss.com/pace/1.0.2/themes/black/pace-theme-bounce.min.css\n\n\n\n\n\n\n\n回到顶部样式修改主题配置文件，开启回到顶部\nback2top:  enable: true  # Back to top in sidebar.  sidebar: false  # Scroll percent label in b2t button.  scrollpercent: false  # 钢铁侠  ironman: true\n\n在themes/next/source/js下新建totop.js\n$(window).scroll(function() &#123;    $(window).scrollTop() &gt; $(window).height()*0.5 ? $(&quot;#rocket&quot;).addClass(&quot;show&quot;) : $(&quot;#rocket&quot;).removeClass(&quot;show&quot;);&#125;);$(&quot;#rocket&quot;).click(function() &#123;    $(&quot;#rocket&quot;).addClass(&quot;launch&quot;);    $(&quot;html, body&quot;).animate(&#123;        scrollTop: 0    &#125;, 1000, function() &#123;        $(&quot;#rocket&quot;).removeClass(&quot;show launch&quot;);    &#125;);    return false;&#125;);\n\n修改themes/next/layout/_partials/wigets.swig\n&#123;%- if theme.back2top.enable and not theme.back2top.sidebar %&#125;   &#123;%- if theme.back2top.ironman %&#125;     &lt;span id=&quot;rocket&quot; href=&quot;#top&quot; class=&quot;&quot;&gt;&lt;/span&gt;     &lt;script src=&quot;https://cdn.bootcss.com/jquery/3.4.1/jquery.min.js&quot;&gt;&lt;/script&gt;     &#123;&#123;- next_js(&#x27;totop.js&#x27;) &#125;&#125;   &#123;%- else %&#125;      &lt;div class=&quot;back-to-top motion-element&quot;&gt;       &lt;i class=&quot;fa fa-arrow-up&quot;&gt;&lt;/i&gt;       &lt;span&gt;0%&lt;/span&gt;     &lt;/div&gt;      &#123;%- endif %&#125; &#123;%- endif %&#125;\n\n修改themes/next/source/css/common/scaffolding下的base.styl\n// 钢铁侠#rocket &#123;  position: fixed;  right: 50px;  bottom: 50px;  z-index: 3;  display: block;  visibility: hidden;  width: 42px;  height: 43px;  background: url(&quot;https://s2.ax1x.com/2019/12/16/Q51U0O.png&quot;) no-repeat 50% 0;  opacity: 0;  cursor: pointer;  -webkit-transition: visibility 0.6s cubic-bezier(0.6, 0.04, 0.98, 0.335), opacity 0.6s cubic-bezier(0.6, 0.04, 0.98, 0.335), -webkit-transform 0.6s cubic-bezier(0.6, 0.04, 0.98, 0.335);  -moz-transition: visibility 0.6s cubic-bezier(0.6, 0.04, 0.98, 0.335), opacity 0.6s cubic-bezier(0.6, 0.04, 0.98, 0.335), -moz-transform 0.6s cubic-bezier(0.6, 0.04, 0.98, 0.335);  transition: visibility 0.6s cubic-bezier(0.6, 0.04, 0.98, 0.335), opacity 0.6s cubic-bezier(0.6, 0.04, 0.98, 0.335), transform 0.6s cubic-bezier(0.6, 0.04, 0.98, 0.335);&#125;#rocket i &#123;  display: block;  margin-top: 48px;  height: 14px;  background: url(&quot;https://s2.ax1x.com/2019/12/16/Q51U0O.png&quot;) no-repeat 50% -20px;  opacity: .5;  -webkit-transition: -webkit-transform .2s;  -moz-transition: -moz-transform .2s;  transition: transform .2s;  -webkit-transform-origin: 50% 0;  -moz-transform-origin: 50% 0;  transform-origin: 50% 0;&#125;#rocket:hover &#123;  background-position: 50% -44px;&#125;#rocket:hover i &#123;  background-position: 50% 100%;  -webkit-animation: flaming .7s infinite;  -moz-animation: flaming .7s infinite;  animation: flaming .7s infinite;&#125;#rocket.show &#123;    visibility: visible;    opacity: 1;&#125;#rocket.launch &#123;  background-position: 50% -44px;  opacity: 0;  -webkit-transform: translateY(-500px);  -moz-transform: translateY(-500px);  -ms-transform: translateY(-500px);  transform: translateY(-500px);  pointer-events: none;&#125;#rocket.launch i &#123;  background-position: 50% 100%;  -webkit-transform: scale(1.4, 3.2);  -moz-transform: scale(1.4, 3.2);  transform: scale(1.4, 3.2);&#125; \n\n\n\n\n\n\n\n命令常用命令：hexo new &quot;postName&quot;      # 新建文章hexo new page &quot;pageName&quot; # 新建页面hexo generate            # 生成静态页面至public目录hexo server              # 开启预览访问端口（默认端口4000，&#x27;ctrl + c&#x27;关闭server）hexo deploy              # 将.deploy目录部署到GitHub\n\n\n\n常用复合命令：hexo d -ghexo s -ghexo clean &amp;&amp; hexo g &amp;&amp; hexo shexo clean &amp;&amp; hexo g &amp;&amp; hexo d\n\n\n\n简写：hexo n == hexo newhexo g == hexo generatehexo s == hexo serverhexo d == hexo deploy\n\n博客地址：http://valten.gitee.io/blog\n参考：\nhttps://www.jianshu.com/p/6f77c96b7effhttps://blog.csdn.net/u012294515/article/details/83094693https://blog.csdn.net/loze/article/details/94206726https://github.com/huweihuang/huweihuang.github.io\n","categories":["技术教程","Hexo"],"tags":["Hexo","NexT"]},{"title":"docsify搭建个人博客","url":"/%E6%8A%80%E6%9C%AF%E6%95%99%E7%A8%8B/docsify/docsify%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/","content":"快速开始推荐全局安装 docsify-cli 工具，可以方便地创建及在本地预览生成的文档。\nnpm i docsify-cli -g\n\n\n\n初始化项目如果想在项目的 ./docs 目录里写文档，直接通过 init 初始化项目。\ndocsify init ./docs\n\n\n\n开始写文档初始化成功后，可以看到 ./docs 目录下创建的几个文件\n\nindex.html 入口文件\nREADME.md 会做为主页内容渲染\n.nojekyll 用于阻止 GitHub Pages 忽略掉下划线开头的文件\n\n直接编辑 docs/README.md 就能更新文档内容，当然也可以添加更多页面。\n本地预览通过运行 docsify serve 启动一个本地服务器，可以实时预览效果。默认访问地址 http://localhost:3000 。\ndocsify serve docs\n\n\n\n\n\n部署和 GitBook 生成的文档一样，我们可以直接把文档网站部署到 GitHub Pages 或者 VPS 上。\nGitHub PagesGitHub Pages 支持从三个地方读取文件\n\ndocs/ 目录\nmaster 分支\ngh-pages 分支\n\n我们推荐直接将文档放在 docs/ 目录下，在设置页面开启 GitHub Pages 功能并选择 master branch /docs folder 选项。\n\n可以将文档放在根目录下，然后选择 master 分支 作为文档目录。你需要在部署位置下放一个 .nojekyll 文件（比如 /docs 目录或者 gh-pages 分支）\nGitee Pages在对应的 Gitee 仓库服务中选择 Gitee Pages，选择您要部署的分支，填写您要部署的分支上的目录，例如docs，填写完成之后点击启动即可。\n定制化Loading 提示初始化时会显示 Loading... 内容，你可以自定义提示信息。\n&lt;!-- index.html --&gt;&lt;div id=&quot;app&quot;&gt;加载中&lt;/div&gt;\n\n\n\n封面通过设置 coverpage 参数，可以开启渲染封面的功能。具体用法见配置项#coverpage。\n基本用法封面的生成同样是从 markdown 文件渲染来的。开启渲染封面功能后在文档根目录创建 _coverpage.md 文件。渲染效果如本文档。\nindex.html\n&lt;!-- index.html --&gt;&lt;script&gt;  window.$docsify = &#123;    coverpage: true  &#125;&lt;/script&gt;&lt;script src=&quot;//cdn.jsdelivr.net/npm/docsify/lib/docsify.min.js&quot;&gt;&lt;/script&gt;&lt;!-- _coverpage.md --&gt;![logo](_media/icon.svg)# docsify &lt;small&gt;3.5&lt;/small&gt;&gt; 一个神奇的文档网站生成器。- 简单、轻便 (压缩后 ~21kB)- 无需生成 html 文件- 众多主题[GitHub](https://github.com/docsifyjs/docsify/)[Get Started](#docsify)\n\n\n\n自定义背景目前的背景是随机生成的渐变色，我们自定义背景色或者背景图。在文档末尾用添加图片的 Markdown 语法设置背景。\n_coverpage.md&lt;!-- _coverpage.md --&gt;# docsify &lt;small&gt;3.5&lt;/small&gt;[GitHub](https://github.com/docsifyjs/docsify/)[Get Started](#quick-start)&lt;!-- 背景图片 --&gt;![](_media/bg.png)&lt;!-- 背景色 --&gt;![color](#f0f0f0)\n\n\n\n定制侧边栏为了获得侧边栏，您需要创建自己的_sidebar.md，你也可以自定义加载的文件名。默认情况下侧边栏会通过 Markdown 文件自动生成，效果如当前的文档的侧边栏。\n首先配置 loadSidebar 选项，具体配置规则见配置项#loadSidebar。\n&lt;!-- index.html --&gt;&lt;script&gt;  window.$docsify = &#123;    loadSidebar: true  &#125;&lt;/script&gt;&lt;script src=&quot;//cdn.jsdelivr.net/npm/docsify/lib/docsify.min.js&quot;&gt;&lt;/script&gt;\n\n接着创建 _sidebar.md 文件，内容如下\n&lt;!-- docs/_sidebar.md --&gt;* [首页](zh-cn/)* [指南](zh-cn/guide)\n\n需要在 ./docs 目录创建 .nojekyll 命名的空文件，阻止 GitHub Pages 忽略命名是下划线开头的文件。\n侧边栏标题一个页面的 title 标签是由侧边栏中选中条目的名称所生成的。为了更好的 SEO ，你可以在文件名后面指定页面标题。\n&lt;!-- docs/_sidebar.md --&gt;* [Home](/)* [Guide](guide.md &quot;The greatest guide in the world&quot;)\n\n\n\n显示目录自定义侧边栏同时也可以开启目录功能。设置 subMaxLevel 配置项，具体介绍见 配置项#subMaxLevel。\n&lt;!-- index.html --&gt;&lt;script&gt;  window.$docsify = &#123;    loadSidebar: true,    subMaxLevel: 2  &#125;&lt;/script&gt;&lt;script src=&quot;//cdn.jsdelivr.net/npm/docsify/lib/docsify.min.js&quot;&gt;&lt;/script&gt;\n\n\n\n全文搜索全文搜索插件会根据当前页面上的超链接获取文档内容，在 localStorage 内建立文档索引。默认过期时间为一天，当然我们可以自己指定需要缓存的文件列表或者配置过期时间。\n&lt;script&gt;  window.$docsify = &#123;    search: &#x27;auto&#x27;, // 默认值    search : [      &#x27;/&#x27;,            // =&gt; /README.md      &#x27;/guide&#x27;,       // =&gt; /guide.md      &#x27;/get-started&#x27;, // =&gt; /get-started.md      &#x27;/zh-cn/&#x27;,      // =&gt; /zh-cn/README.md    ],    // 完整配置参数    search: &#123;      maxAge: 86400000, // 过期时间，单位毫秒，默认一天      paths: [], // or &#x27;auto&#x27;      placeholder: &#x27;Type to search&#x27;,      // 支持本地化      placeholder: &#123;        &#x27;/zh-cn/&#x27;: &#x27;搜索&#x27;,        &#x27;/&#x27;: &#x27;Type to search&#x27;      &#125;,      noData: &#x27;No Results!&#x27;,      // 支持本地化      noData: &#123;        &#x27;/zh-cn/&#x27;: &#x27;找不到结果&#x27;,        &#x27;/&#x27;: &#x27;No Results&#x27;      &#125;,      // 搜索标题的最大层级, 1 - 6      depth: 2,      hideOtherSidebarContent: false, // 是否隐藏其他侧边栏内容      // 避免搜索索引冲突      // 同一域下的多个网站之间      namespace: &#x27;website-1&#x27;,      // 使用不同的索引作为路径前缀（namespaces）      // 注意：仅适用于 paths: &#x27;auto&#x27; 模式      //      // 初始化索引时，我们从侧边栏查找第一个路径      // 如果它与列表中的前缀匹配，我们将切换到相应的索引      pathNamespaces: [&#x27;/zh-cn&#x27;, &#x27;/ru-ru&#x27;, &#x27;/ru-ru/v1&#x27;],      // 您可以提供一个正则表达式来匹配前缀。在这种情况下，      // 匹配到的字符串将被用来识别索引      pathNamespaces: /^(\\/(zh-cn|ru-ru))?(\\/(v1|v2))?/    &#125;  &#125;&lt;/script&gt;&lt;script src=&quot;//cdn.jsdelivr.net/npm/docsify/lib/docsify.min.js&quot;&gt;&lt;/script&gt;&lt;script src=&quot;//cdn.jsdelivr.net/npm/docsify/lib/plugins/search.min.js&quot;&gt;&lt;/script&gt;\n\n当执行全文搜索时，该插件会忽略双音符（例如，”cafe” 也会匹配 “café”）。像 IE11 这样的旧版浏览器需要使用以下 String.normalize() polyfill 来忽略双音符：\n&lt;script src=&quot;//polyfill.io/v3/polyfill.min.js?features=String.prototype.normalize&quot;&gt;&lt;/script&gt;\n\n\n\n","categories":["技术教程","docsify"],"tags":["docsify"]},{"title":"常用Git命令清单","url":"/%E6%8A%80%E6%9C%AF%E6%95%99%E7%A8%8B/Git/%E5%B8%B8%E7%94%A8Git%E5%91%BD%E4%BB%A4%E6%B8%85%E5%8D%95/","content":"我每天使用 Git ，但是很多命令记不住。\n一般来说，日常使用只要记住下图 6 个命令，就可以了。但是熟练使用，恐怕要记住 60 ～ 100 个命令。\n\n\n\n下面是我整理的常用 Git 命令清单。几个专用名词的译名如下。\n\nWorkspace：工作区\nIndex / Stage：暂存区\nRepository：仓库区（或本地仓库）\nRemote：远程仓库\n\n新建代码库# 在当前目录新建一个Git代码库$ git init# 新建一个目录，将其初始化为Git代码库$ git init [project-name]# 下载一个项目和它的整个代码历史$ git clone [url]\n\n配置Git 的设置文件为 .gitconfig，它可以在用户主目录下（全局配置），也可以在项目目录下（项目配置）。\n# 显示当前的Git配置$ git config --list# 编辑Git配置文件$ git config -e [--global]# 设置提交代码时的用户信息$ git config [--global] user.name &quot;[name]&quot;$ git config [--global] user.email &quot;[email address]&quot;\n\n增加/删除文件# 添加指定文件到暂存区$ git add [file1] [file2] ...# 添加指定目录到暂存区，包括子目录$ git add [dir]# 添加当前目录的所有文件到暂存区$ git add .# 添加每个变化前，都会要求确认# 对于同一个文件的多处变化，可以实现分次提交$ git add -p# 删除工作区文件，并且将这次删除放入暂存区$ git rm [file1] [file2] ...# 停止追踪指定文件，但该文件会保留在工作区$ git rm --cached [file]# 改名文件，并且将这个改名放入暂存区$ git mv [file-original] [file-renamed]\n\n代码提交# 提交暂存区到仓库区$ git commit -m [message]# 提交暂存区的指定文件到仓库区$ git commit [file1] [file2] ... -m [message]# 提交工作区自上次commit之后的变化，直接到仓库区$ git commit -a# 提交时显示所有diff信息$ git commit -v# 使用一次新的commit，替代上一次提交# 如果代码没有任何新变化，则用来改写上一次commit的提交信息$ git commit --amend -m [message]# 重做上一次commit，并包括指定文件的新变化$ git commit --amend [file1] [file2] ...\n\n分支# 列出所有本地分支$ git branch# 列出所有远程分支$ git branch -r# 列出所有本地分支和远程分支$ git branch -a# 新建一个分支，但依然停留在当前分支$ git branch [branch-name]# 新建一个分支，并切换到该分支$ git checkout -b [branch]# 新建一个分支，指向指定commit$ git branch [branch] [commit]# 新建一个分支，与指定的远程分支建立追踪关系$ git branch --track [branch] [remote-branch]# 切换到指定分支，并更新工作区$ git checkout [branch-name]# 切换到上一个分支$ git checkout -# 建立追踪关系，在现有分支与指定的远程分支之间$ git branch --set-upstream [branch] [remote-branch]# 合并指定分支到当前分支$ git merge [branch]# 选择一个commit，合并进当前分支$ git cherry-pick [commit]# 删除分支$ git branch -d [branch-name]# 删除远程分支$ git push origin --delete [branch-name]$ git branch -dr [remote/branch]\n\n标签# 列出所有tag$ git tag# 新建一个tag在当前commit$ git tag [tag]# 新建一个tag在指定commit$ git tag [tag] [commit]# 删除本地tag$ git tag -d [tag]# 删除远程tag$ git push origin :refs/tags/[tagName]# 查看tag信息$ git show [tag]# 提交指定tag$ git push [remote] [tag]# 提交所有tag$ git push [remote] --tags# 新建一个分支，指向某个tag$ git checkout -b [branch] [tag]\n\n查看信息# 显示有变更的文件$ git status# 显示当前分支的版本历史$ git log# 显示commit历史，以及每次commit发生变更的文件$ git log --stat# 搜索提交历史，根据关键词$ git log -S [keyword]# 显示某个commit之后的所有变动，每个commit占据一行$ git log [tag] HEAD --pretty=format:%s# 显示某个commit之后的所有变动，其&quot;提交说明&quot;必须符合搜索条件$ git log [tag] HEAD --grep feature# 显示某个文件的版本历史，包括文件改名$ git log --follow [file]$ git whatchanged [file]# 显示指定文件相关的每一次diff$ git log -p [file]# 显示过去5次提交$ git log -5 --pretty --oneline# 显示所有提交过的用户，按提交次数排序$ git shortlog -sn# 显示指定文件是什么人在什么时间修改过$ git blame [file]# 显示暂存区和工作区的差异$ git diff# 显示暂存区和上一个commit的差异$ git diff --cached [file]# 显示工作区与当前分支最新commit之间的差异$ git diff HEAD# 显示两次提交之间的差异$ git diff [first-branch]...[second-branch]# 显示今天你写了多少行代码$ git diff --shortstat &quot;@&#123;0 day ago&#125;&quot;# 显示某次提交的元数据和内容变化$ git show [commit]# 显示某次提交发生变化的文件$ git show --name-only [commit]# 显示某次提交时，某个文件的内容$ git show [commit]:[filename]# 显示当前分支的最近几次提交$ git reflog\n\n远程同步# 下载远程仓库的所有变动$ git fetch [remote]# 显示所有远程仓库$ git remote -v# 显示某个远程仓库的信息$ git remote show [remote]# 增加一个新的远程仓库，并命名$ git remote add [shortname] [url]# 取回远程仓库的变化，并与本地分支合并$ git pull [remote] [branch]# 上传本地指定分支到远程仓库$ git push [remote] [branch]# 强行推送当前分支到远程仓库，即使有冲突$ git push [remote] --force# 推送所有分支到远程仓库$ git push [remote] --all\n\n撤销# 恢复暂存区的指定文件到工作区$ git checkout [file]# 恢复某个commit的指定文件到暂存区和工作区$ git checkout [commit] [file]# 恢复暂存区的所有文件到工作区$ git checkout .# 重置暂存区的指定文件，与上一次commit保持一致，但工作区不变$ git reset [file]# 重置暂存区与工作区，与上一次commit保持一致$ git reset --hard# 重置当前分支的指针为指定commit，同时重置暂存区，但工作区不变$ git reset [commit]# 重置当前分支的HEAD为指定commit，同时重置暂存区和工作区，与指定commit一致$ git reset --hard [commit]# 重置当前HEAD为指定commit，但保持暂存区和工作区不变$ git reset --keep [commit]# 新建一个commit，用来撤销指定commit# 后者的所有变化都将被前者抵消，并且应用到当前分支$ git revert [commit]# 暂时将未提交的变化移除，稍后再移入$ git stash$ git stash pop\n\n其他# 生成一个可供发布的压缩包$ git archive\n\n转载：https://www.ruanyifeng.com/blog/2015/12/git-cheat-sheet.html\n","categories":["技术教程","Git"],"tags":["Git"]},{"title":"批处理bat脚本案例","url":"/%E6%8A%80%E6%9C%AF%E6%95%99%E7%A8%8B/bat/%E6%89%B9%E5%A4%84%E7%90%86bat%E6%A1%88%E4%BE%8B/","content":"sublime_text右键菜单\nsublime_text安装目录根路径执行\n\n@ECHO OFF &amp; PUSHD %~DP0 &amp; TITLE&gt;NUL 2&gt;&amp;1 REG.exe query &quot;HKU\\S-1-5-19&quot; || (    ECHO SET UAC = CreateObject^(&quot;Shell.Application&quot;^) &gt; &quot;%TEMP%\\Getadmin.vbs&quot;    ECHO UAC.ShellExecute &quot;%~f0&quot;, &quot;%1&quot;, &quot;&quot;, &quot;runas&quot;, 1 &gt;&gt; &quot;%TEMP%\\Getadmin.vbs&quot;    &quot;%TEMP%\\Getadmin.vbs&quot;    DEL /f /q &quot;%TEMP%\\Getadmin.vbs&quot; 2&gt;NUL    Exit /b)SET /P ST=输入a添加右键菜单，输入d删除右键菜单：if /I &quot;%ST%&quot;==&quot;a&quot; goto Addif /I &quot;%ST%&quot;==&quot;d&quot; goto Remove:Addreg add &quot;HKEY_CLASSES_ROOT\\*\\shell\\Sublime Text&quot; /t REG_SZ /v &quot;&quot; /d &quot;用 &amp;Sublime Text 打开&quot; /freg add &quot;HKEY_CLASSES_ROOT\\*\\shell\\Sublime Text&quot; /t REG_EXPAND_SZ /v &quot;Icon&quot; /d &quot;%~dp0sublime_text.exe&quot; /freg add &quot;HKEY_CLASSES_ROOT\\*\\shell\\Sublime Text\\command&quot; /t REG_SZ /v &quot;&quot; /d &quot;%~dp0sublime_text.exe \\&quot;%%1\\&quot;&quot; /f exit:Removereg delete &quot;HKEY_CLASSES_ROOT\\*\\shell\\Sublime Text&quot; /fexit\n\njava环境变量配置::添加环境变量JAVA_HOME::echo off 表示在批处理文件执行过程中，只显示结果，而不显示执行的命令@echo onecho 添加Java环境变量setx /M JAVA_HOME &quot;C:\\Program Files\\Java\\jdk1.8.0_171&quot;setx /M Path &quot;%Path%;%%JAVA_HOME%%\\bin;%%JAVA_HOME%%\\jre\\bin;&quot;setx /M CLASSPATH &quot;.;%%JAVA_HOME%%\\lib\\dt.jar;%%JAVA_HOME%%\\lib\\tools.jar;&quot;::pause命令运行后会中断执行的语句。这个中断不是立即停止，只是暂停::按下任意键之后就会继续执行下面的语句。pause::添加环境变量之后不会在本cmd窗口生效，所以%JAVA_HOME%没有值::需要输入  %%JAVA_HOME%% 显示 %JAVA_HOME%\n\nnginx启动@echo offif &quot;%1&quot;==&quot;help&quot; (goto help) else (if &quot;%1&quot;==&quot;-h&quot; goto help)if &quot;%1&quot;==&quot;version&quot; (goto version) else (if &quot;%1&quot;==&quot;-v&quot; goto version)if &quot;%1&quot;==&quot;start&quot; goto startif &quot;%1&quot;==&quot;stop&quot; goto stopif &quot;%1&quot;==&quot;reload&quot; goto reloadif &quot;%1&quot;==&quot;reopen&quot; goto reopenif &quot;%1&quot;==&quot;find&quot; goto findgoto error:helpnginx -vecho Usage: nginxd [-h,help] [-v,version] [start] [stop] [stop -a] [reload] [reopen] [find]echo=echo Options:echo   help,-h         : this helpecho   version,-v      : show current nginx versionecho   start           : start nginx master processecho   stop            : stop the newest nginx master processecho   stop -a         : stop all nginx master processesecho   reload          : reload configurationecho   reopen          : reopen nginxecho   find            : show the nginx master process listecho=exit /B:versionnginx -vexit /B:startstart nginx -p D:\\Programs\\Nginxexit /B:stopif &quot;%2&quot;==&quot;-a&quot; (taskkill /F /IM nginx.exe) else (if &quot;%2&quot;==&quot;&quot; (nginx -s stop -p D:\\Programs\\Nginx) else goto error)exit /B:reloadnginx -s reload -p D:\\Programs\\Nginxexit /B:findtasklist /fi &quot;imagename eq nginx.exe&quot;exit /B:errorecho nginxd: invalid option: &quot;%1 %2&quot;echo=   exit /B\n\n","categories":["技术教程","bat"],"tags":["批处理","脚本","bat"]},{"title":"Openresty+Lua搭建文件服务器","url":"/%E6%8A%80%E6%9C%AF%E6%95%99%E7%A8%8B/Lua/Openresty+Lua%E6%90%AD%E5%BB%BA%E6%96%87%E4%BB%B6%E6%9C%8D%E5%8A%A1%E5%99%A8/","content":"目的搭建静态文件服务器，用户访问浏览器地址下载相应的文件\n如访问：http://127.0.0.1/doc/test.docx 即是下载test.docx文件\n步骤安装openresty配置nginx.conf#user  nobody;worker_processes  1;events &#123;    worker_connections 4096 ;&#125;http &#123;    include       mime.types;    default_type  application/octet-stream;    add_header &#x27;Access-Control-Allow-Origin&#x27; &#x27;*&#x27;;    add_header &#x27;Access-Control-Allow-Methods&#x27; &#x27;GET,POST,OPTIONS&#x27;;    sendfile        on;    #tcp_nopush     on;    #keepalive_timeout  0;    keepalive_timeout  65;    lua_package_path &quot;lualib/?.lua;&quot;;    lua_package_cpath &quot;lualib/?.so;&quot;;     resolver 114.114.114.114;     server &#123;        listen       80;        server_name  localhost;        # 文件存储路径        root C:/data/sharefile;        set $store_dir C:/data/sharefile/; # 文件存储路径        location / &#123;            autoindex on; # 索引            autoindex_exact_size on; # 显示文件大小            autoindex_localtime on; # 显示文件时间        &#125;        location /download &#123;            alias C:/data/sharefile;            autoindex on;            index  index.html index.htm;        &#125;                location /upload &#123;            client_max_body_size    4000m;              default_type  application/json;            lua_code_cache on;              content_by_lua_file lua_scripts/upload.lua;        &#125;                location /delete &#123;            default_type  application/json;            content_by_lua_file lua_scripts/deletefile.lua;        &#125;                location /move&#123;            default_type  application/json;            content_by_lua_file lua_scripts/move.lua;        &#125;                location /isexit&#123;            default_type  application/json;            content_by_lua_file lua_scripts/isexit.lua;        &#125;    &#125;&#125;\n\n\n\n重新启动 openresty访问 http://127.0.0.1，效果如下\n配置上传文件-- upload.lua--==========================================-- 文件上传--==========================================local upload = require &quot;resty.upload&quot;-- 文件保存的根路径-- local saveRootPath = &quot;/data/sharefile/&quot;local saveRootPath = ngx.var.store_dirlocal baseurl = &quot;download/&quot;local urllist = &quot;&#123;&quot;local dir = &quot;0&quot;local newfilenamelocal acdd = &quot;y&quot; --[[自动创建目录]]local arf = &quot;y&quot; --[[自动重命名文件]]dir = ngx.req.get_uri_args()[&quot;dir&quot;]if dir == nil then    dir = &quot;0&quot;endlocal date_ym = os.date(&quot;%Y%m&quot;);local date_d = os.date(&quot;%d&quot;);acdd = ngx.req.get_uri_args()[&quot;acdd&quot;]if acdd == &quot;n&quot; then    saveRootPath = saveRootPath .. dir .. &quot;/&quot;    baseurl = baseurl .. dir .. &quot;/&quot;else    saveRootPath = saveRootPath .. date_ym .. &quot;/&quot; .. date_d .. &quot;/&quot; .. dir .. &quot;/&quot;    baseurl = baseurl .. date_ym .. &quot;/&quot; .. date_d .. &quot;/&quot; .. dir .. &quot;/&quot;endarf = ngx.req.get_uri_args()[&quot;arf&quot;]local chunk_size = 40960local form = upload:new(chunk_size)if not form then    ngx.say(&quot;&#123;\\&quot;error\\&quot;:\\&quot;error\\&quot;, \\&quot;msg\\&quot;:\\&quot;no data post\\&quot;&#125;&quot;)    returnend-- 保存的文件对象local file-- function getFileName(res)    local filename = ngx.re.match(res, &#x27;(.+)filename=&quot;(.+)&quot;(.*)&#x27;)    if filename then        return filename[2]    endend--function getExtension(str)    return str:match(&quot;.+%.(%w+)$&quot;)end--function get16Md5(str)    return string.sub(str, 9, 24)endfunction getNewFileName(file_name)    if arf == &quot;n&quot; then        newfilename = file_name        return newfilename    else        local extension = getExtension(file_name)        local filedate = os.date(&quot;%y%m%d%H%M%S&quot;);        local md5 = get16Md5(ngx.md5(file_name));        if extension then            newfilename = filedate .. md5 .. &quot;.&quot; .. extension            if not extension then                newfilename = filedate .. md5            end        end        return newfilename    endendfunction dir_exists(path)    local file = io.open(path, &quot;rb&quot;)    if file then        --ngx.log(ngx.ERR, &quot;path dir_exists************&quot;)        file:close()    end    if not file then        ngx.log(ngx.ERR, &quot;path not dir_exists************&quot;)        -- linux系统        -- os.execute(&#x27;mkdir -p &#x27; .. path)        -- windows系统        local path1 = string.gsub(path, &#x27;/&#x27;, &#x27;\\\\&#x27;)        os.execute(&#x27;md &#x27;.. path1)    endend--[[local uritoken = ngx.req.get_uri_args()[&quot;token&quot;] local cookietoken = ngx.var.cookie_token --$cookie_tokenlocal token = uritoken or cookietokenif token == nil then    ngx.say(&quot;&#123;\\&quot;error\\&quot;:\\&quot;error\\&quot;, \\&quot;msg\\&quot;:\\&quot;token is empty\\&quot;,url:\\&quot;\\&quot;&#125;&quot;)    returnend]]while true do    --ngx.log(ngx.ERR, &quot;1111************&quot;)    local typ, res, err = form:read()    --ngx.log(ngx.ERR, &quot;2222-typ************&quot;..typ)    if not typ then        ngx.say(&quot;&#123;\\&quot;error\\&quot;:\\&quot;error\\&quot;, \\&quot;msg\\&quot;:\\&quot;&quot; .. tostring(err) .. &quot;\\&quot;&#125;&quot;)        return    end    if typ == &quot;header&quot; then        --[[                ngx.log(ngx.ERR, &quot;3333-typ=header************&quot;..type(res))                ngx.log(ngx.ERR, &quot;RRRR-typ=header-res[1]************&quot;..#(res))                for key, value in pairs(res) do                    ngx.log(ngx.ERR, &quot;KKK-typ=header-res[1] key************&quot;..key)                    ngx.log(ngx.ERR, &quot;VVV-typ=header-res[1] value************&quot;..value)                end        ]]        --ngx.log(ngx.ERR, &quot;4444-typ=header-res[1]************&quot;..res[1])        if res[1] ~= &quot;Content-Type&quot; then            --ngx.log(ngx.ERR, &quot;5555-res[2]************&quot; .. res[2])            local file_name = getFileName(res[2])            if file_name then                getNewFileName(file_name)                dir_exists(saveRootPath)                local file_name_1 = saveRootPath .. newfilename                local fileexists = io.open(file_name_1, &quot;rb&quot;)                if fileexists then                    fileexists:close()                    ngx.say(&quot;&#123;\\&quot;error\\&quot;:\\&quot;error\\&quot;, \\&quot;msg\\&quot;:\\&quot;[&quot; .. newfilename .. &quot;] file already exists\\&quot;&#125;&quot;)                    return                end                -- linux系统                -- file = io.open(file_name_1, &quot;w+&quot;)                -- windows系统需要加b                file = io.open(file_name_1, &quot;w+b&quot;)                urllist = urllist .. &quot;\\&quot;&quot; .. file_name .. &quot;\\&quot;:\\&quot;&quot; .. baseurl .. newfilename .. &quot;\\&quot;,&quot;                if not file then                    ngx.say(&quot;&#123;\\&quot;error\\&quot;:\\&quot;error\\&quot;, \\&quot;msg\\&quot;:\\&quot;failed to open file &quot; .. file_name_1 .. &quot;\\&quot;&#125;&quot;)                    return                end            end        end    elseif typ == &quot;body&quot; then        if file then            --\tngx.log(ngx.ERR, &quot;9999-1111-write************&quot;..res)            file:write(res)        end    elseif typ == &quot;part_end&quot; then        if file then            file:close()        end        file = nil    elseif typ == &quot;eof&quot; then        break    else        -- do nothing    endendlocal ul = string.sub(urllist, 1, -2)local ull = ul .. &quot;&#125;&quot;--ngx.log(ngx.ERR, &quot;ull************&quot;..ull)ngx.header[&quot;Content-Type&quot;] = &quot;application/json; charset=utf-8&quot;--ngx.header[&quot;Control-Allow-Headers&quot;] = &quot;Origin, X-Requested-With, Content-Type, Accept,filedir&quot;--ngx.header[&quot;filedir&quot;] = &quot;&quot;ngx.say(&quot;&#123;\\&quot;error\\&quot;:\\&quot;success\\&quot;, \\&quot;msg\\&quot;:\\&quot;success\\&quot;,\\&quot;urllist\\&quot;:&quot; .. ull .. &quot;&#125;&quot;)\n\nhttp://127.0.0.1/upload?dir=test&amp;acdd=n&amp;arf=n\n参数 acdd 和 arf 可选\n下载文件download.lua\n-- download.lua--==========================================-- 下载上传--==========================================local http = require &quot;resty.http&quot;local upload = require &quot;resty.upload&quot;local oss = require &quot;resty.oss&quot;ngx.say(&quot;1231=================&quot;)-- 获取上传的文件function readFile()    local chunk_size = 4096    local form, err = upload:new(chunk_size)    form:set_timeout(20000)    local file = &#123;&#125;    if not err then        while true do            local typ, res, err2 = form:read()            if not typ then                err = err2                print(&quot;failed to read: &quot;, err2)                break            end            if typ == &#x27;header&#x27; and res[1] == &#x27;Content-Disposition&#x27; then                local filename = string.match(res[2], &#x27;filename=&quot;(.*)&quot;&#x27;)                file.name = filename            end            if typ == &#x27;header&#x27; and res[1] == &#x27;Content-Type&#x27; then                file[&#x27;type&#x27;] = res[2]            end            if typ == &#x27;body&#x27; and file then                file[typ] = (file[typ] or &#x27;&#x27;) .. res            end            if typ == &quot;eof&quot; then                break            end        end    end    return file, errendlocal file, err = readFile()local oss_config = &#123;    accessKey  = &quot;xxxxxxxxxxxxxxxxxxxx&quot;,    secretKey  = &quot;xxxxxxxxxxxxxxxxxxxxxxxxxxxx&quot;,    bucket      = &quot;xxxx&quot;,    endpoint   = &quot;oss-cn-beijing.aliyuncs.com&quot;&#125;local client = oss.new(oss_config)local url = client:put_object(file.body, file.type, file.name)ngx.say(url)ngx.say(&quot;asdfasdfasdf2134123&quot;)\n\nhttp://127.0.0.1/download/seal.jpg\n移动文件-- move.lua--==========================================-- 移动上传--==========================================local storepath = &quot;/data/sharefile/&quot;local request_method = ngx.var.request_methodlocal sourcedir = ngx.req.get_uri_args()[&quot;sourceDir&quot;]local filename = ngx.req.get_uri_args()[&quot;fileName&quot;]local targetdir = ngx.req.get_uri_args()[&quot;targetDir&quot;]local romoveCmd = &quot;mv&quot;..&quot; &quot;..storepath..sourcedir..filename..&quot; &quot;..storepath..targetdir..filenamelocal mv_file = os.execute(romoveCmd)ngx.header[&quot;Content-Type&quot;] = &quot;application/json; charset=utf-8&quot;if(mv_file ~= 0) then \tngx.say(&quot;&#123;\\&quot;error\\&quot;:\\&quot;error\\&quot;, \\&quot;msg\\&quot;:\\&quot;move fail\\&quot;&#125;&quot;)else\tngx.say(&quot;&#123;\\&quot;error\\&quot;:\\&quot;success\\&quot;, \\&quot;msg\\&quot;:\\&quot;&quot;..targetdir..filename..&quot;\\&quot;&#125;&quot;)end\n\n\n\n删除文件-- delete.lua--==========================================-- 删除上传--==========================================local storepath = &quot;/data/sharefile/&quot;local request_method = ngx.var.request_methodlocal filename = ngx.req.get_uri_args()[&quot;f&quot;]local rm_file = os.remove(storepath..filename)ngx.header[&quot;Content-Type&quot;]    = &quot;application/json; charset=utf-8&quot;if(rm_file == nil) then \tngx.say(&quot;&#123;\\&quot;error\\&quot;:\\&quot;error\\&quot;, \\&quot;msg\\&quot;:\\&quot;file not exist or other reasons\\&quot;&#125;&quot;)else\tngx.say(&quot;&#123;\\&quot;error\\&quot;:\\&quot;success\\&quot;, \\&quot;msg\\&quot;:\\&quot;success\\&quot;&#125;&quot;)end\n\n","categories":["技术教程","Lua"],"tags":["Openresty","Lua","文件服务器"]},{"title":"Oracle查询连续日期","url":"/%E6%95%B0%E6%8D%AE%E5%BA%93/Oracle/Oracle%E6%9F%A5%E8%AF%A2%E8%BF%9E%E7%BB%AD%E6%97%A5%E6%9C%9F/","content":"在线数据http://sqlfiddle.com/\ncreate table test(  id    VARCHAR2(32),  vcode VARCHAR2(50),  qdate date);insert into test select * from (select &#x27;1&#x27; id, &#x27;A001&#x27; as vcode, date &#x27;2019-05-01&#x27; as qdate from dual unionselect &#x27;2&#x27; id, &#x27;A001&#x27; as vcode, date &#x27;2019-05-02&#x27; as qdate from dual unionselect &#x27;3&#x27; id, &#x27;A001&#x27; as vcode, date &#x27;2019-05-03&#x27; as qdate from dual unionselect &#x27;4&#x27; id, &#x27;A001&#x27; as vcode, date &#x27;2019-05-05&#x27; as qdate from dual unionselect &#x27;5&#x27; id, &#x27;A001&#x27; as vcode, date &#x27;2019-05-07&#x27; as qdate from dual unionselect &#x27;6&#x27; id, &#x27;A001&#x27; as vcode, date &#x27;2019-05-09&#x27; as tqdateime from dual unionselect &#x27;7&#x27; id, &#x27;A001&#x27; as vcode, date &#x27;2019-05-10&#x27; as qdate from dual unionselect &#x27;8&#x27; id, &#x27;B001&#x27; as vcode, date &#x27;2019-05-06&#x27; as qdate from dual unionselect &#x27;9&#x27; id, &#x27;B001&#x27; as vcode, date &#x27;2019-05-07&#x27; as qdate from dual unionselect &#x27;10&#x27; id, &#x27;B001&#x27; as vcode, date &#x27;2019-05-08&#x27; as qdate from dual) \n\n生成表如下：\n\n\n\nD\nVCODE\nQDATE\n\n\n\n1\nA001\n2019-05-01T00:00:00Z\n\n\n10\nB001\n2019-05-08T00:00:00Z\n\n\n2\nA001\n2019-05-02T00:00:00Z\n\n\n3\nA001\n2019-05-03T00:00:00Z\n\n\n4\nA001\n2019-05-05T00:00:00Z\n\n\n5\nA001\n2019-05-07T00:00:00Z\n\n\n6\nA001\n2019-05-09T00:00:00Z\n\n\n7\nA001\n2019-05-10T00:00:00Z\n\n\n8\nB001\n2019-05-06T00:00:00Z\n\n\n9\nB001\n2019-05-07T00:00:00Z\n\n\n按照名字vcode分组，按照日期qdate排序\nselectt.*,row_number() over(partition by vcode order by qdate) as rnfrom test t;\n\n结果如下：\n\n\n\nID\nVCODE\nQDATE\nRN\n\n\n\n1\nA001\n2019-05-01T00:00:00Z\n1\n\n\n2\nA001\n2019-05-02T00:00:00Z\n2\n\n\n3\nA001\n2019-05-03T00:00:00Z\n3\n\n\n4\nA001\n2019-05-05T00:00:00Z\n4\n\n\n5\nA001\n2019-05-07T00:00:00Z\n5\n\n\n6\nA001\n2019-05-09T00:00:00Z\n6\n\n\n7\nA001\n2019-05-10T00:00:00Z\n7\n\n\n8\nB001\n2019-05-06T00:00:00Z\n1\n\n\n9\nB001\n2019-05-07T00:00:00Z\n2\n\n\n10\nB001\n2019-05-08T00:00:00Z\n3\n\n\n提取日期减去行号，得到的结果rn连续相同时即为日期连续组\nselectt.*,trunc(qdate) - row_number() over(partition by vcode order by qdate) as rnfrom test t;\n\n结果如下：\n\n\n\nID\nVCODE\nQDATE\nRN\n\n\n\n1\nA001\n2019-05-01T00:00:00Z\n2019-04-30T00:00:00Z\n\n\n2\nA001\n2019-05-02T00:00:00Z\n2019-04-30T00:00:00Z\n\n\n3\nA001\n2019-05-03T00:00:00Z\n2019-04-30T00:00:00Z\n\n\n4\nA001\n2019-05-05T00:00:00Z\n2019-05-01T00:00:00Z\n\n\n5\nA001\n2019-05-07T00:00:00Z\n2019-05-02T00:00:00Z\n\n\n6\nA001\n2019-05-09T00:00:00Z\n2019-05-03T00:00:00Z\n\n\n7\nA001\n2019-05-10T00:00:00Z\n2019-05-03T00:00:00Z\n\n\n8\nB001\n2019-05-06T00:00:00Z\n2019-05-05T00:00:00Z\n\n\n9\nB001\n2019-05-07T00:00:00Z\n2019-05-05T00:00:00Z\n\n\n10\nB001\n2019-05-08T00:00:00Z\n2019-05-05T00:00:00Z\n\n\n根据vcode和rn分组，得到的count即为连续的天数\nselect vcode, rn, count(*)from (selectt.*,trunc(qdate) - row_number() over(partition by vcode order by qdate) as rnfrom test t) group by vcode, rn;\n\n结果如下：\n\n\n\nVCODE\nRN\nCOUNT(*)\n\n\n\nB001\n2019-05-05T00:00:00Z\n3\n\n\nA001\n2019-05-01T00:00:00Z\n1\n\n\nA001\n2019-05-02T00:00:00Z\n1\n\n\nA001\n2019-05-03T00:00:00Z\n2\n\n\nA001\n2019-04-30T00:00:00Z\n3\n\n\n通过having即可筛选出连续天数&gt;=2的vcode\nselect vcode, rn, count(*)from (selectt.*,trunc(qdate) - row_number() over(partition by vcode order by qdate) as rnfrom test t) group by vcode, rn having count(1) &gt;= 2;\n\n结果如下：\n\n\n\nVCODE\nRN\nCOUNT(*)\n\n\n\nB001\n2019-05-05T00:00:00Z\n3\n\n\nA001\n2019-05-03T00:00:00Z\n2\n\n\nA001\n2019-04-30T00:00:00Z\n3\n\n\n","categories":["数据库","Oracle"],"tags":["Oracle"]},{"title":"杂记","url":"/%E5%85%B6%E4%BB%96/%E6%9D%82%E8%AE%B0/","content":"数据闪回1、启动表的row movement特性\nALTER TABLE FX_MXZXRW ENABLE ROW MOVEMENT;\n\n\n\n2、闪回指定时间的快照\nFLASHBACK TABLE FX_MXZXRW TO TIMESTAMP TO_TIMESTAMP(&#x27;2021-02-05 13:45:00&#x27;,&#x27;yyyy-mm-dd hh24:mi:ss&#x27;);\n\n\n\n3、关闭表的row movement功能\nALTER TABLE FX_MXZXRW DISABLE ROW MOVEMENT;\n\n\n\njmap使用线程对应系统占用情况\njmap -heap [pid]\n\n\n\n生成dump文件\njmap -dump:format=b,file=20210225.dump.hprof [pid]\n\n\n\nLinux安装wpsrpm包下载地址\nhttps://linux.wps.cn/\n安装rpm包\nsudo yum localinstall wps-office-11.1.0.10161-1.x86_64.rpm\n\n\n\nCentos 7安装可视化桌面首先安装X(X Window System)\nyum groupinstall &quot;X Window System&quot;\n\n\n\n安装可视化桌面\nyum groupinstall &quot;GNOME Desktop&quot;\n\n\n\n启动(如果启动失败，重启reboot)\nstartx\n\n\n\nsublime_text右键菜单\nsublime_text安装目录根路径执行\n\n@ECHO OFF &amp; PUSHD %~DP0 &amp; TITLE&gt;NUL 2&gt;&amp;1 REG.exe query &quot;HKU\\S-1-5-19&quot; || (    ECHO SET UAC = CreateObject^(&quot;Shell.Application&quot;^) &gt; &quot;%TEMP%\\Getadmin.vbs&quot;    ECHO UAC.ShellExecute &quot;%~f0&quot;, &quot;%1&quot;, &quot;&quot;, &quot;runas&quot;, 1 &gt;&gt; &quot;%TEMP%\\Getadmin.vbs&quot;    &quot;%TEMP%\\Getadmin.vbs&quot;    DEL /f /q &quot;%TEMP%\\Getadmin.vbs&quot; 2&gt;NUL    Exit /b)SET /P ST=输入a添加右键菜单，输入d删除右键菜单：if /I &quot;%ST%&quot;==&quot;a&quot; goto Addif /I &quot;%ST%&quot;==&quot;d&quot; goto Remove:Addreg add &quot;HKEY_CLASSES_ROOT\\*\\shell\\Sublime Text&quot; /t REG_SZ /v &quot;&quot; /d &quot;用 &amp;Sublime Text 打开&quot; /freg add &quot;HKEY_CLASSES_ROOT\\*\\shell\\Sublime Text&quot; /t REG_EXPAND_SZ /v &quot;Icon&quot; /d &quot;%~dp0sublime_text.exe&quot; /freg add &quot;HKEY_CLASSES_ROOT\\*\\shell\\Sublime Text\\command&quot; /t REG_SZ /v &quot;&quot; /d &quot;%~dp0sublime_text.exe \\&quot;%%1\\&quot;&quot; /f exit:Removereg delete &quot;HKEY_CLASSES_ROOT\\*\\shell\\Sublime Text&quot; /fexit\n\n\n\njava环境变量配置::添加环境变量JAVA_HOME::echo off 表示在批处理文件执行过程中，只显示结果，而不显示执行的命令@echo onecho 添加Java环境变量setx /M JAVA_HOME &quot;C:\\Program Files\\Java\\jdk1.8.0_171&quot;setx /M Path &quot;%Path%;%%JAVA_HOME%%\\bin;%%JAVA_HOME%%\\jre\\bin;&quot;setx /M CLASSPATH &quot;.;%%JAVA_HOME%%\\lib\\dt.jar;%%JAVA_HOME%%\\lib\\tools.jar;&quot;::pause命令运行后会中断执行的语句。这个中断不是立即停止，只是暂停::按下任意键之后就会继续执行下面的语句。pause::添加环境变量之后不会在本cmd窗口生效，所以%JAVA_HOME%没有值::需要输入  %%JAVA_HOME%% 显示 %JAVA_HOME%\n\n\n\nnginx启动@echo offif &quot;%1&quot;==&quot;help&quot; (goto help) else (if &quot;%1&quot;==&quot;-h&quot; goto help)if &quot;%1&quot;==&quot;version&quot; (goto version) else (if &quot;%1&quot;==&quot;-v&quot; goto version)if &quot;%1&quot;==&quot;start&quot; goto startif &quot;%1&quot;==&quot;stop&quot; goto stopif &quot;%1&quot;==&quot;reload&quot; goto reloadif &quot;%1&quot;==&quot;reopen&quot; goto reopenif &quot;%1&quot;==&quot;find&quot; goto findgoto error:helpnginx -vecho Usage: nginxd [-h,help] [-v,version] [start] [stop] [stop -a] [reload] [reopen] [find]echo=echo Options:echo   help,-h         : this helpecho   version,-v      : show current nginx versionecho   start           : start nginx master processecho   stop            : stop the newest nginx master processecho   stop -a         : stop all nginx master processesecho   reload          : reload configurationecho   reopen          : reopen nginxecho   find            : show the nginx master process listecho=exit /B:versionnginx -vexit /B:startstart nginx -p D:\\Programs\\Nginxexit /B:stopif &quot;%2&quot;==&quot;-a&quot; (taskkill /F /IM nginx.exe) else (if &quot;%2&quot;==&quot;&quot; (nginx -s stop -p D:\\Programs\\Nginx) else goto error)exit /B:reloadnginx -s reload -p D:\\Programs\\Nginxexit /B:findtasklist /fi &quot;imagename eq nginx.exe&quot;exit /B:errorecho nginxd: invalid option: &quot;%1 %2&quot;echo=   exit /B\n\n","categories":["其他"],"tags":["杂记"]},{"title":"Live Template","url":"/%E6%8A%80%E6%9C%AF%E6%95%99%E7%A8%8B/IDEA/LiveTemplate/","content":"方法带参数返回值问题之前设置idea liveTemplate 方法注释的时候，按照网上的教程params,return参数无法获取，现在终于解决这个问题了，我将详细介绍配置的每一步。\n步骤打开设置Settings找到Live Templates新建Template Group新建Live Template\n模板名字：*\n模板代码：* * $des$ *  * @author huangyuanli * @date $date$ $time$ $param$$return$ **/\n\n\n\n\nparam参数内容：groovyScript(&quot;def result=&#x27;&#x27;; def params=\\&quot;$&#123;_1&#125;\\&quot;.replaceAll(&#x27;[\\\\\\\\[|\\\\\\\\]|\\\\\\\\s]&#x27;, &#x27;&#x27;).split(&#x27;,&#x27;).toList(); for(i = 0; i &lt; params.size(); i++) &#123;result+=&#x27; * @param\\\\t&#x27; + params[i] + &#x27;\\\\t&#x27; + ((i &lt; params.size() - 1) ? &#x27;\\\\n&#x27; : &#x27;&#x27;)&#125;; return result&quot;, methodParameters())\n\n\n\nreturn参数内容：groovyScript(&quot;def returnType = \\&quot;$&#123;_1&#125;\\&quot;; def result = &#x27; * @return &#x27; + returnType; return result;&quot;, methodReturnType());\n\n\n\n使用方法输入 /** ，然后按 Tab 键，效果如下：\n\n","categories":["技术教程","IDEA"],"tags":["IDEA","Live Template"]},{"title":"代码片段","url":"/%E5%85%B6%E4%BB%96/%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5/","content":"AES 加密后端代码import org.apache.log4j.Logger;import javax.crypto.Cipher;import javax.crypto.spec.IvParameterSpec;import javax.crypto.spec.SecretKeySpec;import java.security.Key;import java.security.spec.AlgorithmParameterSpec;import java.util.Base64;/** * @className: AESUtil * @describe: 对称加密AES算法，前端cryptojs实现，后端Java实现 * @author: huangyuanli * @date: 2019/2/21 10:22 **/public class AESUtil &#123;    private static final Logger LOG = Logger.getLogger(AESUtil.class);    private static final String TRANSFORMATION = &quot;AES/CBC/PKCS5Padding&quot;;    private static final String ALGORITHM = &quot;AES&quot;;    private static final String CHARSET = &quot;utf-8&quot;;    /**     * 建议为16位或32位     */    private static final String KEY = &quot;1234123412ABCDEF&quot;;    /**     * 必须16位     * 初始化向量IV不可以为32位，否则异常java.security.InvalidAlgorithmParameterException: Wrong IV length: must be 16 bytes long     */    private static final String IV = &quot;ABCDEF1234123412&quot;;    // 加密    public static String encrypt(String context) &#123;        try &#123;            byte[] decode = context.getBytes(CHARSET);            byte[] bytes = createKeyAndIv(decode, Cipher.ENCRYPT_MODE);            return Base64.getEncoder().encodeToString(bytes);        &#125; catch (Exception e) &#123;            e.printStackTrace();        &#125;        return null;    &#125;    // 解密    public static String decrypt(String context) &#123;        try &#123;            Base64.Decoder decoder = Base64.getDecoder();            byte[] decode = decoder.decode(context);            byte[] bytes = createKeyAndIv(decode, Cipher.DECRYPT_MODE);            return new String(bytes, CHARSET);        &#125; catch (Exception e) &#123;            LOG.debug(&quot;context：&quot; + context);        &#125;        return null;    &#125;    // 获取key &amp; iv    public static byte[] createKeyAndIv(byte[] context, int opmode) throws Exception &#123;        byte[] key = KEY.getBytes(CHARSET);        byte[] iv = IV.getBytes(CHARSET);        return cipherFilter(context, opmode, key, iv);    &#125;    // 执行操作    public static byte[] cipherFilter(byte[] context, int opmode, byte[] key, byte[] iv) throws Exception &#123;        Key secretKeySpec = new SecretKeySpec(key, ALGORITHM);        AlgorithmParameterSpec ivParameterSpec = new IvParameterSpec(iv);        Cipher cipher = Cipher.getInstance(TRANSFORMATION);        cipher.init(opmode, secretKeySpec, ivParameterSpec);        return cipher.doFinal(context);    &#125;&#125;\n\n\n\n前端代码//加密getAesString: function(data)&#123;    var key = CryptoJS.enc.Utf8.parse(&quot;1234123412ABCDEF&quot;);    var iv  = CryptoJS.enc.Utf8.parse(&quot;ABCDEF1234123412&quot;);    var encrypted = CryptoJS.AES.encrypt(data, key,    &#123;        iv:iv,        mode:CryptoJS.mode.CBC,        padding:CryptoJS.pad.Pkcs7    &#125;);    //返回的是base64格式的密文    return encrypted.toString();&#125;,//解密getDAesString: function(encrypted)&#123;    var key = CryptoJS.enc.Utf8.parse(&quot;1234123412ABCDEF&quot;);    var iv  = CryptoJS.enc.Utf8.parse(&quot;ABCDEF1234123412&quot;);    var decrypted = CryptoJS.AES.decrypt(encrypted, key,    &#123;        iv:iv,        mode:CryptoJS.mode.CBC,        padding:CryptoJS.pad.Pkcs7    &#125;);    return decrypted.toString(CryptoJS.enc.Utf8);&#125;\n\nBase64与图片互转import org.apache.commons.lang.StringUtils;import sun.misc.BASE64Decoder;import sun.misc.BASE64Encoder;import javax.imageio.ImageIO;import java.awt.image.BufferedImage;import java.io.*;/** * 图片转为Base64字符串 **/public class ConvertImgToBase64 &#123;\tpublic static void main(String[] args) &#123;\t\t//base64ToImg(base64, &quot;D:/hczz.png&quot;);\t\t//String base64Str = imgToBase64(&quot;D:/longmao.png&quot;);\t\t//System.out.println(isImage(base64));\t\t//writeToFile(base64Str, null, null);\t&#125;\tpublic static String imgToBase64(String imgPath) &#123;\t\tInputStream in = null;\t\tbyte[] data = null;\t\tString encode = null;\t\tBASE64Encoder encoder = new BASE64Encoder();\t\ttry &#123;\t\t\tin = new FileInputStream(imgPath);\t\t\tdata = new byte[in.available()];\t\t\tin.read(data);\t\t\tencode = encoder.encode(data);\t\t&#125; catch (IOException e) &#123;\t\t\te.printStackTrace();\t\t&#125; finally &#123;\t\t\ttry &#123;\t\t\t\tin.close();\t\t\t&#125; catch (IOException e) &#123;\t\t\t\te.printStackTrace();\t\t\t&#125;\t\t&#125;\t\t// 去掉换行\t\tif (StringUtils.isNotBlank(encode)) &#123;\t\t\tencode = encode.replaceAll(&quot;\\r\\n&quot;, &quot;&quot;);\t\t&#125;\t\treturn encode;\t&#125;\tpublic static boolean base64ToImg(String base64Str, String imgPath) &#123;\t\tif (StringUtils.isNotBlank(base64Str)) &#123;\t\t\tBASE64Decoder decoder = new BASE64Decoder();\t\t\tOutputStream out = null;\t\t\ttry &#123;\t\t\t\tout = new FileOutputStream(imgPath);\t\t\t\tbyte[] b = decoder.decodeBuffer(base64Str);\t\t\t\tout.write(b);\t\t\t&#125; catch (IOException e) &#123;\t\t\t\te.printStackTrace();\t\t\t&#125;\t\t&#125;\t\treturn false;\t&#125;\tprivate static void writeToFile(String str, String path, String fileName) &#123;\t\tif (StringUtils.isNotBlank(str)) &#123;\t\t\ttry &#123;\t\t\t\tString newFileName = StringUtils.isBlank(fileName) ? &quot;file&quot; : fileName;\t\t\t\tif (StringUtils.isNotBlank(path)) &#123;\t\t\t\t\tFile dir = new File(path);\t\t\t\t\tif (!dir.exists()) &#123;\t\t\t\t\t\tdir.createNewFile();\t\t\t\t\t&#125;\t\t\t\t\tnewFileName = path + File.separator + newFileName;\t\t\t\t&#125;\t\t\t\tFile file = new File(newFileName);\t\t\t\tif (!file.exists()) &#123;\t\t\t\t\tfile.createNewFile();\t\t\t\t&#125;\t\t\t\tFileWriter fileWriter = new FileWriter(file.getName(), true);\t\t\t\tfileWriter.write(str);\t\t\t\tfileWriter.close();\t\t\t&#125; catch (IOException e) &#123;\t\t\t\te.printStackTrace();\t\t\t&#125;\t\t&#125;\t&#125;\tpublic static boolean isImage(String imgBase64Str) &#123;\t\tif (StringUtils.isBlank(imgBase64Str)) &#123;\t\t\treturn false;\t\t&#125; else &#123;\t\t\tByteArrayInputStream byteArrayInputStream = null;\t\t\ttry &#123;\t\t\t\tBASE64Decoder decoder = new BASE64Decoder();\t\t\t\tbyte[] byteArray = decoder.decodeBuffer(imgBase64Str);\t\t\t\tbyteArrayInputStream = new ByteArrayInputStream(byteArray);\t\t\t\tBufferedImage bufImg = ImageIO.read(byteArrayInputStream);\t\t\t\tif (bufImg == null) &#123;\t\t\t\t\treturn false;\t\t\t\t&#125; else &#123;\t\t\t\t\treturn true;\t\t\t\t&#125;\t\t\t&#125; catch (IOException e) &#123;\t\t\t\te.printStackTrace();\t\t\t&#125; finally &#123;\t\t\t\tif (byteArrayInputStream != null) &#123;\t\t\t\t\ttry &#123;\t\t\t\t\t\tbyteArrayInputStream.close();\t\t\t\t\t&#125; catch (IOException e) &#123;\t\t\t\t\t\te.printStackTrace();\t\t\t\t\t&#125;\t\t\t\t&#125;\t\t\t&#125;\t\t&#125;\t\treturn false;\t&#125;&#125;\n\n\n\nConcurrentHashmappublic class ConcurrentHashmapTest &#123;    //循环次数    private static final int LOOP_COUNT = 10000000;    //线程数量    private static final int THREAD_COUNT = 10;    //元素数量    private static final int ITEM_COUNT = 1000;    private static Map&lt;String, Long&gt; normaluse() throws InterruptedException &#123;        ConcurrentHashMap&lt;String, Long&gt; freqs = new ConcurrentHashMap&lt;&gt;(ITEM_COUNT);        ForkJoinPool forkJoinPool = new ForkJoinPool(THREAD_COUNT);        forkJoinPool.execute(() -&gt; IntStream.rangeClosed(1, LOOP_COUNT).parallel().forEach(i -&gt; &#123;                    //获得一个随机的Key                    String key = &quot;item&quot; + ThreadLocalRandom.current().nextInt(ITEM_COUNT);                    synchronized (freqs) &#123;                        if (freqs.containsKey(key)) &#123;                            //Key存在则+1                            freqs.put(key, freqs.get(key) + 1);                        &#125; else &#123;                            //Key不存在则初始化为1                            freqs.put(key, 1L);                        &#125;                    &#125;                &#125;        ));        forkJoinPool.shutdown();        forkJoinPool.awaitTermination(1, TimeUnit.HOURS);        return freqs;    &#125;    private static Map&lt;String, Long&gt; gooduse() throws InterruptedException &#123;        ConcurrentHashMap&lt;String, LongAdder&gt; freqs = new ConcurrentHashMap&lt;&gt;(ITEM_COUNT);        ForkJoinPool forkJoinPool = new ForkJoinPool(THREAD_COUNT);        forkJoinPool.execute(() -&gt; IntStream.rangeClosed(1, LOOP_COUNT).parallel().forEach(i -&gt; &#123;                    String key = &quot;item&quot; + ThreadLocalRandom.current().nextInt(ITEM_COUNT);                    //利用computeIfAbsent()方法来实例化LongAdder，然后利用LongAdder来进行线程安全计数                    freqs.computeIfAbsent(key, k -&gt; new LongAdder()).increment();                &#125;        ));        forkJoinPool.shutdown();        forkJoinPool.awaitTermination(1, TimeUnit.HOURS);        //因为我们的Value是LongAdder而不是Long，所以需要做一次转换才能返回        return freqs.entrySet().stream()                .collect(Collectors.toMap(Map.Entry::getKey, e -&gt; e.getValue().longValue())                );    &#125;    public static void main(String[] args) throws InterruptedException &#123;        StopWatch stopWatch = new StopWatch();        stopWatch.start(&quot;normaluse&quot;);        Map&lt;String, Long&gt; normaluse = normaluse();        stopWatch.stop();        //校验元素数量        Assert.isTrue(normaluse.size() == ITEM_COUNT, &quot;normaluse size error&quot;);        //校验累计总数        Assert.isTrue(normaluse.values().stream()                        .mapToLong(l -&gt; l).reduce(0, Long::sum) == LOOP_COUNT                , &quot;normaluse count error&quot;);        stopWatch.start(&quot;gooduse&quot;);        Map&lt;String, Long&gt; gooduse = gooduse();        stopWatch.stop();        Assert.isTrue(gooduse.size() == ITEM_COUNT, &quot;gooduse size error&quot;);        Assert.isTrue(gooduse.values().stream()                        .mapToLong(l -&gt; l)                        .reduce(0, Long::sum) == LOOP_COUNT                , &quot;gooduse count error&quot;);        System.out.println(stopWatch.prettyPrint());    &#125;&#125;\n\n\n\n通过反射给对象赋值/** * 解析反馈数据，并转换成对应的反馈对象 * * @author xis * @date 2020-01-14 17:39 **/public class ResolveFeedbackData&lt;T extends FbBaseInfo&gt; &#123;    public List&lt;T&gt; resolveFbData(Class&lt;T&gt; tClass, String sjxsm, List&lt;String&gt; sjxnr) &#123;        if (CollectionUtils.isEmpty(sjxnr)) &#123;            return null;        &#125;        String[] sjxsms = sjxsm.split(&quot;\\\\|\\\\|&quot;);        // 数据项说明字段个数        int sjxsmLen = sjxsms.length;        // 数据项说明字段        String[] sFields = new String[sjxsmLen];        // 下划线连接改成驼峰命名        for (int i = 0; i &lt; sjxsms.length; i++) &#123;            String tmp = underlineToCamel(sjxsms[i].trim());            sFields[i] = tmp;        &#125;        // 解析后的结果        return sjxnr.stream().collect(ArrayList::new, (list, sjx) -&gt; &#123;            String[] sjxs = sjx.split(&quot;\\\\|\\\\|&quot;);            // 数据内容长度            int sjxLen = sjxs.length;            if (sjxsmLen == sjxLen) &#123;                // 获取源对象的所有属性                Field[] tFields = tClass.getDeclaredFields();                // 通过类的详情信息，创建目标对象 这一步等同于UserTwo target = new UserTwo()；                T target = null;                try &#123;                    target = tClass.newInstance();                &#125; catch (Exception e) &#123;                    e.printStackTrace();                &#125;                for (int i = 0; i &lt; sjxs.length; i++) &#123;                    String sjxStr = sjxs[i].trim();                    // 数据项说明                    String sField = sFields[i];                    // 循环对象的每一个属性                    for (Field tField : tFields) &#123;                        // 判断源对象的属性名是否和目标对象的属性名一致                        if (StringUtils.uncapitalize(sField).equals(tField.getName())) &#123;                            try &#123;                                // 属性的set方法名                                String tMethodName = &quot;set&quot; + sField;                                // 获得属性的set方法                                Method tMethod = tClass.getMethod(tMethodName, tField.getType());                                // 获取字段类型                                String genericType = tField.getGenericType().toString();                                // 字段值                                Object sjxVal = null;                                switch (genericType) &#123;                                    case &quot;class java.lang.String&quot;:                                        sjxVal = sjxStr.trim();                                        break;                                    case &quot;class java.lang.Integer&quot;:                                        sjxVal = Integer.parseInt(sjxStr.trim());                                        break;                                    case &quot;class java.lang.Double&quot;:                                        sjxVal = Double.parseDouble(sjxStr.trim());                                        break;                                    case &quot;class java.util.Date&quot;:                                        // 获取注解的日期格式值                                        JSONField jsonField = tField.getAnnotation(JSONField.class);                                        String datePattern = &quot;yyyy-MM-dd HH:mm:ss&quot;;                                        if (jsonField != null) &#123;                                            datePattern = jsonField.format();                                        &#125;                                        // 日期格式化                                        sjxVal = DateUtil.convertStringToDate(datePattern, sjxStr.trim());                                        break;                                    default:                                        break;                                &#125;                                // 调用set方法，并将值作为参数传入                                tMethod.invoke(target, sjxVal);                            &#125; catch (Exception e) &#123;                                e.printStackTrace();                            &#125;                        &#125;                    &#125;                &#125;                list.add(target);            &#125;        &#125;, List::addAll);    &#125;    /**     * @describe: 下划线转驼峰     * @param: str     * @return: String     * @author: huangyuanli     * @date: 2020/1/16 12:29     **/    public static String underlineToCamel(String str) &#123;        if (str == null || &quot;&quot;.equals(str.trim())) &#123;            return &quot;&quot;;        &#125;        StringBuilder builder = new StringBuilder();        Arrays.asList(str.split(&quot;_&quot;)).forEach(temp -&gt; builder.append(StringUtils.capitalize(temp)));        return builder.toString();    &#125;    public static void main(String[] args) &#123;        String str = &quot;pass_code || start_place || end_place || order_create_time || order_begin_time || order_end_time || traveltype || city || driver_code&quot;;//        String[] split = str.split(&quot;\\\\|\\\\|&quot;);//        for (String s : split) &#123;//            System.out.println(s.trim());//        &#125;//        for (String s : split) &#123;//            System.out.println(underlineToCamel(s.trim()));//        &#125;        Class&lt;?&gt; tClass = DiDiOrder.class;//\t\tField[] declaredFields = tClass.getDeclaredFields();//\t\tfor (Field declaredField : declaredFields) &#123;//\t\t\tSystem.out.println(declaredField.getName());//\t\t\tJSONField annotation = declaredField.getAnnotation(JSONField.class);//            if (annotation != null) &#123;//\t\t\t\tSystem.out.println(annotation.format());//\t\t\t&#125;//\t\t&#125;        List&lt;String&gt; objects = new ArrayList&lt;&gt;();        objects.add(&quot;13888848688 || 出发地1 || 目的地2 || 2019-12-21 09:10:32 || 2019-12-21 09:15:36 || 2019-12-21 09:55:39 || 出租车 || 上海市 || 13616678887&quot;);        objects.add(&quot;13888848688 || 出发地1 || 目的地2 || 2019-12-22 13:10:32 || 2019-12-22 13:15:36 || 2019-12-22 13:55:39 || 出租车 || 上海市 || 13936823456&quot;);        ResolveFeedbackData resolveFeedbackData = new ResolveFeedbackData();        List list = resolveFeedbackData.resolveFbData(tClass, str, objects);        for (Object o : list) &#123;            System.out.println(o.toString());        &#125;    &#125;    static class DiDiOrder extends FbBaseInfo &#123;        String passCode;        String startPlace;        String endPlace;\t\t@JSONField(format = &quot;yyyy-MM-dd HH:mm:ss&quot;)        Date orderCreateTime;\t\t@JSONField(format = &quot;yyyy-MM-dd HH:mm:ss&quot;)        Date orderBeginTime;\t\t@JSONField(format = &quot;yyyy-MM-dd HH:mm:ss&quot;)        Date orderEndTime;        String traveltype;        String city;        String driverCode;        String test;        public String getPassCode() &#123;            return passCode;        &#125;        public void setPassCode(String passCode) &#123;            this.passCode = passCode;        &#125;        public String getStartPlace() &#123;            return startPlace;        &#125;        public void setStartPlace(String startPlace) &#123;            this.startPlace = startPlace;        &#125;        public String getEndPlace() &#123;            return endPlace;        &#125;        public void setEndPlace(String endPlace) &#123;            this.endPlace = endPlace;        &#125;        public Date getOrderCreateTime() &#123;            return orderCreateTime;        &#125;        public void setOrderCreateTime(Date orderCreateTime) &#123;            this.orderCreateTime = orderCreateTime;        &#125;        public Date getOrderBeginTime() &#123;            return orderBeginTime;        &#125;        public void setOrderBeginTime(Date orderBeginTime) &#123;            this.orderBeginTime = orderBeginTime;        &#125;        public Date getOrderEndTime() &#123;            return orderEndTime;        &#125;        public void setOrderEndTime(Date orderEndTime) &#123;            this.orderEndTime = orderEndTime;        &#125;        public String getTraveltype() &#123;            return traveltype;        &#125;        public void setTraveltype(String traveltype) &#123;            this.traveltype = traveltype;        &#125;        public String getCity() &#123;            return city;        &#125;        public void setCity(String city) &#123;            this.city = city;        &#125;        public String getDriverCode() &#123;            return driverCode;        &#125;        public void setDriverCode(String driverCode) &#123;            this.driverCode = driverCode;        &#125;        public String getTest() &#123;            return test;        &#125;        public void setTest(String test) &#123;            this.test = test;        &#125;        @Override        public String toString() &#123;            return &quot;DiDiOrder&#123;&quot; +                    &quot;passCode=&#x27;&quot; + passCode + &#x27;\\&#x27;&#x27; +                    &quot;, startPlace=&#x27;&quot; + startPlace + &#x27;\\&#x27;&#x27; +                    &quot;, endPlace=&#x27;&quot; + endPlace + &#x27;\\&#x27;&#x27; +                    &quot;, orderCreateTime=&quot; + orderCreateTime +                    &quot;, orderBeginTime=&quot; + orderBeginTime +                    &quot;, orderEndTime=&quot; + orderEndTime +                    &quot;, traveltype=&#x27;&quot; + traveltype + &#x27;\\&#x27;&#x27; +                    &quot;, city=&#x27;&quot; + city + &#x27;\\&#x27;&#x27; +                    &quot;, driverCode=&#x27;&quot; + driverCode + &#x27;\\&#x27;&#x27; +                    &quot;, test=&#x27;&quot; + test + &#x27;\\&#x27;&#x27; +                    &#x27;&#125;&#x27;;        &#125;    &#125;&#125;\n\n\n\n日期工具类SimpleDateFormatpackage com.hisign.xzxt2.common.utils;import org.apache.commons.lang.time.DateUtils;import org.apache.commons.logging.Log;import org.apache.commons.logging.LogFactory;import java.text.DateFormat;import java.text.ParseException;import java.text.SimpleDateFormat;import java.util.*;/** * 日期处理共通方法 * * @classname CommonUtils * @author xzxt * @date 2016年7月13日 下午4:23:40 */public class DateUtil extends DateUtils&#123;    /**     * 日志     */    private static Log log = LogFactory.getLog(DateUtil.class);    private static String[] parsePatterns = &#123; &quot;yyyy-MM-dd&quot;, &quot;yyyy-MM-dd HH:mm:ss&quot;, &quot;yyyy-MM-dd HH:mm&quot;,            &quot;yyyy/MM/dd&quot;, &quot;yyyy/MM/dd HH:mm:ss&quot;, &quot;yyyy/MM/dd HH:mm&quot; &#125;;    /**     * 日期格式     */    private static String datePattern = &quot;yyyy-MM-dd&quot;;    /**     * 时间格式     */    private static String timePattern = &quot;HH:mm:ss&quot;;    /**     * 日期时间格式     */    private static String datetimePattern = &quot;yyyy-MM-dd HH:mm:ss&quot;;    /**     * 日期时间格式2     */    private static String datetimePattern2 = &quot;yyyyMMddHHmmss&quot;;    /**     * 中文日期格式     */    private static String datePattern_CN = &quot;yyyy年M月d日&quot;;    /**     * 中文日期时间格式 精确到分     */    private static String datetimePattern_CN = &quot;yyyy年M月d日H时m分&quot;;    /**    * 从message.properties中获取date.default_format对应的日期格式    * 默认日期格式:yyyy-MM-dd    * @author xzxt    * @date 2019/3/12 13:57    * @return 日期格式，默认:yyyy-MM-dd    **/    public static String getDatePattern() &#123;        return datePattern;    &#125;    /**    * Date类型的日期转化成String类型的日期    * 默认日期格式:yyyy-MM-dd    * @author xzxt    * @date 2019/3/12 14:00    * @param aDate 日期    * @return string类型的日期    **/    public static final String getDate(Date aDate) &#123;        SimpleDateFormat df = null;        String returnValue = &quot;&quot;;        if (aDate != null) &#123;            df = new SimpleDateFormat(datePattern);            returnValue = df.format(aDate);        &#125;        return (returnValue);    &#125;    /**    * string类型的日期转化成指定格式Date类型    * @author xzxt    * @date 2019/3/12 14:15    * @param aMask 指定的格式类型    * @param strDate string类型的日期    * @return Date类型的日期    **/    public static final Date convertStringToDate(String aMask, String strDate) throws ParseException &#123;        SimpleDateFormat df = null;        Date date = null;        df = new SimpleDateFormat(aMask);        if (log.isDebugEnabled()) &#123;            // debug状态时打印的日志            log.debug(&quot;converting &#x27;&quot; + strDate + &quot;&#x27; to date with mask &#x27;&quot; + aMask + &quot;&#x27;&quot;);        &#125;        // 日期转化        try &#123;            date = df.parse(strDate);        &#125; catch (ParseException pe) &#123;            throw new ParseException(pe.getMessage(), pe.getErrorOffset());        &#125;        return date;    &#125;    /**    * string类型的日期转化成默认Date类型的日期时间    * 默认格式：yyyy-MM-dd HH:mm:ss    * @author xzxt    * @date 2019/3/12 14:21    * @param strDate 需要转化的日期时间    * @return 默认格式的Date    **/    public static final Date convertStringToDateTime(String strDate) throws ParseException &#123;        SimpleDateFormat df = null;        Date date = null;        df = new SimpleDateFormat(datetimePattern);        if (log.isDebugEnabled()) &#123;            // debug状态时打印的日志            log.debug(&quot;converting &#x27;&quot; + strDate + &quot;&#x27; to date with mask &#x27;&quot; + datetimePattern + &quot;&#x27;&quot;);        &#125;        // 日期时间转化        try &#123;            date = df.parse(strDate);        &#125; catch (ParseException pe) &#123;            // log.error(&quot;ParseException: &quot; + pe);            throw new ParseException(pe.getMessage(), pe.getErrorOffset());        &#125;        return date;    &#125;    /**    * 获取日期时间参数中的时间，返回格式为：HH:mm:ss    * @author xzxt    * @date 2019/3/12 14:27    * @param theTime 日期时间    * @return string类型的时间    **/    public static String getTimeNow(Date theTime) &#123;        return getDateTime(timePattern, theTime);    &#125;    /**    * 获取当前时间日历    * @author xzxt    * @date 2019/3/12 15:17    * @return 当前时间日历    **/    public static Calendar getToday() throws ParseException &#123;        Date today = new Date();        SimpleDateFormat df = new SimpleDateFormat(datePattern);        // This seems like quite a hack (date -&gt; string -&gt; date),        // but it works ;-)        String todayAsString = df.format(today);        Calendar cal = new GregorianCalendar();        cal.setTime(convertStringToDate(todayAsString));        return cal;    &#125;    /**    * Date类型日期时间转化成指定格式的string字符串日期时间    * @author xzxt    * @date 2019/3/12 15:18    * @param aMask 日期格式    * @param aDate 需要转化的日期时间    * @return string字符串日期时间    **/    public static final String getDateTime(String aMask, Date aDate) &#123;        SimpleDateFormat df = null;        String returnValue = &quot;&quot;;        if (aDate == null) &#123;            log.error(&quot;aDate is null!&quot;);        &#125; else &#123;            df = new SimpleDateFormat(aMask);            returnValue = df.format(aDate);        &#125;        return returnValue;    &#125;    /**     * Date类型日期时间转化成默认格式的string字符串日期时间     * 默认格式：yyyy-MM-dd HH:mm:ss     * @author xzxt     * @date 2019/3/12 15:18     * @param aDate 需要转化的日期时间     * @return string字符串日期时间     **/    public static final String getDateTime(Date aDate) &#123;        SimpleDateFormat df = null;        String returnValue = &quot;&quot;;        if (aDate == null) &#123;            log.error(&quot;aDate is null!&quot;);        &#125; else &#123;            df = new SimpleDateFormat(datetimePattern);            returnValue = df.format(aDate);        &#125;        return (returnValue);    &#125;    /**     * Date类型日期时间转化成默认格式的string字符串日期时间     * 默认格式：yyyy-MM-dd     * @author xzxt     * @date 2019/3/12 15:18     * @param aDate 需要转化的日期时间     * @return string字符串日期时间     **/    public static final String convertDateToString(Date aDate) &#123;        return getDateTime(datePattern, aDate);    &#125;    /**     * Date类型日期转化成指定格式的string字符串日期     * @author xzxt     * @date 2019/3/12 15:18     * @param pattern 日期格式     * @param aDate 需要转化的日期时间     * @return string字符串日期时间     **/    public static final String convertDateToString(String pattern, Date aDate) &#123;        return getDateTime(pattern, aDate);    &#125;    /**     * string字符串日期转化成默认格式的Date类型日期     * 默认格式：yyyy-MM-dd     * @author xzxt     * @date 2019/3/12 15:18     * @param strDate 需要转化的日期     * @return Date类型日期     **/    public static Date convertStringToDate(String strDate) throws ParseException &#123;        Date aDate = null;        try &#123;            if (log.isDebugEnabled()) &#123;                log.debug(&quot;converting date with pattern: &quot; + datePattern);            &#125;            aDate = convertStringToDate(datePattern, strDate);        &#125; catch (ParseException pe) &#123;            log.error(&quot;Could not convert &#x27;&quot; + strDate + &quot;&#x27; to a date, throwing exception&quot;);            throw new ParseException(pe.getMessage(), pe.getErrorOffset());        &#125;        return aDate;    &#125;    /**    * 日期类型时间比较，如果date1&gt;date2 则返回1，相等放回0，小于返回-1    * @author xzxt    * @date 2019/3/12 15:29    * @param date1 日期1    * @param date2 日期2    * @return date1&gt;date2 则返回1，相等放回0，小于返回-1    **/    public static int compareDate(Date date1, Date date2) &#123;        String d1 = getDateTime(datePattern, date1);        String d2 = getDateTime(datePattern, date2);        if (d1 == null &amp;&amp; d2 != null) &#123;            return -1;        &#125; else if (d1 != null &amp;&amp; d2 == null) &#123;            return 1;        &#125; else if (d1 == null &amp;&amp; d2 == null) &#123;            return 0;        &#125; else &#123;            return d1.compareTo(d2);        &#125;    &#125;    /**    * 日期时间转化成中文的日期时间字符串，默认格式：yyy年M月d日H时m分    * @author xzxt    * @date 2019/3/12 15:32    * @param date Date类型时间    * @return 中文的日期时间字符串    **/    public static String convertDatetimeToChineseString(Date date) &#123;        DateFormat df = new SimpleDateFormat(datetimePattern_CN);        String strDate = df.format(date);        return strDate;    &#125;    /**     * 日期转化成中文的日期字符串，默认格式：yyy年M月d日     * @author xzxt     * @date 2019/3/12 15:32     * @param date Date类型时间     * @return 中文的日期时间字符串     **/    public static String convertDateToChineseString(Date date) &#123;        DateFormat df = new SimpleDateFormat(datePattern_CN);        String strDate = df.format(date);        return strDate;    &#125;    /**     * 计算2个时间的差     *     * @author xzxt     * @param endDate 结束时间     * @param beginDate 开始时间     * @return Integer类型的天数    **/    public static Integer getUnm(Date endDate, Date beginDate) &#123;        Integer a = 0;        try &#123;            Long days = (endDate.getTime() - beginDate.getTime()) / (24 * 60 * 60 * 1000) + 1;            a = days.intValue();        &#125; catch (Exception e) &#123;            log.error(e.getMessage());            a = 0;        &#125;        return a;    &#125;    /**    * string类型日期时间转化成默认格式的Date类型日期    * 默认格式：yyyy-MM-dd    * @author xzxt    * @date 2019/3/12 15:40    * @param time 转 date yyyy-dd-mm    * @return Date类型日期    **/    public static Date strToDate(String time) &#123;        SimpleDateFormat sdf = new SimpleDateFormat(datePattern);        Date dt = null;        try &#123;            dt = sdf.parse(time);        &#125; catch (Exception ex) &#123;            log.error(ex.getMessage());        &#125;        return dt;    &#125;    /**     * Date类型日期转化成指定格式的string字符串日期     * 默认格式：yyyyMMddHHmmss     * @author xzxt     * @date 2019/3/12 15:18     * @param aDate 需要转化的日期时间     * @return string字符串日期时间     */    public static final String convertDateToString2(Date aDate) &#123;        return getDateTime(datetimePattern2, aDate);    &#125;    /**    * 按照yyyy-MM-dd HH:mm:ss的格式，日期转字符串    * @author xzxt    * @date 2019/3/12 15:54    * @param date Date类型日期时间    * @return String类型的日期时间    **/    public static String date2Str(Date date) &#123;        return date2Str(date, datetimePattern);    &#125;    /**    * 按照参数format的格式，日期转字符串    * @author xzxt    * @date 2019/3/12 15:57    * @param date Date类型日期    * @param format 日期格式    * @return String类型的时间    **/    public static String date2Str(Date date, String format) &#123;        if (date != null) &#123;            SimpleDateFormat sdf = new SimpleDateFormat(format);            return sdf.format(date);        &#125; else &#123;            return &quot;&quot;;        &#125;    &#125;    /**    * Object类型日期型转化为Date类型日期，自动适配字符串格式    * 格式：&#123; &quot;yyyy-MM-dd&quot;, &quot;yyyy-MM-dd HH:mm:ss&quot;, &quot;yyyy-MM-dd HH:mm&quot;, &quot;yyyy/MM/dd&quot;, &quot;yyyy/MM/dd HH:mm:ss&quot;, &quot;yyyy/MM/dd HH:mm&quot; &#125;    * @author xzxt    * @date 2019/3/12 15:58    * @param str Object类型的时间    * @return Date类型日期    **/    public static Date parseDate(Object str) &#123;        if (str == null)&#123;            return null;        &#125;        try &#123;            return parseDate(str.toString(), parsePatterns);        &#125; catch (ParseException e) &#123;            return null;        &#125;    &#125;    /**    * 日期加1天    * @author xzxt    * @date 2019/3/12 16:06    * @param day Date类型日期    * @return Date类型日期    **/    public static Date toNextDay(Date day) &#123;        Calendar calendar = new GregorianCalendar();        try &#123;            Date date = convertStringToDate(convertDateToString(day));            calendar.setTime(date);        &#125; catch (ParseException e) &#123;            e.printStackTrace();        &#125;        // 日期加1天        calendar.add(calendar.DATE, 1);        return calendar.getTime();    &#125;    /**     * 获取相对当前的日期几天的日期     * @author xzxt     * @date 2018/11/22 15:13     * @param date 时间     * @param day int类型，可为负数     * @return 相对当前的日期几天的日期     */    public static Date getRelativeDate(Date date, int day) &#123;        Calendar cal = Calendar.getInstance();        cal.setTime(date);        cal.set(Calendar.DAY_OF_YEAR, cal.get(Calendar.DAY_OF_YEAR) + day);        return cal.getTime();    &#125;&#125;\n\n\n\nDateTimeFormatterimport org.apache.commons.lang3.StringUtils;import java.time.LocalDate;import java.time.LocalDateTime;import java.time.format.DateTimeFormatter;/** * 日期格式化工具类扩展 * * @author huangyuanli * @className DateUtils * @package com.hisign.xzxt2.hxgc.clhx.utils * @date 2021/8/31 11:40 **/public class DateUtils &#123;    /**     * 日期格式     */    private static String datePattern = &quot;yyyy-MM-dd&quot;;    /**     * 日期格式     */    private static String datePattern2 = &quot;yyyyMMdd&quot;;    /**     * 时间格式     */    private static String timePattern = &quot;HH:mm:ss&quot;;    /**     * 日期时间格式     */    private static String datetimePattern = &quot;yyyy-MM-dd HH:mm:ss&quot;;    /**     * 日期时间格式2     */    private static String datetimePattern2 = &quot;yyyyMMddHHmmss&quot;;    /**     * 中文日期格式     */    private static String datePattern_CN = &quot;yyyy年M月d日&quot;;    /**     * 中文日期时间格式 精确到分     */    private static String datetimePattern_CN = &quot;yyyy年M月d日H时m分&quot;;    /**     * 将日期字符串转成指定格式     * @param datetime 日期字符串     * @param srcPattern 源格式，就是传入日期字符串的格式     * @param targetPattern 目标格式     * @return 目标字符串     */    public static String convertDate(String datetime, String srcPattern, String targetPattern) &#123;        if (StringUtils.isEmpty(datetime)) &#123;            return &quot;&quot;;        &#125;        DateTimeFormatter dtf = DateTimeFormatter.ofPattern(srcPattern);        LocalDate ld = LocalDate.parse(datetime, dtf);        DateTimeFormatter fa = DateTimeFormatter.ofPattern(targetPattern);        return ld.format(fa);    &#125;    /**     * 将时间字符串转成指定格式     * @param datetime 时间字符串     * @param srcPattern 源格式，就是传入时间字符串的格式     * @param targetPattern 目标格式     * @return 目标字符串     */    public static String convertDateTime(String datetime, String srcPattern, String targetPattern) &#123;        if (StringUtils.isEmpty(datetime)) &#123;            return &quot;&quot;;        &#125;        DateTimeFormatter dtf = DateTimeFormatter.ofPattern(srcPattern);        LocalDateTime ld = LocalDateTime.parse(datetime, dtf);        DateTimeFormatter fa = DateTimeFormatter.ofPattern(targetPattern);        return ld.format(fa);    &#125;    public static void main(String[] args) &#123;        String d = convertDate(&quot;19370707&quot;, datePattern2, datePattern);        System.out.println(d);        String dt = convertDateTime(&quot;19370707080925&quot;, datetimePattern2, datetimePattern);        System.out.println(dt);        String dt2 = convertDateTime(&quot;1937-07-07 08:09:25&quot;, datetimePattern, datetimePattern_CN);        System.out.println(dt2);    &#125;&#125;\n\n","categories":["其他"],"tags":["代码片段"]},{"title":"hadoop入门笔记","url":"/%E5%A4%A7%E6%95%B0%E6%8D%AE/hadoop/Hadoop%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0/","content":"环境准备配置静态ipvim /etc/sysconfig/network-scripts/ifcfg-ens32\n\nifcfg-ens32\n# 网络类型为以太网TYPE=Ethernet# 设置固定ip，dhcp 改为 static# BOOTPROTU=dhcpBOOTPROTU=static# 网卡设备名，一定要跟文件名一致DEVICE=ens32# 网卡设备名，一定要跟文件名一致NAME=ens32# 设定网卡随网络服务启动# ONBOOT=noONBOOT=yes# 固定ipIPADDR=192.168.40.91# 网关GATEWAY=192.168.40.254# 子网掩码NETMASK=255.255.255.0# DNS地址DNS1=8.8.8.8DNS2=114.114.114.114\n\n重启网络服务，使生效\n# 重启网络服务service network restart\n\n\n\n修改主机名vim /etc/hostname\n\nhostname\nhadoop91  # reboot重启生效\n\n\n\n修改hosts文件vim /etc/hosts\n\nhosts\n# ip要和网卡配置中的静态ip一致，域名要和hosts文件中的主机名一致192.168.40.91 hadoop91192.168.40.92 hadoop92192.168.40.93 hadoop93\n\n重启网络服务，使生效\n# 重启网络服务service network restart\n\n\n\n关闭防火墙# 关闭防火墙service iptables stop# 禁用防火墙，开机自启关闭chkconfig iptables off# 查看防火墙状态service iptables status# 查看开机自启列表chkconfig --list iptables\n\n在关闭防火墙到时候，出现：\nRedirecting to /bin/systemctl stop  iptables.serviceFailed to stop iptables.service: Unit iptables.service not loaded.\n\n解决方法：\ncentos7开始默认用的是firewalld，这个是基于iptables的，虽然有iptables的核心，但是iptables的服务是没安装的。所以你只要停止firewalld服务即可：  \n# 安装防火墙yum install firewalld firewall-config# 停止防火墙sudo systemctl stop firewalld# 禁用防火墙，开机自启关闭sudo systemctl disable firewalld\n\n\n\n创建用户# 添加用户useradd hisign# 设置密码passwd hisign\n\n\n\n配置用户root权限修改/etc/sudoers \n# 用户 haung 可以不用密码使用sudohisign    ALL=(ALL)    NOPASSWD: ALL\n\n该文件为root用户的只读文件，可以在root用户修改完后强制保存\n# ESC后，:wq! 强制保存:wq!\n\n\n\n创建文件夹创建文件夹/opt/software、/opt/module用于存放安装包和安装软件\nsudo mkdir /opt/software /opt/module\n\n修改文件夹所有者\nsudo chown hisign:hisign /opt/software /opt/module\n\n\n\n安装jdk首先到官网上下载你想要的jdk\n# 进入目录cd /opt/software# 解压到指定目录tar -zxvf jdk-8u144-linux-x64.tar.gz -C /opt/module\n\n配置环境变量\nsudo vim /etc/profile\n\n输入大写的  G  跳转到文件末尾，在最后面添加：\n# JAVA_HOMEexport JAVA_HOME=/opt/module/jdk1.8.0_144export PATH=$PATH:$JAVA_HOME/bin\n\n执行profile文件\nsource /etc/profile\n\n这样可以使配置不用重启即可立即生效。\n检查新安装的jdk\njava -version\n\n显示：\njava version &quot;1.8.0_144&quot;Java(TM) SE Runtime Environment (build 1.8.0_144-b01)Java HotSpot(TM) 64-Bit Server VM (build 25.144-b01, mixed mode)\n\n\n\n\n\n安装hadoophadoop历史版本下载地址\nhttps://archive.apache.org/dist/hadoop/common/\n# 进入目录cd /opt/software# 解压到指定目录tar -zxvf hadoop-2.7.2.tar.gz -C /opt/module\n\n配置环境变量\nsudo vim /etc/profile\n\n输入大写的  G  跳转到文件末尾，在最后面添加：\n# HADOOP_HOMEexport HADOOP_HOME=/opt/module/hadoop-2.7.2export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin\n\n执行profile文件\nsource /etc/profile\n\n这样可以使配置不用重启即可立即生效。\n检查新安装的jdk\nhadoop version\n\n到此安装结束\nhadoop目录结构\ndrwxr-xr-x. 2 hisign hisign   194 5月  22 2017 bindrwxr-xr-x. 3 hisign hisign    20 5月  22 2017 etcdrwxr-xr-x. 2 hisign hisign   106 5月  22 2017 includedrwxr-xr-x. 3 hisign hisign    20 5月  22 2017 libdrwxr-xr-x. 2 hisign hisign   239 5月  22 2017 libexec-rw-r--r--. 1 hisign hisign 15429 5月  22 2017 LICENSE.txt-rw-r--r--. 1 hisign hisign   91 5月  22 2017 NOTICE.txt-rw-r--r--. 1 hisign hisign  1366 5月  22 2017 README.txtdrwxr-xr-x. 2 hisign hisign  4096 5月  22 2017 sbindrwxr-xr-x. 4 hisign hisign    31 5月  22 2017 share\n\n重要目录\n\nbin目录：存放对Hadoop相关服务（HDFS,YARN）进行操作的脚本etc目录：Hadoop的配置文件目录，存放Hadoop的配置文件lib目录：存放Hadoop的本地库（对数据进行压缩解压缩功能）sbin目录：存放启动或停止Hadoop相关服务的脚本share目录：存放Hadoop的依赖jar包、文档、和官方案例\n\nhadoop运行模式本地运行模式官方Grep案例\n在hadoop-2.7.2文件下面创建一个input文件夹\n\nmkdir input\n\n\n将Hadoop的xml配置文件复制到input\n\ncp etc/hadoop/*.xml input\n\n\n执行share目录下的MapReduce程序\n\nbin/hadoop jar \\share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar \\grep input output &#x27;dfs[a-z.]+&#x27;\n\n\n查看输出结果  \n\ncat output/*\n\n显示\n1  dfsadmin\n\n\n\n官方WordCount案例\n在hadoop-2.7.2文件下面创建一个wcinput文件夹\n\nmkdir wcinput\n\n\n在wcinput文件下创建一个wc.input文件  \n\ntouch wcinput/wc.input\n\n\n编辑wc.input文件  \n\nvi wcinput/wc.input\n\n在文件中添加以下内容\nhadoop yarnhadoop mapreduceatguiguatguigu\n\n\n执行share目录下的MapReduce程序\n\nbin/hadoop jar \\share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar \\wordcount \\wcinput \\wcoutput\n\n\n查看输出结果  \n\ncat wcoutput/*\n\n显示\natguigu 2hadoop  2mapreduce       1yarn    1\n\n\n\n\n\n伪分布式运行模式启动HDFS并运行程序配置集群\n配置 hadoop-env.sh\n\nvim etc/hadoop/hadoop-env.sh\n\nhadoop-env.sh\nexport JAVA_HOME=/opt/module/jdk1.8.0_144\n\n\n配置 core-site.xml\n\nvim etc/hadoop/core-site.xml\n\ncore-site.xml\n&lt;configuration&gt;    &lt;!-- 指定HDFS中NameNode的地址 --&gt;    &lt;property&gt;        &lt;name&gt;fs.defaultFS&lt;/name&gt;        &lt;value&gt;hdfs://hadoop91:9000&lt;/value&gt;    &lt;/property&gt;    &lt;!-- 指定Hadoop运行时产生文件的存储目录 --&gt;    &lt;property&gt;        &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;        &lt;value&gt;/opt/module/hadoop-2.7.2/data/tmp&lt;/value&gt;    &lt;/property&gt;&lt;/configuration&gt;\n\n\n配置 hdfs-site.xml\n\nvim etc/hadoop/hdfs-site.xml\n\nhdfs-site.xml\n&lt;configuration&gt;    &lt;!-- 指定HDFS副本的数量 --&gt;    &lt;property&gt;        &lt;name&gt;dfs.replication&lt;/name&gt;        &lt;value&gt;1&lt;/value&gt;    &lt;/property&gt;&lt;/configuration&gt;\n\n\n\n启动集群\n格式化NameNode（第一次启动时格式化，以后就不要总格式化）  \n\nbin/hdfs namenode -format\n\n\n启动NameNode\n\nsbin/hadoop-daemon.sh start namenode\n\n\n启动DataNode\n\nsbin/hadoop-daemon.sh start datanode\n\n\n\n查看集群查看是否启动成功\n[hisign@hadoop91 hadoop-2.7.2]$ jps2807 NameNode3098 Jps2892 DataNode\n\n注意：jps是JDK中的命令，不是Linux命令。不安装JDK不能使用jps\nweb端查看HDFS文件系统\nhttp://hadoop91:50070/dfshealth.html#tab-datanode\n如果能看，看hosts文件是否配置hadoop91\n查看产生的Log日志\n说明：在企业中遇到Bug时，经常根据日志提示信息去分析问题、解决Bug。\nls opt/module/hadoop-2.7.2/logs\n\n\n\n思考：为什么不能一直格式化NameNode，格式化NameNode，要注意什么？\n注意：格式化NameNode，会产生新的集群id,导致NameNode和DataNode的集群id不一致，集群找不到已往数据。所以，格式NameNode时，一定要先删除data数据和log日志，然后再格式化NameNode。\n操作集群\n在HDFS文件系统上创建一个input文件夹\n\nbin/hdfs dfs -mkdir -p /user/hisign/input\n\n\n将测试文件内容上传到文件系统上\n\nbin/hdfs dfs -put wcinput/wc.input /user/hisign/input/\n\n\n查看上传的文件是否正确\n\nbin/hdfs dfs -ls  /user/hisign/input/bin/hdfs dfs -cat  /user/hisign/input/wc.input\n\n\n运行MapReduce程序  \n\nbin/hadoop jar \\share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar \\wordcount \\/user/hisign/input/ \\/user/hisign/output\n\n\n查看输出结果\n\nbin/hdfs dfs -cat /user/hisign/output/*\n\n显示\natguigu 2hadoop  2mapreduce       1yarn    1\n\n\n将测试文件内容下载到本地\n\nbin/hdfs dfs -get /user/hisign/output/part-r-00000 ./wcoutput/\n\n\n删除输出结果\n\nbin/hdfs dfs -rm -r /user/hisign/output\n\n\n\n\n\n启动YARN并运行程序配置集群\n配置 yarn-env.sh\n\nvim etc/hadoop/yarn-env.sh\n\nyarn-env.sh\nexport JAVA_HOME=/opt/module/jdk1.8.0_144\n\n\n配置 yarn-site.xml\n\nvim etc/hadoop/yarn-site.xml\n\nyarn-site.xml\n&lt;configuration&gt;    &lt;!-- Reducer获取数据的方式 --&gt;    &lt;property&gt;        &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;        &lt;value&gt;mapreduce_shuffle&lt;/value&gt;    &lt;/property&gt;    &lt;!-- 指定YARN的ResourceManager的地址 --&gt;    &lt;property&gt;        &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;        &lt;value&gt;hadoop91&lt;/value&gt;    &lt;/property&gt;&lt;/configuration&gt;\n\n\n配置 mapred-env.sh\n\nvim etc/hadoop/mapred-env.sh\n\nmapred-env.sh\nexport JAVA_HOME=/opt/module/jdk1.8.0_144\n\n\n配置 mapred-site.xml\n\ncp etc/hadoop/mapred-site.xml.template etc/hadoop/mapred-site.xmlvim etc/hadoop/mapred-site.xml\n\nmapred-site.xml\n&lt;configuration&gt;    &lt;!-- 指定MR运行在YARN上 --&gt;    &lt;property&gt;        &lt;name&gt;mapreduce.framework.name&lt;/name&gt;        &lt;value&gt;yarn&lt;/value&gt;    &lt;/property&gt;&lt;/configuration&gt;\n\n\n\n启动集群\n启动前必须保证NameNode和DataNode已经启动\n\n# 查看是否启动jps2807 NameNode8217 Jps2892 DataNode# 启动 NameNodesbin/hadoop-daemon.sh start namenode# 启动 DataNodesbin/hadoop-daemon.sh start datanode\n\n\n启动ResourceManager\n\nsbin/yarn-daemon.sh start resourcemanager\n\n\n启动NodeManager\n\nsbin/yarn-daemon.sh start nodemanager\n\n\n\n操作集群\nYARN浏览器查看页面\n\nhttp://hadoop91:8088/cluster\n\n删除HDFS文件系统上的output目录\n\nbin/hdfs dfs -rm -R /user/hisign/output\n\n\n执行MapReduce程序\n\nbin/hadoop jar \\share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar \\wordcount \\/user/hisign/input  \\/user/hisign/output\n\n\n查看运行结果\n\nbin/hdfs dfs -cat /user/hisign/output/*\n\n显示\natguigu 2hadoop  2mapreduce       1yarn    1\n\n\n\n配置历史服务器为了查看程序的历史运行情况，需要配置一下历史服务器。具体配置步骤如下\n\n配置 mapred-site.xml\n\nvim etc/hadoop/mapred-site.xml\n\nmapred-site.xml\n&lt;configuration&gt;\t&lt;!-- 历史服务器端地址 --&gt;    &lt;property&gt;        &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;        &lt;value&gt;hadoop91:10020&lt;/value&gt;    &lt;/property&gt;    &lt;!-- 历史服务器web端地址 --&gt;    &lt;property&gt;        &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;        &lt;value&gt;hadoop91:19888&lt;/value&gt;    &lt;/property&gt;&lt;/configuration&gt;\n\n\n启动历史服务器\n\nsbin/mr-jobhistory-daemon.sh start historyserver\n\n\n查看历史服务器是否启动\n\njps\n\n\n查看JobHistory\n\nhttp://hadoop91:19888/jobhistory\n配置日志的聚集日志聚集概念：应用运行完成以后，将程序运行日志信息上传到HDFS系统上。\n日志聚集功能好处：可以方便的查看到程序运行详情，方便开发调试。\n注意：开启日志聚集功能，需要重新启动NodeManager 、ResourceManager和HistoryServer。\n开启日志聚集功能具体步骤如下：\n\n配置 yarn-site.xml\n\nvim etc/hadoop/yarn-site.xml\n\nyarn-site.xml\n&lt;configuration&gt;    &lt;!-- 日志聚集功能开启 --&gt;    &lt;property&gt;        &lt;name&gt;yarn.log-aggregation-enable&lt;/name&gt;        &lt;value&gt;true&lt;/value&gt;    &lt;/property&gt;    &lt;!-- 日志保留时间设置7天 --&gt;    &lt;property&gt;        &lt;name&gt;yarn.log-aggregation.retain-seconds&lt;/name&gt;        &lt;value&gt;604800&lt;/value&gt;    &lt;/property&gt;&lt;/configuration&gt;\n\n\n关闭NodeManager 、ResourceManager和HistoryServer\n\nsbin/yarn-daemon.sh stop resourcemanagersbin/yarn-daemon.sh stop nodemanagersbin/mr-jobhistory-daemon.sh stop historyserver\n\n\n启动NodeManager 、ResourceManager和HistoryServer\n\nsbin/yarn-daemon.sh start resourcemanagersbin/yarn-daemon.sh start nodemanagersbin/mr-jobhistory-daemon.sh start historyserver\n\n\n删除HDFS上已经存在的输出文件\n\nbin/hdfs dfs -rm -R /user/hisign/output\n\n\n执行WordCount程序\n\nbin/hadoop jar \\share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar \\wordcount \\/user/hisign/input \\/user/hisign/output\n\n\n查看日志\n\nhttp://hadoop91:19888/jobhistory\n完全分布式运行模式虚拟机准备vmware中的完整克隆是基于指定的虚拟机克隆出相同的一份出来，不必再安装。但是我们要保证三个地方不能一样，一个是主机名称（hostname），还有一个是ip地址，所以我们在克隆后要对这三个地方进行修改。这里以centos为例\n# 修改主机名vim /etc/hostname########################### hadoop91hadoop92# 修改静态ipvim /etc/sysconfig/network-scripts/ifcfg-ens32########################### 修改静态ip# IPADDR=192.168.40.91IPADDR=192.168.40.92\n\n重启生效\nreboot\n\n\n\n\n\n集群分布脚本scp 安全拷贝\n定义：\n\n\nscp可以实现服务器与服务器之间的数据拷贝。（from server1 to server2）\n\n基本语法\n#命令 递归  要拷贝的文件路径/名称  目的用户@主机:目的路径/名称scp   -r   $pdir/$fname          $user@hadoop$host:$pdir/$fname\n\n\n案例\n\n1、在hadoop91上，将hadoop91中/opt/module目录下的软件拷贝到远程服务器hadoop92上。\n[hisign@hadoop91 /]$ scp -r /opt/module root@hadoop92:/opt/module\n\n\n\n2、在hadoop93上，将远程服务器hadoop91服务器上的/opt/module目录下的软件拷贝到本地。\n[hisign@hadoop93 opt]$sudo scp -r hisign@hadoop91:/opt/module /opt/module\n\n\n\n3、在hadoop93上操作将hadoop91中/opt/module目录下的软件拷贝到hadoop94上。\n[hisign@hadoop93 opt]$ scp -r hisign@hadoop91:/opt/module root@hadoop94:/opt/module\n\n注意：拷贝过来的/opt/module目录，别忘了在hadoop92、hadoop93、hadoop94上修改所有文件的，所有者和所有者组。\nsudo chown hisign:hisign -R /opt/module\n\n\n\n4、将hadoop91中/etc/profile文件拷贝到hadoop92的/etc/profile上。\n[hisign@hadoop91 ~]$ sudo scp /etc/profile root@hadoop92:/etc/profile\n\n\n\n5、将hadoop91中/etc/profile文件拷贝到hadoop93的/etc/profile上。\n[hisign@hadoop91 ~]$ sudo scp /etc/profile root@hadoop93:/etc/profile\n\n\n\n6、将hadoop91中/etc/profile文件拷贝到hadoop94的/etc/profile上。\n[hisign@hadoop91 ~]$ sudo scp /etc/profile root@hadoop94:/etc/profile\n\n注意：拷贝过来的配置文件别忘了 source /etc/profile 使生效。\nrsync 远程同步工具rsync主要用于备份和镜像。具有速度快、避免复制相同内容和支持符号链接的优点。\nrsync和scp区别：用rsync做文件的复制要比scp的速度快，rsync只对差异文件做更新。scp是把所有文件都复制过去。\n\n基本语法\n\n# 命令 选项参数  要拷贝的文件路径/名称  目的用户@主机:目的路径/名称rsync   -av     $pdir/$fname         $user@hadoop$host:$pdir/$fname\n\n\n案例\n\n把hadoop91机器上的/opt/software目录同步到hadoop92服务器的root用户下的/opt/目录\nrsync -av /opt/software/ hadoop92:/opt/software\n\n\n\nxsync 集群分布脚本1、需求：循环复制文件到所有节点的相同目录下\n2、需求分析：\n\nrsync命令原始拷贝：\n\nrsync -av   /opt/module        root@hadoop93:/opt/\n\n\n\n\n期望脚本：\n\nxsync 要同步的文件名称\n\n\n\n\n说明：在/home/hisign/bin这个目录下存放的脚本，hisign用户可以在系统任何地方直接执行。\n\n3、脚本实现\n在/home/hisign目录下创建bin目录，并在bin目录下xsync创建文件，文件内容如下：\nmkdir -p  /home/hisign/bincd /home/hisign/bin# 新建脚本vim xsync\n\n\n\n在该文件中编写如下代码\n#!/bin/bash#1 获取输入参数个数，如果没有参数，直接退出pcount=$#if ((pcount==0)); thenecho no args;exit;fi#2 获取文件名称p1=$1fname=`basename $p1`echo fname=$fname#3 获取上级目录到绝对路径pdir=`cd -P $(dirname $p1); pwd`echo pdir=$pdir#4 获取当前用户名称user=`whoami`#5 循环for((host=91; host&lt;94; host++)); do    echo ------------------- hadoop$host --------------    rsync -av $pdir/$fname $user@hadoop$host:$pdirdone\n\n\n\n\n修改脚本 xsync 具有执行权限\n\nchmod 777 xsync\n\n\n\n\n调用脚本形式：xsync 文件名称\n\nxsync /home/hisign/bin\n\n注意：如果将xsync放到/home/hisign/bin目录下仍然不能实现全局使用，可以将xsync移动到/usr/local/bin目录下。\nsudo mv /home/hisign/bin/xsync /usr/local/bin\n\n\n\n集群配置集群部署规划\n\n\n\nhadoop91\nhadoop92\nhadoop93\n\n\n\nHDFS\nNameNode  DataNode\nDataNode\nSecondaryNameNode  DataNode\n\n\nYARN\nNodeManager\nResourceManager  NodeManager\nNodeManager\n\n\n配置集群核心配置文件配置core-site.xml\n[hisign@hadoop91 /]$ cd /opt/module/hadoop-2.7.2/etc/hadoop[hisign@hadoop91 hadoop]$ vi core-site.xml\n\n\n\n在该文件中编写如下配置\n&lt;configuration&gt;    &lt;!-- 指定HDFS中NameNode的地址 --&gt;    &lt;property&gt;        &lt;name&gt;fs.defaultFS&lt;/name&gt;        &lt;value&gt;hdfs://hadoop91:9000&lt;/value&gt;    &lt;/property&gt;    &lt;!-- 指定Hadoop运行时产生文件的存储目录 --&gt;    &lt;property&gt;        &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;        &lt;value&gt;/opt/module/hadoop-2.7.2/data/tmp&lt;/value&gt;    &lt;/property&gt;&lt;/configuration&gt;\n\nHDFS配置文件配置hadoop-env.sh\n[hisign@hadoop91 hadoop]$ vi hadoop-env.sh\n\nhadoop-env.sh\nexport JAVA_HOME=/opt/module/jdk1.8.0_144\n\n\n\n配置hdfs-site.xml\n[hisign@hadoop91 hadoop]$ vi hdfs-site.xml\n\n在该文件中编写如下配置\n&lt;configuration&gt;    &lt;!-- 指定HDFS副本的数量 --&gt;    &lt;property&gt;        &lt;name&gt;dfs.replication&lt;/name&gt;        &lt;value&gt;3&lt;/value&gt;    &lt;/property&gt;    &lt;!-- 指定Hadoop辅助名称节点主机配置 --&gt;    &lt;property&gt;          &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;          &lt;value&gt;hadoop93:50090&lt;/value&gt;    &lt;/property&gt;&lt;/configuration&gt;\n\n\n\nYARN配置文件配置yarn-env.sh\n[hisign@hadoop91 hadoop]$ vi yarn-env.sh\n\nyarn-env.sh\nexport JAVA_HOME=/opt/module/jdk1.8.0_144\n\n\n\n配置yarn-site.xml\n[hisign@hadoop91 hadoop]$ vi yarn-site.xml\n\n在该文件中增加如下配置\n&lt;configuration&gt;    &lt;!-- Reducer获取数据的方式 --&gt;    &lt;property&gt;        &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;        &lt;value&gt;mapreduce_shuffle&lt;/value&gt;    &lt;/property&gt;    &lt;!-- 指定YARN的ResourceManager的地址 --&gt;    &lt;property&gt;        &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;        &lt;value&gt;hadoop92&lt;/value&gt;    &lt;/property&gt;&lt;/configuration&gt;\n\n\n\nMapReduce配置文件配置mapred-env.sh\n[hisign@hadoop91 hadoop]$ vi mapred-env.sh\n\nmapred-env.sh\nexport JAVA_HOME=/opt/module/jdk1.8.0_144\n\n\n\n配置mapred-site.xml\n[hisign@hadoop91 hadoop]$ cp mapred-site.xml.template mapred-site.xml[hisign@hadoop91 hadoop]$ vi mapred-site.xml\n\n在该文件中增加如下配置\n&lt;configuration&gt;    &lt;!-- 指定MR运行在YARN上 --&gt;    &lt;property&gt;        &lt;name&gt;mapreduce.framework.name&lt;/name&gt;        &lt;value&gt;yarn&lt;/value&gt;    &lt;/property&gt;&lt;/configuration&gt;\n\n\n\n在集群上分发配置好的Hadoop配置文件\nxsync /opt/module/hadoop-2.7.2/\n\n\n\n查看文件分发情况\ncat /opt/module/hadoop-2.7.2/etc/hadoop/core-site.xmlcat /opt/module/hadoop-2.7.2/etc/hadoop/hdfs-site.xmlcat /opt/module/hadoop-2.7.2/etc/hadoop/yarn-site.xmlcat /opt/module/hadoop-2.7.2/etc/hadoop/mapred-site.xml\n\n\n\n集群单点启动如果集群是第一次启动，需要格式化NameNode\n[hisign@hadoop91 hadoop-2.7.2]$ hdfs namenode -format\n\n\n\n在hadoop91上启动NameNode\n[hisign@hadoop91 hadoop-2.7.2]$ hadoop-daemon.sh start namenode[hisign@hadoop91 hadoop-2.7.2]$ jps\n\n显示\n14849 Jps14782 NameNode\n\n\n\n在hadoop91、hadoop92以及hadoop93上分别启动DataNode\n[hisign@hadoop91 hadoop-2.7.2]$ hadoop-daemon.sh start datanode[hisign@hadoop91 hadoop-2.7.2]$ jps\n\n显示\n14936 Jps14873 DataNode14782 NameNode\n\n\n\n[hisign@hadoop92 hadoop-2.7.2]$ hadoop-daemon.sh start datanode[hisign@hadoop92 hadoop-2.7.2]$ jps\n\n显示\n14013 DataNode14045 Jps\n\n\n\n[hisign@hadoop93 hadoop-2.7.2]$ hadoop-daemon.sh start datanode[hisign@hadoop93 hadoop-2.7.2]$ jps\n\n显示\n13739 DataNode13774 Jps\n\n\n\n思考：每次都一个一个节点启动，如果节点数增加到1000个怎么办？\n早上来了开始一个一个节点启动，到晚上下班刚好完成，下班？\nSSH免密登录原理：\nhttps://www.cnblogs.com/haojun/p/11131432.html\n 工作原理如下图所示：\n\n生成公钥和私钥：\n[hisign@hadoop91 /]$ ssh-keygen -t rsa\n\n然后敲（三个回车），就会生成两个文件id_rsa（私钥）、id_rsa.pub（公钥）\n[hisign@hadoop91 /]$ cd ~/.ssh/[hisign@hadoop91 .ssh]$ ll\n\n显示\n总用量 12-rw-------. 1 hisign hisign 1675 11月  9 09:58 id_rsa-rw-r--r--. 1 hisign hisign  397 11月  9 09:58 id_rsa.pub-rw-r--r--. 1 hisign hisign  372 11月  9 09:15 known_hosts\n\n\n\n将公钥拷贝到要免密登录的目标机器上\nssh-copy-id可以把本地主机的公钥复制到远程主机的authorized_keys文件上，ssh-copy-id命令也会给远程主机的用户主目录（home）和~/.ssh, 和~/.ssh/authorized_keys设置合适的权限。\n# 给用户hisign配置免密登录[hisign@hadoop91 .ssh]$ ssh-copy-id hadoop91[hisign@hadoop91 .ssh]$ ssh-copy-id hadoop92[hisign@hadoop91 .ssh]$ ssh-copy-id hadoop93\n\n注意：在hadoop92和hadoop93上把上面的操作都再执行一遍，三台服务器就能互相之间进行免密登录了。如果想要其他用户也能进行免密登录，切换到其他用户执行上操作即可。\n群起集群配置slaves[hisign@hadoop91 /]$ cd /opt/module/hadoop-2.7.2/etc/hadoop[hisign@hadoop91 hadoop]$ vim slaves\n\n在该文件中增加如下内容：\nhadoop91hadoop92hadoop93\n\n注意：该文件中添加的内容结尾不允许有空格，文件中不允许有空行。\n同步所有节点配置文件\nxsync slaves\n\n\n\n启动集群1、如果集群是第一次启动，需要格式化NameNode（注意格式化之前，一定要先停止上次启动的所有namenode和datanode进程，然后再删除data和log数据）\n[hisign@hadoop91 hadoop-2.7.2]$ bin/hdfs namenode -format\n\n\n\n2、启动HDFS\n[hisign@hadoop91 hadoop-2.7.2]$ sbin/start-dfs.sh[hisign@hadoop91 hadoop-2.7.2]$ jps18627 DataNode18836 Jps18495 NameNode[hisign@hadoop92 hadoop-2.7.2]$ jps15957 Jps15883 DataNode[hisign@hadoop93 hadoop-2.7.2]$ jps15891 SecondaryNameNode15787 DataNode15932 Jps\n\n\n\n3、启动YARN\n[hisign@hadoop92 hadoop-2.7.2]$ sbin/start-yarn.sh16004 ResourceManager16106 NodeManager15883 DataNode16205 Jps\n\n注意：NameNode和ResourceManger如果不是同一台机器，不能在NameNode上启动 YARN，应该在ResouceManager所在的机器上启动YARN。\n4、Web端查看SecondaryNameNode\nhttp://hadoop93:50090/status.html\n查看集群jps能查看当前节点的java进程，但是节点多了，得切换到别的节点去查看，所以写个shell脚本查看所有节点的java进程\n\n说明：在/home/hisign/bin这个目录下存放的脚本，hisign用户可以在系统任何地方直接执行。\n\n在/home/hisign目录下创建bin目录，并在bin目录下jpsall创建文件，文件内容如下：\nmkdir -p  /home/hisign/bincd /home/hisign/bin# 新建脚本vim jpsall\n\n\n\n在该文件中编写如下代码\n#!/bin/bash# 循环for((host=91; host&lt;94; host++)); do    echo ------------------- hadoop$host --------------    ssh hadoop$host &quot;jps&quot; | grep -v Jpsdone\n\n\n\n\n修改脚本 jpsall 具有执行权限\n\nchmod +x jpsall\n\n\n\n\n调用脚本形式：jpsall 文件名称\n\njpsall\n\n注意：如果将xsync放到/home/hisign/bin目录下仍然不能实现全局使用，可以将jpsall移动到/usr/local/bin目录下。\nsudo mv /home/hisign/bin/jpsall /usr/local/bin\n\n\n\n集群基本测试1、上传文件到集群\n\n上传小文件\n\n[hisign@hadoop91 hdoop-2.7.2]$ hdfs dfs -mkdir -p /user/hisign/input[hisign@hadoop91 hdoop-2.7.2]$ hdfs dfs -put wcinput/wc.input /user/hisign/input\n\n\n\n\n上传大文件\n\nbin/hadoop fs -put /opt/software/hadoop-2.7.2.tar.gz /user/hisign/input\n\n\n\n2、上传文件后查看文件存放在什么位置\n\n/opt/module/hadoop-2.7.2/data/tmp/dfs/data/current/BP-917863227-192.168.40.91-1604892333948/current/finalized/subdir0/subdir0/\n\n3、查看HDFS在磁盘存储文件内容\n[hisign@hadoop91 subdir0]$ ll总用量 194552-rw-rw-r--. 1 hisign hisign        45 11月  9 12:25 blk_1073741825-rw-rw-r--. 1 hisign hisign        11 11月  9 12:25 blk_1073741825_1001.meta-rw-rw-r--. 1 hisign hisign 134217728 11月  9 12:29 blk_1073741826-rw-rw-r--. 1 hisign hisign   948583 11月  9 12:29 blk_1073741826_1002.meta-rw-rw-r--. 1 hisign hisign  63439959 11月  9 12:29 blk_1073741827-rw-rw-r--. 1 hisign hisign    495635 11月  9 12:29 blk_1073741827_1003.meta[hisign@hadoop91 subdir0]$ cat blk_1073741825hadoop yarnhadoop mapreduceatguiguatguigu\n\n\n\n4、拼接\n[hisign@hadoop91 subdir0]$ cat blk_1073741825 &gt;&gt; tmp.file[hisign@hadoop91 subdir0]$ cat blk_1073741827 &gt;&gt; tmp.file\n\n\n\n5、下载\n[hisign@hadoop91 subdir0]$ cd -[hisign@hadoop91 hadoop-2.7.2]$ pwd/opt/module/hadoop-2.7.2bin/hadoop fs -get /user/hisign/input/hadoop-2.7.2.tar.gz ./\n\n\n\n集群启动/停止\n各个服务组件逐一启动/停止\n\n​    （1）分别启动/停止HDFS组件\nhadoop-daemon.sh start / stop namenode / datanode / secondarynamenode\n\n\n\n​    （2）启动/停止YARN\nyarn-daemon.sh start / stop resourcemanager / nodemanager\n\n\n\n 各个模块分开启动/停止（配置ssh是前提）常用\n\n​    （1）整体启动/停止HDFS\nstart-dfs.sh  / stop-dfs.sh\n\n\n​    （2）整体启动/停止YARN\nstart-yarn.sh / stop-yarn.sh\n\n\n\n\nsbin/start-all.sh 启动所有的Hadoop守护进程。包括NameNode、 Secondary NameNode、DataNode、ResourceManager、NodeManager\n\nsbin/stop-all.sh 停止所有的Hadoop守护进程。包括NameNode、 Secondary NameNode、DataNode、ResourceManager、NodeManager\n\nsbin/start-dfs.sh 启动Hadoop HDFS守护进程NameNode、SecondaryNameNode、DataNode\n\nsbin/stop-dfs.sh 停止Hadoop HDFS守护进程NameNode、SecondaryNameNode和DataNode\n\nsbin/hadoop-daemons.sh start namenode 单独启动NameNode守护进程\n\nsbin/hadoop-daemons.sh stop namenode 单独停止NameNode守护进程\n\nsbin/hadoop-daemons.sh start datanode 单独启动DataNode守护进程\n\nsbin/hadoop-daemons.sh stop datanode 单独停止DataNode守护进程\n\nsbin/hadoop-daemons.sh start secondarynamenode 单独启动SecondaryNameNode守护进程\n\nsbin/hadoop-daemons.sh stop secondarynamenode 单独停止SecondaryNameNode守护进程\n\nsbin/start-yarn.sh 启动ResourceManager、NodeManager\n\nsbin/stop-yarn.sh 停止ResourceManager、NodeManager\n\nsbin/yarn-daemon.sh start resourcemanager 单独启动ResourceManager\n\nsbin/yarn-daemons.sh start nodemanager 单独启动NodeManager\n\nsbin/yarn-daemon.sh stop resourcemanager 单独停止ResourceManager\n\nsbin/yarn-daemons.sh stopnodemanager 单独停止NodeManager\n\nsbin/mr-jobhistory-daemon.sh start historyserver 手动启动jobhistory\n\nsbin/mr-jobhistory-daemon.sh stop historyserver 手动停止jobhistory\n\n\n\n集群时间同步时间同步的方式：找一个机器，作为时间服务器，所有的机器与这台集群时间进行定时的同步，比如，每隔十分钟，同步一次时间。\n时间服务器配置必须root用户\n1、检查ntp是否安装\n[root@hadoop91 ~]# rpm -qa|grep ntpntp-4.2.6p5-29.el7.centos.2.x86_64ntpdate-4.2.6p5-29.el7.centos.2.x86_64\n\n如果没有安装，先安装\nyum install ntp -y\n\n\n\n2、修改ntp配置文件\n[root@hadoop91 ~]# vi /etc/ntp.conf\n\n\n修改1，授权192.168.40.0-192.168.40.255网段上的所有机器可以从这台机器上查询和同步时间\n\n# restrict 192.168.1.0 mask 255.255.255.0 nomodify notraprestrict 192.168.1.0 mask 255.255.255.0 nomodify notrap\n\n\n修改2，集群在局域网中，不使用其他互联网上的时间\n\nserver 0.centos.pool.ntp.org iburstserver 1.centos.pool.ntp.org iburstserver 2.centos.pool.ntp.org iburstserver 3.centos.pool.ntp.org iburst为#server 0.centos.pool.ntp.org iburst#server 1.centos.pool.ntp.org iburst#server 2.centos.pool.ntp.org iburst#server 3.centos.pool.ntp.org iburst\n\n\n增加如下内容，当该节点丢失网络连接，依然可以采用本地时间作为时间服务器为集群中的其他节点提供时间同步\n\nserver 127.127.1.0fudge 127.127.1.0 stratum 10\n\n\n\n3、修改/etc/sysconfig/ntpd 文件\n[root@hadoop91 ~]# vim /etc/sysconfig/ntpd\n\n增加内容如下（让硬件时间与系统时间一起同步）\nSYNC_HWCLOCK=yes\n\n\n\n4、重新启动ntpd服务\n# 查看服务状态[root@hadoop91 ~]# service ntpd status# 启动服务[root@hadoop91 ~]# service ntpd start# 停止服务[root@hadoop91 ~]# service ntpd stop# 重启服务[root@hadoop91 ~]# service ntpd restart\n\n\n\n5、设置ntpd服务开机自启\n[root@hadoop91 ~]# chkconfig ntpd on\n\n\n\n其他机器配置必须root用户\n1、在其他机器配置10分钟与时间服务器同步一次\n[root@hadoop91 ~]#  crontab -e\n\n编写定时任务如下：\n*/10 * * * * /usr/sbin/ntpdate hadoop91\n\n2、修改任意机器时间\n[root@hadoop91 ~]#  date -s &quot;2017-9-11 11:11:11&quot;\n\n3、十分钟后查看机器是否与时间服务器同步\n[root@hadoop91 ~]#  date\n\n说明：测试的时候可以将10分钟调整为1分钟，节省时间。\n*/1 * * * * /usr/sbin/ntpdate hadoop91\n\n","categories":["大数据","hadoop"],"tags":["hadoop","大数据"]},{"title":"Linux 开发环境搭建","url":"/%E6%8A%80%E6%9C%AF%E6%95%99%E7%A8%8B/Linux/Linux%20%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/","content":"JDK查询系统自带的jdk# 查询系统自带的jdk rpm -qa | grep jdk\n\n显示：\njava-1.7.0-openjdk-1.7.0.111-2.6.7.8.el7.x86_64             java-1.8.0-openjdk-1.8.0.102-4.b14.el7.x86_64               java-1.8.0-openjdk-headless-1.8.0.102-4.b14.el7.x86_64      java-1.7.0-openjdk-headless-1.7.0.111-2.6.7.8.el7.x86_64    copy-jdk-configs-3.3-10.el7_5.noarch\n\n\n\n卸载系统自带jdk# 卸载指定jdkrpm -e --nodeps java-1.7.0-openjdk-1.7.0.111-2.6.7.8.el7.x86_64rpm -e --nodeps java-1.7.0-openjdk-headless-1.7.0.111-2.6.7.8.el7.x86_64rpm -e --nodeps java-1.8.0-openjdk-1.8.0.102-4.b14.el7.x86_64rpm -e --nodeps java-1.8.0-openjdk-headless-1.8.0.102-4.b14.el7.x86_64\n\n或者使用\n# 卸载全部rpm -qa | grep jdk | xargs rpm -e --nodeps# 或者yum remove *openjdk*\n\n之后再次输入rpm -qa | grep java 查看卸载情况：\n安装新的jdk首先到官网上下载你想要的jdk，下载完成之后将安装包放到Linux系统指定的文件夹/opt/software下\n# 进入jdk存放目录cd /opt/software# 解压到指定目录tar -zxvf jdk-8u131-linux-x64.tar.gz -C /usr/local\n\n\n\n设置环境变量vim /etc/profile\n\n输入大写的  G  跳转到文件末尾，在最后面添加：\nexport JAVA_HOME=/usr/local/jdk1.8.0_131export JRE_HOME=$JAVA_HOME/jreexport CLASSPATH=.:$JAVA_HOME/lib:$JRE_HOME/libexport PATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/bin\n\n执行profile文件\nsource /etc/profile\n\n这样可以使配置不用重启即可立即生效。\n检查新安装的jdk\njava -version\n\n显示：\njava version &quot;1.8.0_131&quot;Java(TM) SE Runtime Environment (build 1.8.0_131-b11)Java HotSpot(TM) 64-Bit Server VM (build 25.131-b11, mixed mode)\n\n到此为止，整个安装过程结束。\n\nNacos准备https://github.com/alibaba/nacos/releases \n解压上传下载过后的压缩包到自己的服务器目录\n# 进入目录cd /opt/software# 解压到/usr/local目录下tar -zxvf nacos-server-1.3.1.tar.gz -C /usr/local\n\n\n\n设置开机启动创建服务\n在 /lib/systemd/system 目录下创建 nacos.service 文件\ncd /lib/systemd/system\n\n创建文件\nvim nacos.service\n\n输入a编辑，输入以下内容：\n[Unit]Description=nacosAfter=network.target[Service]Type=forkingExecStart=/usr/local/nacos/bin/startup.sh -m standaloneExecReload=/usr/local/nacos/bin/shutdown.shExecStop=/usr/local/nacos/bin/shutdown.shPrivateTmp=true[Install]WantedBy=multi-user.target\n\n按 esc 退出编辑，输入:wq保存并且退出\n进入nacos的bin目录下，修改启动文件\ncd /usr/local/nacos/bin\n\n修改文件\nvi startup.sh\n\n按a进入编辑模式，修改jdk路径\n[ ! -e &quot;$JAVA_HOME/bin/java&quot; ] &amp;&amp; JAVA_HOME=/usr/local/jdk1.8.0_144#[ ! -e &quot;$JAVA_HOME/bin/java&quot; ] &amp;&amp; JAVA_HOME=$HOME/jdk/java#[ ! -e &quot;$JAVA_HOME/bin/java&quot; ] &amp;&amp; JAVA_HOME=/usr/java#[ ! -e &quot;$JAVA_HOME/bin/java&quot; ] &amp;&amp; JAVA_HOME=/opt/taobao/java#[ ! -e &quot;$JAVA_HOME/bin/java&quot; ] &amp;&amp; unset JAVA_HOME\n\n其他的配置的四条配置前加 # 注释，按esc退出编辑，:wq 保存并退出\n设置开机启动\nsystemctl daemon-reloadsystemctl enable nacos.servicesystemctl start nacos.service\n\n\n\n启动nacosnohup sh /usr/local/nacos/bin/startup.sh -m standalone &gt; /dev/null 2&gt;&amp;1\n\n\n\n\nRedis准备wget http://download.redis.io/releases/redis-4.0.8.tar.gz\n\n历史版本下载\nhttp://download.redis.io/releases/\n安装redis需要gcc编译环境\n# 安装gccyum install gcc -y\n\n\n\n解压上传下载过后的压缩包到自己的服务器目录\n# 进入目录cd /opt/software# 解压到/tmp目录下tar -zxvf redis-4.0.8.tar.gz -C /tmp\n\n\n\n安装# 进入redis源码目录cd /tmp/redis-4.0.8# 编译make# 如果make报错，添加参数MALLOC=libc执行# zmalloc.h:50:31: error: jemalloc/jemalloc.h: No such file or directory，make MALLOC=libc# 安装cd srcmake install PREFIX=/usr/local/redis\n\n移动配置文件到安装目录下\n# 新建配置文件目录mkdir -p /usr/local/redis/etc# 将配置文件移到对应目录mv ../redis.conf /usr/local/redis/etc\n\n\n\n设置vim /usr/local/redis/etc/redis.conf# 配置redis后台启动：将daemonize no 改成 daemonize yesdaemonize yes# 配置远程访问：将protected-mode yes 改为 noprotected-mode no\n\n\n\n设置开机启动vim /etc/rc.d/rc.local# 在里面添加内容(意思就是开机调用这段开启redis的命令)/usr/local/redis/bin/redis-server /usr/local/redis/etc/redis.conf\n\n要想保证开机自启，得确认rc.local是可执行文件，如果不是，添加执行权限\n# 添加执行权限chmod +x /etc/rc.d/rc.local\n\n\n\n启动redis/usr/local/redis/bin/redis-server /usr/local/redis/etc/redis.conf\n\n\n\n常用命令\n# 启动redisredis-server /usr/local/redis/etc/redis.conf# 停止redispkill redis# 卸载redisrm -rf /usr/local/redis  # 删除安装目录rm -rf /usr/bin/redis-*  # 删除所有redis相关命令脚本rm -rf /tmp/redis-4.0.8 # 删除redis解压文件夹\n\n\n\n\nNginx准备wget http://nginx.org/download/nginx-1.9.0.tar.gz\n\n历史版本下载\nhttps://nginx.org/download/\n解压上传下载过后的压缩包到自己的服务器目录\n# 进入目录cd /opt/software# 解压到/tmp目录下tar -zxvf nginx-1.9.0.tar.gz -C /tmp\n\n\n\n安装安装依赖插件，默认需要 zlib、openssl 和 pcre 依赖包，其他组件可以根据自己需要选择安装。输入如下命令： \nyum install -y gcc gcc-c++ zlib zlib-devel openssl openssl-devel pcre pcre-devel\n\n\ngcc：编译器组件，包括C、C++等zlib：数据压缩库openssl：https安全传输协议，默认没有打开pcre：正则表达式库\n\n# 进入nginx目录cd /tmp/nginx-1.9.0# 配置，默认安装到/usr/local/nginx目录，如果要自定义目录 ./configure --prefix=/usr/local/nginx./configure  # 安装make &amp;&amp; make install\n\n\n\n设置开机启动vim /etc/rc.local# 在里面添加内容(意思就是开机调用这段开启nginx的命令)/usr/local/nginx/sbin/nginx -c /usr/local/nginx/conf/nginx.conf\n\n要想保证开机自启，得确认rc.local是可执行文件，如果不是，添加执行权限\n# 添加执行权限chmod +x /etc/rc.local\n\n\n\n启动nginx/usr/local/nginx/sbin/nginx -c /usr/local/nginx/conf/nginx.conf\n\n\n\n常用命令\n./nginx # 启动./nginx -s stop # 关闭./nginx -s reload # 重启\n\n\n\n\nZookeeper准备http://archive.apache.org/dist/zookeeper/\n解压上传下载过后的压缩包到自己的服务器目录\n# 进入目录cd /opt/software# 解压到指定目录tar -zxvf zookeeper-3.4.10.tar.gz -C /usr/local\n\n\n\n配置新建配置文件\n# 进入zookeeper配置文件目录cd /usr/local/zookeeper-3.4.10/conf# 将zoo_sample.cfg这个文件复制为zoo.cfg (必须是这个文件名)cp zoo_sample.cfg zoo.cfg\n\n修改配置文件\nvim zoo.cfg# 指定数据和日志目录dataDir=/usr/local/zookeeper-3.4.10/datadataLogDir=//usr/local/zookeeper-3.4.10/logscd ../# 新建目录存放数据和日志mkdir /usr/local/zookeeper-3.4.10/datamkdir /usr/local/zookeeper-3.4.10/logs\n\n\n\n设置环境变量vim /etc/profile\n\n输入大写的  G  跳转到文件末尾，在最后面添加：\nexport ZOOKEEPER_HOME=/usr/local/zookeeper-3.4.10export PATH=$ZOOKEEPER_HOME/bin:$PATH\n\n执行profile文件\nsource /etc/profile\n\n这样可以使配置不用重启即可立即生效。\n启动zookeepercd /usr/local/zookeeper-3.4.10/bin# 启动./zkServer.sh start\n\n\n\n常用命令\n./zkServer.sh status # 查看状态./zkServer.sh stop # 停止./zkCli.sh # 启动客户端\n\n\n\n\nKafka准备http://archive.apache.org/dist/kafka/\n解压上传下载过后的压缩包到自己的服务器目录\n# 进入目录cd /opt/software# 解压到指定目录tar -zxvf kafka_2.12-2.0.0.tar.gz -C /usr/local\n\n\n\n配置# 进入配置文件目录cd /usr/local/kafka_2.12-2.0.0/config# 修改 server.propertiesvim server.properties==============================================================================broker.id=0 port=9092 #端口号 host.name=localhost #单机可直接用localhostlog.dirs=/data/kafka/log #日志存放路径可修改可不修改zookeeper.connect=localhost:2181 #zookeeper地址和端口，单机配置部署，localhost:2181# 修改 zookeeper.propertiesvim zookeeper.properties==============================================================================#zookeeper数据目录  (可以修改可以不修改)dataDir=/data/kafka/zookeeper/data#zookeeper日志目录 （可以修改可以不修改）dataLogDir=/data/kafka/zookeeper/logclientPort=2181 maxClientCnxns=100 tickTime=2000\n\n创建目录\nmkdir -p /data/kafka/logmkdir -p /data/kafka/zookeeper/datamkdir -p /data/kafka/zookeeper/log\n\n\n\n新建执行脚本# 启动脚本# 进入kafka目录下 输入命令：vi  kafkaStart.sh====================================================================添加内容为：#!/bin/bash#启动zookeeper/usr/local/kafka_2.12-2.0.0/bin/zookeeper-server-start.sh /usr/local/kafka_2.12-2.0.0/config/zookeeper.properties &amp;sleep 3  #默默等3秒后执行 #启动kafka/usr/local/kafka_2.12-2.0.0/bin/kafka-server-start.sh /usr/local/kafka_2.12-2.0.0/config/server.properties &amp;# 停止脚本# 进入kafka目录下 输入命令：vi  kafkaStop.sh====================================================================添加内容为：#!/bin/bash#停止kafka/usr/local/kafka_2.12-2.0.0/bin/kafka-server-stop.sh /usr/local/kafka_2.12-2.0.0/config/server.properties &amp;sleep 3  #默默等3秒后执行 #停止zookeeper/usr/local/kafka_2.12-2.0.0/bin/zookeeper-server-stop.sh /usr/local/kafka_2.12-2.0.0/config/zookeeper.properties &amp;# 添加脚本执行权限chmod +x kafkaStart.shchmod +x kafkaStop.sh\n\n\n\n设置开机启动vim /etc/rc.local# 在里面添加内容(意思就是开机调用这段开启kafka的命令)sh /usr/local/kafka/kafkaStart.sh &amp;\n\n要想保证开机自启，得确认rc.local是可执行文件，如果不是，添加执行权限\n# 添加执行权限chmod +x /etc/rc.local\n\n\n\n启动kafkash /usr/local/kafka/kafkaStart.sh &amp;\n","categories":["技术教程","Linux"],"tags":["Linux","JDK","Nacos","Redis","Nginx","Zookeeper"]},{"title":"Linux 基础环境搭建","url":"/%E6%8A%80%E6%9C%AF%E6%95%99%E7%A8%8B/Linux/Linux%20%E5%9F%BA%E7%A1%80%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/","content":"下载以CentOS7为例，下载地址\nhttp://mirrors.aliyun.com/centos/7/isos/x86_64/\n安装不赘述，网络设置桥接模式\n配置网络vi /etc/sysconfig/network-scripts/ifcfg-ens32\n\nifcfg-ens32\n# 网络类型为以太网TYPE=Ethernet# 设置固定ip，dhcp 改为 static# BOOTPROTU=dhcpBOOTPROTU=static# 网卡设备名，一定要跟文件名一致DEVICE=ens32# 网卡设备名，一定要跟文件名一致NAME=ens32# 设定网卡随网络服务启动# ONBOOT=noONBOOT=yes# 固定ipIPADDR=192.168.40.26# 网关GATEWAY=192.168.40.254# 子网掩码NETMASK=255.255.255.0# DNS地址DNS1=8.8.8.8DNS2=114.114.114.114\n\n重启网络服务，使生效\n# 重启网络服务service network restart\n\n\n\n配置国内yum源查看所有的yum源\nyum repolist all\n\n查看可用的yum源\nyum repolist enabled\n\n阿里镜像仓库配置\n根据官网的说明，我们详细说说每步骤的意思。\n（1）备份，将 CentOS-Base.repo 为CentOS-Base.repo.bak\nmv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.bak\n\n（2）下载新的 http://mirrors.aliyun.com/repo/Centos-7.repo，并命名为CentOS-Base.repo\nwget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo\n\n或者\ncurl -o /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo\n\n\n（3）清除缓存\nyum clean all     # 清除系统所有的yum缓存yum makecache     # 生成yum缓存\n\n\n\n防火墙firewalld跟iptables比起来至少有两大好处：\n\nfirewalld可以动态修改单条规则，而不需要像iptables那样，在修改了规则后必须得全部刷新才可以生效；\nfirewalld在使用上要比iptables人性化很多，即使不明白“五张表五条链”而且对TCP/IP协议也不理解也可以实现大部分功能。\n\nfirewalld跟iptables比起来，不好的地方是每个服务都需要去设置才能放行，因为默认是拒绝。而iptables里默认是每个服务是允许，需要拒绝的才去限制。\ncentos7开始默认用的是firewalld，这个是基于iptables的，虽然有iptables的核心，但是iptables的服务是没安装的。\nfirewalld# 安装防火墙yum install firewalld firewall-config# 开启防火墙systemctl start firewalld# 将接口添加到区域 --zone=public，默认接口都在public# --permanent 永久加入，没有这个参数重启后失效firewall-cmd --zone=public --add-interface=eth0# 将端口添加到区域 --zone=public，默认接口都在public# --permanent 永久加入，没有这个参数重启后失效firewall-cmd --add-port=8080/tcp --permanent# 刷新防火墙设置 firewall-cmd --reload# 查看防火墙中已放开的端口firewall-cmd --list-ports# 查看80端口是否开启firewall-cmd --query-port=80/tcp# 停止防火墙systemctl stop firewalld# 查看防火墙是否开机自启systemctl is-enabled firewalld# 禁用防火墙，开机自启关闭systemctl disable firewalld# 启用防火墙，开机自启systemctl enable firewalld\n\n\n\niptables# 关闭防火墙service iptables stop# 禁用防火墙，开机自启关闭chkconfig iptables off# 查看防火墙状态service iptables status# 查看开机自启列表chkconfig --list iptables\n\n\n\n\n\n免密运行sudo在 /etc/sudoers文件中，默认打开的 authenticate 参数用于验证目的。如果设置了它，用户必须通过密码（或其他身份验证方法）进行身份验证，然后才能使用 sudo 运行命令。但是，可以使用 NOPASSWD （当用户调用 sudo 命令时不需要密码）标记来覆盖此默认值。\nroot用户/etc/sudoers 文件只有读的权限，需要给root用户写的权限\n# 添加写权限chmod +w /etc/sudoers\n\n修改/etc/sudoers \n# 用户 haung 可以不用密码使用sudohuang    ALL=(ALL)    NOPASSWD: ALL# 对于组而言，在组名前面使用 % 字符；这意味着 sys 组的所有成员都可以不用密码使用sudo%sys    ALL=(ALL)    NOPASSWD: ALL# sys 组的所有成员都可以不用密码使用sudo运行命令 /bin/kill%sys    ALL=(ALL)    NOPASSWD: /bin/kill# sys 组的所有成员都可以不用密码使用sudo运行命令 /bin/kill、/bin/rm%sys    ALL=(ALL)    NOPASSWD: /bin/kill,/bin/rm\n\n 操作完成之后记得收回root的权限\n# 收回写权限chmod -w /etc/sudoers\n\n当然，也不用添加权限、收回权限这么麻烦，可以在root用户修改完后强制保存\n# ESC后，:wq! 强制保存:wq!\n\n\n\nSSH免密登录原理：\nhttps://www.cnblogs.com/haojun/p/11131432.html\n 工作原理如下图所示：\n\n生成公钥和私钥：\n[hisign@hadoop91 /]$ ssh-keygen -t rsa\n\n然后敲（三个回车），就会生成两个文件id_rsa（私钥）、id_rsa.pub（公钥）\n[hisign@hadoop91 /]$ cd ~/.ssh/[hisign@hadoop91 .ssh]$ ll\n\n显示\n总用量 12-rw-------. 1 hisign hisign 1675 11月  9 09:58 id_rsa-rw-r--r--. 1 hisign hisign  397 11月  9 09:58 id_rsa.pub-rw-r--r--. 1 hisign hisign  372 11月  9 09:15 known_hosts\n\n\n\n将公钥拷贝到要免密登录的目标机器上\nssh-copy-id可以把本地主机的公钥复制到远程主机的authorized_keys文件上，ssh-copy-id命令也会给远程主机的用户主目录（home）和~/.ssh, 和~/.ssh/authorized_keys设置合适的权限。\n# 给用户hisign配置免密登录[hisign@hadoop91 .ssh]$ ssh-copy-id hadoop91[hisign@hadoop91 .ssh]$ ssh-copy-id hadoop92[hisign@hadoop91 .ssh]$ ssh-copy-id hadoop93\n\n注意：在hadoop92和hadoop93上把上面的操作都再执行一遍，三台服务器就能互相之间进行免密登录了。如果想要其他用户也能进行免密登录，切换到其他用户执行上操作即可。\n用户密码# 添加用户huanguseradd huang# 给用户huang设置密码passwd huang# 删除用户huang的密码passwd -d huang\n\n\n\n修改语言vim /etc/locale.conf# LANG=&quot;en_US.UTF-8&quot;LANG=&quot;zh_CN.UTF-8&quot;\n\n重新加载配置文件\nsource /etc/locale.conf\n\n\n\n分发文件scp 安全拷贝\n定义：\n\n\nscp可以实现服务器与服务器之间的数据拷贝。（from server1 to server2）\n\n基本语法\n#命令 递归  要拷贝的文件路径/名称  目的用户@主机:目的路径/名称scp   -r   $pdir/$fname          $user@hadoop$host:$pdir/$fname\n\n\n案例\n\n1、在hadoop91上，将hadoop91中/opt/module目录下的软件拷贝到远程服务器hadoop92上。\n[hisign@hadoop91 /]$ scp -r /opt/module root@hadoop92:/opt/module\n\n\n\n2、在hadoop93上，将远程服务器hadoop91服务器上的/opt/module目录下的软件拷贝到本地。\n[hisign@hadoop93 opt]$sudo scp -r hisign@hadoop91:/opt/module /opt/module\n\n\n\n3、在hadoop93上操作将hadoop91中/opt/module目录下的软件拷贝到hadoop104上。\n[hisign@hadoop93 opt]$ scp -r hisign@hadoop91:/opt/module root@hadoop104:/opt/module\n\n注意：拷贝过来的/opt/module目录，别忘了在hadoop92、hadoop93、hadoop104上修改所有文件的，所有者和所有者组。\nsudo chown hisign:hisign -R /opt/module\n\n\n\n4、将hadoop91中/etc/profile文件拷贝到hadoop92的/etc/profile上。\n[hisign@hadoop91 ~]$ sudo scp /etc/profile root@hadoop92:/etc/profile\n\n\n\n5、将hadoop91中/etc/profile文件拷贝到hadoop93的/etc/profile上。\n[hisign@hadoop91 ~]$ sudo scp /etc/profile root@hadoop93:/etc/profile\n\n\n\n6、将hadoop91中/etc/profile文件拷贝到hadoop104的/etc/profile上。\n[hisign@hadoop91 ~]$ sudo scp /etc/profile root@hadoop104:/etc/profile\n\n注意：拷贝过来的配置文件别忘了 source /etc/profile 使生效。\nrsync 远程同步工具rsync主要用于备份和镜像。具有速度快、避免复制相同内容和支持符号链接的优点。\nrsync和scp区别：用rsync做文件的复制要比scp的速度快，rsync只对差异文件做更新。scp是把所有文件都复制过去。\n\n安装\n\nyum install rsync -y\n\n\n\n\n基本语法\n\n# 命令 选项参数  要拷贝的文件路径/名称  目的用户@主机:目的路径/名称rsync   -av     $pdir/$fname         $user@hadoop$host:$pdir/$fname\n\n\n案例\n\n把hadoop91机器上的/opt/software目录同步到hadoop92服务器的root用户下的/opt/目录\nrsync -av /opt/software/ hadoop92:/opt/software\n\n\n\nxsync 集群分布脚本1、需求：循环复制文件到所有节点的相同目录下\n2、需求分析：\n\nrsync命令原始拷贝：\n\nrsync -av   /opt/module  root@hadoop93:/opt/\n\n\n\n\n期望脚本：\n\nxsync 要同步的文件名称\n\n\n\n\n说明：在/home/hisign/bin这个目录下存放的脚本，hisign用户可以在系统任何地方直接执行。\n\n3、脚本实现\n在/home/hisign目录下创建bin目录，并在bin目录下xsync创建文件，文件内容如下：\nmkdir -p  /home/hisign/bincd /home/hisign/bin# 新建脚本vim xsync\n\n\n\n在该文件中编写如下代码\n#!/bin/bash#1 获取输入参数个数，如果没有参数，直接退出pcount=$#if ((pcount==0)); thenecho no args;exit;fi#2 获取文件名称p1=$1fname=`basename $p1`echo fname=$fname#3 获取上级目录到绝对路径pdir=`cd -P $(dirname $p1); pwd`echo pdir=$pdir#4 获取当前用户名称user=`whoami`#5 循环for((host=91; host&lt;94; host++)); do    echo ------------------- hadoop$host --------------    rsync -av $pdir/$fname $user@hadoop$host:$pdirdone\n\n\n\n\n修改脚本 xsync 具有执行权限\n\nchmod 777 xsync\n\n\n\n\n调用脚本形式：xsync 文件名称\n\nxsync /home/hisign/bin\n\n注意：如果将xsync放到/home/hisign/bin目录下仍然不能实现全局使用，可以将xsync移动到/usr/local/bin目录下。\nsudo mv /home/hisign/bin/xsync /usr/local/bin\n\n\n\n\n\n插件推荐上传下载工具lrzszXShell中支持，MobaXterm不支持\n# 安装 lrzszyum install lrzsz -y\n\n 注意：该软件只是用于小文件，比较大的文件还是老老实实用ftp工具吧 \n\nlrzsz是Linux/Unix同Windows进行ZModem文件传输的命令行工具。优点就是不用再开一个sftp工具登录上去上传下载文件。rz：运行该命令会弹出一个文件选择窗口，从本地选择文件上传到Linux服务器sz：将选定的文件发送（send）到本地机器\n\n网络工具包net-toolsifconfig不存在问题\n# 安装 net-toolsyum install net-tools -y \n\n\n\n文本编辑器vim# 安装 net-toolsyum install vim -y \n\n\n\n下载工具wget# 安装 wgetyum install wget -y \n\n下载单个文件wget http://www.linuxde.net/testfile.zip\n\n以下的例子是从网络下载一个文件并保存在当前目录，在下载的过程中会显示进度条，包含（下载完成百分比，已经下载的字节，当前下载速度，剩余下载时间）。\n下载另存为wget -O wordpress.zip http://www.linuxde.net/download.aspx?id=1080\n\nwget默认会以最后一个符合/的后面的字符来命名，对于动态链接的下载通常文件名会不正确。\n错误：下面的例子会下载一个文件并以名称download.aspx?id=1080保存:\nwget http://www.linuxde.net/download?id=1\n\n即使下载的文件是zip格式，它仍然以download.php?id=1080命令。\n正确：为了解决这个问题，我们可以使用参数-O来指定一个文件名：\nwget -O wordpress.zip http://www.linuxde.net/download.aspx?id=1080\n\n下载多个文件wget -i filelist.txt\n\n首先，保存一份下载链接文件：\ncat &gt; filelist.txturl1url2url3url4\n\n接着使用这个文件和参数-i下载。\n","categories":["技术教程","Linux"],"tags":["Linux"]},{"title":"ELK同步Oralce数据至ES","url":"/%E6%8A%80%E6%9C%AF%E6%95%99%E7%A8%8B/Linux/ELK%E5%90%8C%E6%AD%A5Oralce%E6%95%B0%E6%8D%AE%E8%87%B3ES/","content":"ElasticSearch下载 https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-6.7.1.tar.gz \n安装上传下载过后的压缩包到自己的服务器目录\n# 进入目录cd /opt/software# 解压到指定目录tar -zxvf elasticsearch-6.7.1.tar.gz -C /usr/local\n\n配置# 进入es安装目录cd /usr/local/elasticsearch-6.7.1# 编辑配置文件vim ./config/elasticsearch.yml\n\nelasticsearch.yml# 集群名称cluster.name: my-application# 节点名称node.name: node-1# 数据保存地址path.data: /usr/local/elasticsearch-6.7.1/data# 日志保存地址path.logs: /usr/local/elasticsearch-6.7.1/logs# ipnetwork.host: 0.0.0.0# 端口http.port: 9200\n\n\n\n# 编辑配置文件vim ./config/jvm.options\n\njvm.options-Xms1g-Xmx1g\n\n\n  注意：elasticsearch启动不能以root用户来进行，所以需要创建一个用户 \n\n创建用户并授权# 创建用户useradd elsearch# 授权chown -R elsearch:elsearch /usr/local/elasticsearch-6.7.1\n\n切换到ES用户启动# 切换到es用户su elsearch# 给用户elsearch设置密码（我没有设置密码）passwd elsearch# 删除用户elsearch的密码passwd -d elsearch# 进入es目录cd /usr/local/elasticsearch-6.7.1/bin# 启动./elasticsearch# 后台启动./elasticsearch -d\n\n停止ES进程前台运行： Ctrl + C\n后台运行：kill -9 #es进程号，也可以通过执行命令curl -XPOST http://localhost:9200/_cluster/nodes/_shutdown关闭整个集群，curl -XPOST http://localhost:9200/_cluster/nodes/节点标识符/_shutdown关闭单个节点\n查看es进程号ps -ef|grep elasticsearch\n启动报错\nmax file descriptors [4096] for elasticsearch process likely too low, increase to at least [65536]\n修改/etc/security/limits.conf文件 在文件末尾添加如下内容，然后重启服务器或重新登录即可生效。重启后用查看命令进行查看，如果显示数字等于204800即证明修改成功。如果不成功请继续往下看 \n# 我们用的是elsearch用户，而不是root，权限不足。# 首先用root用户登录，然后修改配置文件:su - root# 修改配置命令：vim /etc/security/limits.conf# 如果文件是只读文件，修改为可读写chmod 666 /etc/security/limits.conf# 查看命令:(-n是可以打开最大文件描述符的数量。 -u是用户最大可用的进程数。)ulimit -nulimit -u# 添加下面的内容：* soft nofile 65536* hard nofile 65536* soft nproc 65536* hard nproc 65536# 修改为只读chmod 222 /etc/security/limits.conf\n\n我在解决这个问题时候，发现网上都是说修改这一个文件就行，但是我修改后重新登录发现没更改过来。后来发现，还需要修改两个文件。如果你重启后也没生效，请继续跟着往下修改。 \n\n注：修改90-nproc.conf，如果90-nproc.conf不存在，修改类似的文件即可，即xx-nproc.conf，我本地就是/etc/security/limits.d/20-nproc.conf。 \n\n# 添加下面的内容：* soft nproc 65536* hard nproc 65536* soft nofile 65536* hard nofile 65536\n\n官方 manual 以及网上的教程有很多都用了*符号，然而不是所有系统都认的，比如我在解决这个问题时候，发现ubuntu系统就不支持。最前面一列代表用户名即root和elsearh。 \n# 不兼容方式* soft nproc 65536* hard nproc 65536* soft nofile 65536* hard nofile 65536# 兼容方式root soft nproc 65536root hard nproc 65536root soft nofile 65536root hard nofile 65536elsearch soft nproc 65536elsearch hard nproc 65536elsearch soft nofile 65536elsearch hard nofile 65536\n\nlimits.conf 建议不要使用星号\n\nmax virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144]\n# 切换到root用户su - root# 修改配置sysctl.confvi /etc/sysctl.conf# 添加下面配置：vm.max_map_count=655360# 并执行命令：sysctl -p#然后，重新启动elasticsearch，即可启动成功\n\n\n\n\n问题解决在elasticsearch-head插件地址栏中输入服务器的地址，如：http://192.168.1.12:9200，很不幸，打不开。下面进行原因排查：\nfirewall-cmd --query-port=9200/tcp# 如果显示no，说明9200端口没有开# 开放80端口，重启防火墙# --permanent 永久生效，没有此参数重启后失效firewall-cmd --add-port=9200/tcp --permanentsystemctl restart firewalld\n\n\n\nLogStash下载 https://artifacts.elastic.co/downloads/logstash/logstash-6.7.1.tar.gz \n安装 上传下载过后的压缩包到自己的服务器目录\n# 进入目录cd /opt/software# 解压到指定目录tar -zxvf logstash-6.7.1.tar.gz -C /usr/local\n\n配置新建配置文件cp logstash-sample.conf logstash-test.conf# 进入logstash数据目录cd /usr/local/logstash-6.7.1/data# 新建结果保存目录mkdir metadata# 新建抽取脚本目录mkdir sql\n\n修改配置文件\njdbc_driver_library： 数据库驱动存放位置\nstatement_filepath：抽取脚本存放位置\nlast_run_metadata_path：运行结果保存位置\n\n部分配置文件\n# Sample Logstash configuration for creating a simple# Beats -&gt; Logstash -&gt; Elasticsearch pipeline.input &#123;    jdbc &#123;    \t#驱动地址    \tjdbc_driver_library =&gt; &quot;/home/xis/ojdbc8-12.2.0.1.jar&quot;\t    # jdbc_driver_class =&gt; &quot;com.mysql.jdbc.Driver&quot;\t    jdbc_driver_class =&gt; &quot;Java::oracle.jdbc.driver.OracleDriver&quot;\t    jdbc_connection_string =&gt; &quot;jdbc:oracle:thin:@192.168.40.104:1521:hczz&quot;\t    jdbc_user =&gt; zdkz\t    jdbc_password =&gt; zdkz\t    #仅提取自上次运行以来更改的数据一般使用自增id或者使用update_time 最后更新时间\t    #sql 语句文件，也可以直接写SQL，如statement =&gt; &quot;select * from table1&quot;\t    #statement =&gt; &quot;select * from tb_yw_shxx where del = &#x27;0&#x27; and modify_date &gt; :sql_last_value&quot;        statement_filepath =&gt; &quot;/usr/local/logstash-6.7.1/data/sql/shxx.sql&quot;        #是否使用column 作为增量字段\t    use_column_value =&gt; true\t    #增量字段的类型，目前只有数字(numeric)和时间类型(timestamp)，默认是数字类型\t    tracking_column_type =&gt; &quot;timestamp&quot;\t    #以id做为增量值，用于增量同步，需是数据库字段\t    tracking_column =&gt; &quot;modify_date&quot;\t    #是否记录上次执行结果，true表示会将上次执行结果的tracking_column字段的值保存到last_run_metadata_path指定的文件中\t    record_last_run =&gt; true\t    #上面运行结果的保存位置\t    last_run_metadata_path =&gt; &quot;/usr/local/logstash-6.7.1/data/metadata/shxx&quot;\t    \t\t# 是否将字段名转换为小写，默认true（如果有数据序列化、反序列化需求，建议改为false）；\t\tlowercase_column_names =&gt; true       \t    \t    #是否清除last_run_metadata_path的记录，需要增量同步时此字段必须为false\t  \tclean_run =&gt; false\t  \t#定时设置，corn表达式      \tschedule =&gt; &quot;* * * * *&quot;      \t#ES中type      \ttype =&gt; &quot;shxx&quot;\t&#125;\t    jdbc &#123;    \t#驱动地址    \tjdbc_driver_library =&gt; &quot;/home/xis/ojdbc8-12.2.0.1.jar&quot;\t    # jdbc_driver_class =&gt; &quot;com.mysql.jdbc.Driver&quot;\t    jdbc_driver_class =&gt; &quot;Java::oracle.jdbc.driver.OracleDriver&quot;\t    jdbc_connection_string =&gt; &quot;jdbc:oracle:thin:@192.168.40.104:1521:hczz&quot;\t    jdbc_user =&gt; zdkz\t    jdbc_password =&gt; zdkz\t    #仅提取自上次运行以来更改的数据一般使用自增id或者使用update_time 最后更新时间\t    #sql 语句文件，也可以直接写SQL，如statement =&gt; &quot;select * from table1&quot;\t    #statement =&gt; &quot;select * from tb_yw_zdxx where del = &#x27;0&#x27; and modify_date &gt; :sql_last_value order&quot;        statement_filepath =&gt; &quot;/usr/local/logstash-6.7.1/data/sql/zdxx.sql&quot;        #是否使用column 作为增量字段\t    use_column_value =&gt; true\t    #增量字段的类型，目前只有数字(numeric)和时间类型(timestamp)，默认是数字类型\t    tracking_column_type =&gt; &quot;timestamp&quot;\t    #以id做为增量值，用于增量同步，需是数据库字段\t    tracking_column =&gt; &quot;modify_date&quot;\t    #是否记录上次执行结果，true表示会将上次执行结果的tracking_column字段的值保存到last_run_metadata_path指定的文件中\t    record_last_run =&gt; true\t    #上面运行结果的保存位置\t    last_run_metadata_path =&gt; &quot;/usr/local/logstash-6.7.1/data/metadata/zdxx&quot;\t    \t\t# 是否将字段名转换为小写，默认true（如果有数据序列化、反序列化需求，建议改为false）；\t\tlowercase_column_names =&gt; true       \t    \t    #是否清除last_run_metadata_path的记录，需要增量同步时此字段必须为false\t  \tclean_run =&gt; false\t  \t#定时设置，corn表达式      \tschedule =&gt; &quot;* * * * *&quot;\t\t#ES中type      \ttype =&gt; &quot;zdxx&quot;      \t\t&#125;\t\t\t\t    \t&#125;filter &#123;    # 解决默认时区与当前时区相差8小时问题\truby &#123; \t\tcode =&gt; &quot;event.set(&#x27;timestamp&#x27;, event.get(&#x27;@timestamp&#x27;).time.localtime + 8*60*60)&quot; \t&#125;\truby &#123;\t\tcode =&gt; &quot;event.set(&#x27;@timestamp&#x27;,event.get(&#x27;timestamp&#x27;))&quot;\t&#125;\tmutate &#123;\t\tremove_field =&gt; [&quot;timestamp&quot;]\t&#125;&#125;output &#123;\tif[type] == &quot;shxx&quot;&#123;\t\telasticsearch &#123;\t\t\t#ES ip:port\t\t\thosts =&gt; [&quot;localhost:9200&quot;]\t\t\t#ES索引名\t\t\tindex =&gt; &quot;tb_yw_shxx&quot;\t\t\tdocument_type =&gt; &quot;doc&quot;\t\t\tdocument_id =&gt; &quot;%&#123;id&#125;&quot;\t\t&#125;\t&#125;\tif[type] == &quot;zdxx&quot;&#123;\t\telasticsearch &#123;\t\t\t#ES ip:port\t\t\thosts =&gt; [&quot;localhost:9200&quot;]\t\t\t#ES索引名\t\t\tindex =&gt; &quot;tb_yw_zdxx&quot;\t\t\tdocument_type =&gt; &quot;doc&quot;\t\t\tdocument_id =&gt; &quot;%&#123;id&#125;&quot;\t\t\t&#125;\t&#125;&#125;\n\n启动# 进入logstash安装目录cd /usr/local/logstash-6.7.1/bin# 启动logstash -f ../config/logstash-test.conf\n\n后台启动\nnohup logstash -f ../config/logstash-test.conf\n\n\n\n停止查看进程号 ps -ef|grep logstash\n杀掉进程 kill -9 #logstash进程号\nKibana下载 https://artifacts.elastic.co/downloads/kibana/kibana-6.7.1.tar.gz \n安装 上传下载过后的压缩包到自己的服务器目录\n# 进入目录cd /opt/software# 解压到指定目录tar -zxvf kibana-6.7.1.tar.gz -C /usr/local\n\n配置kibana.yml# 端口server.port: 5601# 主机server.host: &quot;localhost&quot;# es地址elasticsearch.url: &quot;http://localhost:9200&quot;# 索引kibana.index: &quot;.kibana&quot;\n\n启动# 进入kibana安装目录cd /usr/local/kibana-6.7.1/bin# 启动./kibana\n\n后台启动\n# 后台启动nohup ./kibana &amp;\n\n停止ps -ef|grep kibana找不到进程号\n查看进程号 fuser -n tcp 5601\n杀掉进程 kill -9 #kibana进程号\n","categories":["技术教程","Linux"],"tags":["Linux","ELK","ElasticSearch","LogStash","Kibana"]},{"title":"Mybatis 逆向工程","url":"/%E5%90%8E%E7%AB%AF/Mybatis/Mybatis%E9%80%86%E5%90%91%E5%B7%A5%E7%A8%8B/","content":"mybatis-generatorpom.xml&lt;properties&gt;    &lt;java.version&gt;1.8&lt;/java.version&gt;    &lt;ojdbc.version&gt;12.2.0.1&lt;/ojdbc.version&gt;&lt;/properties&gt;&lt;dependencies&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;        &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt;    &lt;/dependency&gt;    &lt;!--jdbc--&gt;    &lt;dependency&gt;        &lt;groupId&gt;com.oracle&lt;/groupId&gt;        &lt;artifactId&gt;ojdbc8&lt;/artifactId&gt;        &lt;version&gt;$&#123;ojdbc.version&#125;&lt;/version&gt;    &lt;/dependency&gt;&lt;/dependencies&gt;&lt;build&gt;    &lt;plugins&gt;        &lt;plugin&gt;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;            &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;        &lt;/plugin&gt;        &lt;!--mybatis逆向工程插件--&gt;        &lt;plugin&gt;            &lt;groupId&gt;org.mybatis.generator&lt;/groupId&gt;            &lt;artifactId&gt;mybatis-generator-maven-plugin&lt;/artifactId&gt;            &lt;version&gt;1.3.5&lt;/version&gt;            &lt;configuration&gt;                &lt;verbose&gt;true&lt;/verbose&gt;                &lt;overwrite&gt;true&lt;/overwrite&gt;            &lt;/configuration&gt;        &lt;/plugin&gt;    &lt;/plugins&gt;&lt;/build&gt;\n\n\n\n\n\ngeneratorConfig.xml&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;!DOCTYPE generatorConfiguration        PUBLIC &quot;-//mybatis.org//DTD MyBatis Generator Configuration 1.0//EN&quot;        &quot;http://mybatis.org/dtd/mybatis-generator-config_1_0.dtd&quot;&gt;&lt;generatorConfiguration&gt;    &lt;!--classPathEntry:数据库的JDBC驱动,换成你自己的驱动位置 可选 --&gt;    &lt;classPathEntry location=&quot;D:\\Program\\Apache\\apache-maven-3.6.3\\repo\\com\\oracle\\ojdbc8\\12.2.0.1\\ojdbc8-12.2.0.1.jar&quot;/&gt;    &lt;!-- 一个数据库一个context --&gt;    &lt;context id=&quot;OracleTables&quot; targetRuntime=&quot;MyBatis3&quot;&gt;        &lt;!-- 生成的Java文件的编码 --&gt;        &lt;property name=&quot;javaFileEncoding&quot; value=&quot;utf-8&quot;/&gt;        &lt;!-- 注释 --&gt;        &lt;commentGenerator&gt;            &lt;property name=&quot;suppressAllComments&quot; value=&quot;false&quot;/&gt;&lt;!-- 是否取消注释 --&gt;            &lt;property name=&quot;suppressDate&quot; value=&quot;false&quot;/&gt; &lt;!-- 是否生成注释代时间戳--&gt;        &lt;/commentGenerator&gt;        &lt;!--数据库连接的信息：驱动类、连接地址、用户名、密码 --&gt;        &lt;jdbcConnection driverClass=&quot;oracle.jdbc.driver.OracleDriver&quot;                        connectionURL=&quot;jdbc:oracle:thin:@192.168.40.104:1521:hczz&quot;                        userId=&quot;zdkz&quot;                        password=&quot;zdkz&quot;&gt;            &lt;!-- 针对oracle数据库 --&gt;            &lt;property name=&quot;remarksReporting&quot; value=&quot;true&quot;/&gt;        &lt;/jdbcConnection&gt;        &lt;!-- 类型转换 --&gt;        &lt;javaTypeResolver&gt;            &lt;!-- 是否使用bigDecimal， false可自动转化以下类型（Long, Integer, Short, etc.） --&gt;            &lt;property name=&quot;forceBigDecimals&quot; value=&quot;false&quot;/&gt;        &lt;/javaTypeResolver&gt;        &lt;!-- 生成实体类地址 --&gt;        &lt;javaModelGenerator targetPackage=&quot;com.hisign.xzxt2.zdkz.model.zdxx&quot; targetProject=&quot;src/main/java&quot;&gt;            &lt;!-- 是否让schema作为包的后缀 --&gt;            &lt;property name=&quot;enableSubPackages&quot; value=&quot;false&quot;/&gt;            &lt;!-- 从数据库返回的值去掉前后空格 --&gt;            &lt;property name=&quot;trimStrings&quot; value=&quot;true&quot;/&gt;        &lt;/javaModelGenerator&gt;        &lt;!-- 指定map.xml生成的位置 --&gt;        &lt;sqlMapGenerator targetPackage=&quot;mapper&quot; targetProject=&quot;src/main/resources&quot;&gt;            &lt;property name=&quot;enableSubPackages&quot; value=&quot;false&quot;/&gt;        &lt;/sqlMapGenerator&gt;        &lt;!-- 指定mapper接口生成的位置 --&gt;        &lt;javaClientGenerator type=&quot;XMLMAPPER&quot; targetPackage=&quot;com.hisign.xzxt2.zdkz.db.dao.zdxx&quot; targetProject=&quot;src/main/java/&quot;&gt;            &lt;property name=&quot;enableSubPackages&quot; value=&quot;false&quot;/&gt;        &lt;/javaClientGenerator&gt;        &lt;!-- table可以有多个,每个数据库中的表都可以写一个table，tableName表示要匹配的数据库表,也可以在tableName属性中通过使用%通配符        来匹配所有数据库表,只有匹配的表才会自动生成文件 enableSelectByPrimaryKey相应的配置表示是否生成相应的接口 --&gt;        &lt;table tableName=&quot;TB_YW_ZDCXRY&quot; enableCountByExample=&quot;false&quot; enableUpdateByExample=&quot;false&quot;               enableDeleteByExample=&quot;false&quot; enableSelectByExample=&quot;false&quot; selectByExampleQueryId=&quot;false&quot;               enableSelectByPrimaryKey=&quot;true&quot; enableUpdateByPrimaryKey=&quot;true&quot;               enableDeleteByPrimaryKey=&quot;true&quot;&gt;            &lt;property name=&quot;useActualColumnNames&quot; value=&quot;false&quot;/&gt;        &lt;/table&gt;    &lt;/context&gt;&lt;/generatorConfiguration&gt;\n\n\n\n配置启动配置\n","categories":["后端","Mybatis"],"tags":["Mybatis"]},{"title":"Oracle 四大排名函数","url":"/%E6%95%B0%E6%8D%AE%E5%BA%93/Oracle/Oracle%E5%9B%9B%E5%A4%A7%E6%8E%92%E5%90%8D%E5%87%BD%E6%95%B0/","content":"ROW_NUMBER()定义\nROW_NUMBER()函数作用就是将select查询到的数据进行排序，每一条数据加一个序号，他不能用做于学生成绩的排名，一般多用于分页查询， 比如查询前10个学生。\n\n实例对学生成绩排序\n这里number就是每个学生的序号 根据studentScore(分数)进行desc倒序\n获取第二个同学成绩\n这里用到的思想就是 分页查询的思想 在原sql外再套一层 selectwhere t.number&gt;=1 and t.number&lt;=10 是不是就是获取前十个学生的成绩信息纳。\nRANK()定义\nRANK()函数，顾名思义排名函数，可以对某一个字段进行排名，这里为什么和ROW_NUMBER()不一样那，ROW_NUMBER()是排序，当存在相同成绩的学生时，ROW_NUMBER()会依次进行排序，他们序号不相同，而Rank()则不一样出现相同的，他们的排名是一样的。下面看例子:\n\n实例对学生成绩进行排名\n\n这里发现 ROW_NUMBER()和RANK()怎么一样？因为学生成绩都不一样所以排名和排序一样，下面改一下就会发现区别。\n\n当出现两个学生成绩相同是里面出现变化。RANK()是 1 2 2，而ROW_NUMBER()则还是1 2 3，这就是RANK()和ROW_NUMBER()的区别了\nDENSE_RANK()定义\nDENSE_RANK()函数也是排名函数，和RANK()功能相似，也是对字段进行排名，那它和RANK()到底有什么不同那？看例子：\n\n实例：\nDENSE_RANK()密集的排名他和RANK()区别在于，排名的连续性，DENSE_RANK()排名是连续的，RANK()是跳跃的排名，所以一般情况下用的排名函数就是RANK()。\nNTILE()定义\nNTILE()函数是将有序分区中的行分发到指定数目的组中，各个组有编号，编号从1开始，就像我们说的’分区’一样 ，分为几个区，一个区会有多少个。\n\n实例：\n这里查询了3次,第一次分为1个’区’ ,所以查询结果number全是1，第二次分为2个区，查询结果为 1 1 2，意思就是 第一个 ‘区’ 为 1 1 两个编号的数据 ，第二个’区’只有2这个数据。\n到这里，SQL的排名问题就说完了，下次介绍一些深层的SQL排名语句\n参考：\nhttps://blog.csdn.net/shaiguchun9503/article/details/82349050\n","categories":["数据库","Oracle"],"tags":["Oracle","排名函数"]},{"title":"Oracle 高级分组函数","url":"/%E6%95%B0%E6%8D%AE%E5%BA%93/Oracle/Oracle%E9%AB%98%E7%BA%A7%E5%88%86%E7%BB%84%E5%87%BD%E6%95%B0/","content":"\n本文主要讲解 ROLLUP, CUBE, GROUPING SETS的主要用法，这些函数可以理解为GroupBy分组函数封装后的精简用法，相当于多个union all 的组合显示效果，但是要比 多个union all的效率要高。\n\n\n其实这些函数在时间的程序开发中应用的并不多，至少在我工作的多年时间中没用过几次，因为现在的各种开发工具/平台都自带了这些高级分组统计功能，使用的方便性及美观性都比这些要好。但如果临时查下数据，用这些函数还是不错的。\n\n创建测试环境在线数据库 http://sqlfiddle.com/ \n1.   创建表\ncreate table EMP2(  ID       NUMBER,  /**员工编号*/  NAME     VARCHAR2(20), /**姓名*/  SEX     VARCHAR2(3),  /**性别*/  HIREDATE DATE,         /**入职日期*/  BASE    VARCHAR2(20), /**工作母地*/  DEPT    VARCHAR2(20), /**所在部门*/  SAL     NUMBER        /**月工资*/);\n\n\n\n2.   插入测试数据\ninsert into emp2 (ID, NAME, SEX, HIREDATE,BASE, DEPT, SAL)values (107, &#x27;小月&#x27;, &#x27;女&#x27;, to_date(&#x27;01-09-2013&#x27;, &#x27;dd-mm-yyyy&#x27;), &#x27;北京&#x27;,&#x27;营运&#x27;, 9000);insert into emp2 (ID, NAME, SEX, HIREDATE,BASE, DEPT, SAL)values (108, &#x27;小美&#x27;, &#x27;女&#x27;, to_date(&#x27;01-06-2011&#x27;, &#x27;dd-mm-yyyy&#x27;), &#x27;上海&#x27;,&#x27;营运&#x27;, 11000);insert into emp2 (ID, NAME, SEX, HIREDATE,BASE, DEPT, SAL)values (101, &#x27;张三&#x27;, &#x27;男&#x27;, to_date(&#x27;01-01-2011&#x27;, &#x27;dd-mm-yyyy&#x27;), &#x27;北京&#x27;,&#x27;财务&#x27;, 8000);insert into emp2 (ID, NAME, SEX, HIREDATE,BASE, DEPT, SAL)values (102, &#x27;李四&#x27;, &#x27;男&#x27;, to_date(&#x27;01-01-2012&#x27;, &#x27;dd-mm-yyyy&#x27;), &#x27;北京&#x27;,&#x27;营运&#x27;, 15000);insert into emp2 (ID, NAME, SEX, HIREDATE,BASE, DEPT, SAL)values (103, &#x27;王五&#x27;, &#x27;男&#x27;, to_date(&#x27;01-01-2013&#x27;, &#x27;dd-mm-yyyy&#x27;), &#x27;上海&#x27;,&#x27;营运&#x27;, 6000);insert into emp2 (ID, NAME, SEX, HIREDATE,BASE, DEPT, SAL)values (104, &#x27;赵六&#x27;, &#x27;男&#x27;, to_date(&#x27;01-01-2014&#x27;, &#x27;dd-mm-yyyy&#x27;), &#x27;上海&#x27;,&#x27;财务&#x27;, 10000);insert into emp2 (ID, NAME, SEX, HIREDATE,BASE, DEPT, SAL)values (105, &#x27;小花&#x27;, &#x27;女&#x27;, to_date(&#x27;01-08-2014&#x27;, &#x27;dd-mm-yyyy&#x27;), &#x27;上海&#x27;,&#x27;财务&#x27;, 4000);insert into emp2 (ID, NAME, SEX, HIREDATE,BASE, DEPT, SAL)values (106, &#x27;小静&#x27;, &#x27;女&#x27;, to_date(&#x27;01-01-2015&#x27;, &#x27;dd-mm-yyyy&#x27;), &#x27;北京&#x27;,&#x27;财务&#x27;, 6000);commit;\n\n\n\n3.   查看一下刚才插入的数据\nselect * from emp2;\n\n\n\n结果如下：\n|  ID | NAME | SEX |             HIREDATE | BASE | DEPT |   SAL ||-----|------|-----|----------------------|------|------|-------|| 107 |   小月 |   女 | 2013-09-01T00:00:00Z |   北京 |   营运 |  9000 || 108 |   小美 |   女 | 2011-06-01T00:00:00Z |   上海 |   营运 | 11000 || 101 |   张三 |   男 | 2011-01-01T00:00:00Z |   北京 |   财务 |  8000 || 102 |   李四 |   男 | 2012-01-01T00:00:00Z |   北京 |   营运 | 15000 || 103 |   王五 |   男 | 2013-01-01T00:00:00Z |   上海 |   营运 |  6000 || 104 |   赵六 |   男 | 2014-01-01T00:00:00Z |   上海 |   财务 | 10000 || 105 |   小花 |   女 | 2014-08-01T00:00:00Z |   上海 |   财务 |  4000 || 106 |   小静 |   女 | 2015-01-01T00:00:00Z |   北京 |   财务 |  6000 |\n\n4.   先看下普通分组的效果\n按照地区统计每个部门的总工资\nselect base, dept, sum(sal) from emp2 group by base, dept;\n\n\n\n结果如下：\n| BASE | DEPT | SUM(SAL) ||------|------|----------||   北京 |   营运 |    24000 ||   上海 |   营运 |    17000 ||   北京 |   财务 |    14000 ||   上海 |   财务 |    14000 |\n\nROLLUP(累计累加)\nROLLUP是对group by的扩展，因此，它只能出现在group by子句中，依赖于分组的列，对每个分组会生成汇总数据, rollup和group by联合一起使用，达到了按group by列顺序分组，并且实现小计和合计的功能。rollup分组还是有序的，先全部分组，然后对每个分组小计，最后合计。\n\n\nrollup中列的顺序不同，则统计的结果不同。因为它是按列从右递减分组的。\n\n\n比如 Group by ROLLUP(A, B, C)，首先会对**(A、B、C)进行GROUP BY，然后对group by进行GROUP BY，然后是(A)**进行GROUP BY，最后对全表进行GROUP BY操作\n\n按照地区统计每个部门的总工资，按工作母地汇总，再合计\nselect base, dept, sum(sal) from emp2 group by rollup(base, dept);\n\n 结果如下：\n|   BASE |   DEPT | SUM(SAL) ||--------|--------|----------||     上海 |     营运 |    17000 ||     上海 |     财务 |    14000 ||     上海 | (null) |    31000 ||     北京 |     营运 |    24000 ||     北京 |     财务 |    14000 ||     北京 | (null) |    38000 || (null) | (null) |    69000 |\n\n\n\n结果相当于\nselect base, dept, sum(sal)  from emp2 group by base, deptunion allselect base, null, sum(sal)  from emp2 group by base, null union all select null, null, sum(sal)  from emp2 group by null, null order by 1, 2;\n\n\n\n如果颠倒下rollup顺序则结果如下：\nselect base, dept, sum(sal) from emp2 group by rollup(dept,base);\n\n\n\n结果如下：\n|   BASE |   DEPT | SUM(SAL) ||--------|--------|----------||     上海 |     营运 |    17000 ||     北京 |     营运 |    24000 || (null) |     营运 |    41000 ||     上海 |     财务 |    14000 ||     北京 |     财务 |    14000 || (null) |     财务 |    28000 || (null) | (null) |    69000 |\n\n\n\n如果在实际查询中，有的小计或合计我们不需要，那么就要使用局部rollup,局部rollup就是将需要固定统计的列放在group by中，而不是放在rollup中。\nselect base, dept, sum(sal) from emp2 group by dept, rollup(base);\n\n\n\n结果如下：\n|   BASE | DEPT | SUM(SAL) ||--------|------|----------||     上海 |   营运 |    17000 ||     北京 |   营运 |    24000 || (null) |   营运 |    41000 ||     上海 |   财务 |    14000 ||     北京 |   财务 |    14000 || (null) |   财务 |    28000 |\n\n\n\n与group by rollup(dept, base)相比：去掉了最后一行的汇总，因为每次汇总要么是dept, base，要么是dept, null ，dept是固定的。\n如果只希望看到合计则可以这样写：\nselect base, dept, sum(sal) from emp2 group by rollup((base, dept));\n\n结果如下：\n|   BASE |   DEPT | SUM(SAL) ||--------|--------|----------||     上海 |     营运 |    17000 ||     上海 |     财务 |    14000 ||     北京 |     营运 |    24000 ||     北京 |     财务 |    14000 || (null) | (null) |    69000 |\n\nCUBE(交叉列表)\nCUBE也是对group by运算的一种扩展，它比rollup扩展更加精细，组合类型更多，rollup是按组合的列从右到左递减分组计算，而CUBE则是对所有可能的组合情况进行分组，这样分组的情况更多，覆盖所有的可能分组，并计算所有可能的分组的小计。\n\n\n对于CUBE来说，列的名字只要一样，那么顺序无所谓，结果都是一样的，因为cube是各种可能情况的组合,只不过统计的结果顺序不同而已。但是对于rollup来说，列的顺序不同，则结果不同。\n\n比如对工作母地和部门的交叉统计\nselect base, dept, sum(sal) from emp2 group by cube(base, dept) order by 1, 2;\n\n\n\n结果如下：\n|   BASE |   DEPT | SUM(SAL) ||--------|--------|----------||     上海 |     营运 |    17000 ||     上海 |     财务 |    14000 ||     上海 | (null) |    31000 ||     北京 |     营运 |    24000 ||     北京 |     财务 |    14000 ||     北京 | (null) |    38000 || (null) |     营运 |    41000 || (null) |     财务 |    28000 || (null) | (null) |    69000 |\n\n\n\n部分CUBE和部分ROLLUP类似，把需要固定统计的列放到group by中，不放到cube中就可以了。\n如果cube中只有一个列，那么和rollup的结果一致\nselect base, dept, sum(sal) from emp2 group by dept, cube(base) order by 1, 2;\n\n\n\n结果如下：\n|   BASE | DEPT | SUM(SAL) ||--------|------|----------||     上海 |   营运 |    17000 ||     上海 |   财务 |    14000 ||     北京 |   营运 |    24000 ||     北京 |   财务 |    14000 || (null) |   营运 |    41000 || (null) |   财务 |    28000 |\n\n\n\nrollup和cube区别：\n如果是ROLLUP(A,B, C)的话，GROUP BY顺序\n(A、B、C)\n(A、B)\n(A)\n最后对全表进行GROUPBY操作。\n如果是GROUP BY CUBE(A, B, C)，GROUP BY顺序(A、B、C)\n(A、B)\n(A、C)\n(A)，\n(B、C)\n(B)\n(C)，\n最后对全表进行GROUPBY操作。\nGROUPING SETS(小计)\n对group by的另一个扩展，专门对分组列分别进行小计计算，不包括合计。使用方式和rollup和cube一样，都是放在group by中。\n\n比如需要分别统计工作母地与部门的合计：\nselect base, dept, sum(sal) from emp2 group by grouping sets(base, dept);\n\n\n\n结果如下：\n|   BASE |   DEPT | SUM(SAL) ||--------|--------|----------||     上海 | (null) |    31000 ||     北京 | (null) |    38000 || (null) |     营运 |    41000 || (null) |     财务 |    28000 |\n\n\n\n等价于\nselect base, null, sum(sal)  from emp2 group by base, null union all select null, dept, sum(sal)  from emp2 group by null, dept;\n\n\n\n理解了grouping sets的原理我们用他实现rollup的功能也是可以的：\nselect base, dept, sum(sal) from emp2 group by grouping sets((base, dept), dept, null);\n\n\n\n结果如下：\n|   BASE |   DEPT | SUM(SAL) ||--------|--------|----------||     上海 |     营运 |    17000 ||     北京 |     营运 |    24000 || (null) |     营运 |    41000 ||     上海 |     财务 |    14000 ||     北京 |     财务 |    14000 || (null) |     财务 |    28000 || (null) | (null) |    69000 |\n\n\n\nGROUPING\n在以上例子中，是用rollup和cube函数都会对结果集产生null，这时候可用grouping函数来确认该记录是由哪个字段得出来的grouping函数用法，带一个参数，参数为字段名，结果是根据该字段得出来的就返回1，反之返回0\n\n例如：\nselect decode(grouping(base), 1, &#x27;所有地区&#x27;, base) base,       decode(grouping(dept), 1, &#x27;所有部门&#x27;, dept) dept,       sum(sal)  from emp2 group by rollup(dept, base);\n\n\n\n结果如下：\n| BASE | DEPT | SUM(SAL) ||------|------|----------||   上海 |   营运 |    17000 ||   北京 |   营运 |    24000 || 所有地区 |   营运 |    41000 ||   上海 |   财务 |    14000 ||   北京 |   财务 |    14000 || 所有地区 |   财务 |    28000 || 所有地区 | 所有部门 |    69000 |\n\n\n\n参考：\nhttps://blog.csdn.net/u014558001/article/details/42387929#\n","categories":["数据库","Oracle"],"tags":["Oracle","高级分组函数"]},{"title":"Oracle去重取第一条数据","url":"/%E6%95%B0%E6%8D%AE%E5%BA%93/Oracle/Oracle%E5%8E%BB%E9%87%8D%E5%8F%96%E7%AC%AC%E4%B8%80%E6%9D%A1%E6%95%B0%E6%8D%AE/","content":"\n问题：在项目中有一张设备检测信息表DEVICE_INFO, 每个设备每天都会产生一条检测信息，现在需要从该表中检索出每个设备的最新检测信息。也就是device_id字段不能重复，消除device_id字段重复的记录，而且要求device_id对应的检测信息test_result是最新的。\n\n解决思路：用Oracle的row_number() over()函数来解决该问题。\n解决过程：查看表中的重复记录select t.id, t.device_id, t.modify_date, t.test_result from device_info t;\n\n\n标记重复的记录select t.id,       t.device_id,       t.modify_date,       t.test_result,       row_number() over(PARTITION BY device_id ORDER BY modify_date desc) row_flag  from device_info t;\n\n\n过滤重复数据，取最新记录select id, device_id, modify_date, test_result  from (select t.id,               t.device_id,               t.modify_date,               t.test_result,               row_number() over(PARTITION BY device_id ORDER BY modify_date desc) row_flag          from device_info t) where row_flag = 1;\n\n\n总结row_number() over(PARTITION BY col1 ORDER BY col2 desc)表示根据 col1 分组，在分组内部根据 col2倒序排序，而此函数计算的值就表示每组内部排序后的顺序编号（组内连续的唯一的)。\n与rownum的区别在于：使用 rownum 进行排序的时候是先对结果集加入伪列rownum然后再进行排序，而此函数在包含排序从句后是先排序再计算行号码。\n\nrow_number()和rownum差不多，功能更强一点（可以在各个分组内从1开时排序）。\n\nrank()是跳跃排序，有两个第二名时接下来就是第四名（同样是在各个分组内）。\n\ndense_rank()是连续排序，有两个第二名时仍然跟着第三名。相比之下row_number是没有重复值的 。\n\n\n参考：\nhttp://blog.csdn.net/nux_123/article/details/45037719\n","categories":["数据库","Oracle"],"tags":["Oracle"]},{"title":"Mybatis 传参数","url":"/%E5%90%8E%E7%AB%AF/Mybatis/Mybatis%E4%BC%A0%E5%8F%82%E6%95%B0/","content":"#{}与${}注意以下两个符号的使用：\n\n**#{}**：MyBatis创建预处理语句属性从而设置安全的值（比如?）。常用作查询条件的值，例如：where name=#{value}。该参数可以指定一个确切的数据类型，\n例如： #{property,javaType=int,jdbcType=NUMERIC}. \n\n**${}**： MyBatis不会修改或转义字符串，将会直接在SQL语句中插入一个不改变的字符串，常用于拼凑sql的实体部分，例如：select * from ${tableName}\n\n\n在执行SQL时MyBatis会自动通过对象中的属性给SQL中参数赋值，它会自动将Java类型转换成数据库的类型。而一旦传入的是null它就无法准确判断这个类型应该是什么，就有可能将类型转换错误，从而报错。\n要解决这个问题，需要针对这些可能为空的字段，手动指定其转换时用到的类型。\n一般情况下，我们没有必要按个字段去识别/判断它是否可以为空，而是将所有的字段都当做可以为空，全部手动设置转换类型。\n#{} 会自动补单引号   order by ‘num asc’\n${} 不会自动补单引号 order by num asc\n\n参数是listOracle批量新增&lt;insert id=&quot;addBatch&quot; parameterType=&quot;list&quot;&gt;    insert into tb_gl_ypbg_clxx_gxc (id, bg_id, gxlx, car_no, car_track, del )    &lt;foreach collection=&quot;list&quot; item=&quot;item&quot; index=&quot;index&quot; separator=&quot;union all&quot;&gt;        select #&#123;item.id,jdbcType=VARCHAR&#125;, #&#123;item.bgId,jdbcType=VARCHAR&#125;,                #&#123;item.gxlx,jdbcType=VARCHAR&#125;, #&#123;item.carNo,jdbcType=VARCHAR&#125;,                #&#123;item.carTrack,jdbcType=VARCHAR&#125;, &#x27;0&#x27;        from dual    &lt;/foreach&gt;&lt;/insert&gt;\n\n\n\nOracle批量修改&lt;update id=&quot;updateBatch&quot; parameterType=&quot;list&quot;&gt;    &lt;foreach collection=&quot;list&quot; item=&quot;item&quot; index=&quot;index&quot; open=&quot;begin&quot; close=&quot;;end;&quot; separator=&quot;;&quot;&gt;        update tb_gl_ypbg_clxx_gxc        &lt;set&gt;            &lt;if test=&quot;item.gxlx != null and item.gxlx != &#x27;&#x27;&quot;&gt;                gxlx = #&#123;item.gxlx,jdbcType=VARCHAR&#125;,            &lt;/if&gt;            modify_username = #&#123;item.modifyPid,jdbcType=VARCHAR&#125;,            modify_truename = #&#123;item.modifyUser,jdbcType=VARCHAR&#125;,            modify_date = sysdate,            modify_unit = #&#123;item.modifyUnit,jdbcType=VARCHAR&#125;,            modify_unit_code = #&#123;item.modifyUnitCode,jdbcType=VARCHAR&#125;        &lt;/set&gt;        where id = #&#123;item.id,jdbcType=CHAR&#125; and del = &#x27;0&#x27;    &lt;/foreach&gt;&lt;/update&gt;\n\n\n\n批量删除&lt;delete id=&quot;deleteAjypYpbgByIds&quot; parameterType=&quot;list&quot;&gt;    delete from ajyp_ypbg where ASJBH in    &lt;foreach item=&quot;asjbh&quot; collection=&quot;list&quot; open=&quot;(&quot; separator=&quot;,&quot; close=&quot;)&quot;&gt;        #&#123;asjbh&#125;    &lt;/foreach&gt;&lt;/delete&gt;\n\n\n\n四种传参方式方式一、顺序传参mapper.java文件：\npublic User selectUser(String name, int deptId);\n\nmapper.xml文件：\n&lt;select id=&quot;selectUser&quot; resultType=&quot;com.wyj.entity.po.User&quot;&gt;\tselect * from user where userName = #&#123;0&#125; and deptId = #&#123;1&#125;&lt;/select&gt;\n\n注意：里面的数字代表你传入参数的顺序，不是特别建议使用这种方法传递参数，特别是参数个数多的时候\n方式二、注解@Param传参mapper.java文件：\npublic User selectUser(@Param(&quot;userName&quot;) String name, int @Param(&quot;deptId&quot;) id);\n\nmapper.xml文件：\n&lt;select id=&quot;selectUser&quot; resultType=&quot;com.wyj.entity.po.User&quot;&gt;\tselect * from user where userName = #&#123;userName&#125; and deptId = #&#123;deptId&#125;&lt;/select&gt;\n\n注意：在xml文件中就只能以在@Param注解中声明的参数名称获取参数\n方式三、Map集合传参mapper.java文件：\npublic User selectUser(Map&lt;String, Object&gt; params);\n\nmapper.xml文件：\n&lt;select id=&quot;selectUser&quot; parameterType=&quot;java.util.Map&quot; resultType=&quot;com.wyj.entity.po.User&quot;&gt;\tselect * from user where userName = #&#123;userName&#125; and deptId = #&#123;deptId&#125;&lt;/select&gt;\n\n方式四、JavaBean实体类传参mapper.java文件：\npublic User selectUser(User user);\n\nmapper.xml文件：\n&lt;select id=&quot;selectUser&quot; parameterType=&quot;com.wyj.entity.po.User&quot; resultType=&quot;com.wyj.entity.po.User&quot;&gt;\tselect * from user where userName = #&#123;userName&#125; and deptId = #&#123;deptId&#125;&lt;/select&gt;","categories":["后端","Mybatis"],"tags":["Mybatis"]},{"title":"iView 行列合并案例","url":"/%E5%89%8D%E7%AB%AF/Vue/iView%20%E8%A1%8C%E5%88%97%E5%90%88%E5%B9%B6%E6%A1%88%E4%BE%8B/","content":"行/列合并4.0.0 设置属性 span-method 可以指定合并行或列的算法。\n该方法参数为 4 个对象：\n\nrow: 当前行\ncolumn: 当前列\nrowIndex: 当前行索引\ncolumnIndex: 当前列索引\n\n该函数可以返回一个包含两个元素的数组，第一个元素代表 rowspan，第二个元素代表 colspan。 也可以返回一个键名为 rowspan 和 colspan 的对象。\n\n&lt;template&gt;    &lt;Table :columns=&quot;columns14&quot; :data=&quot;data5&quot; border :span-method=&quot;handleSpan&quot;&gt;&lt;/Table&gt;&lt;/template&gt;&lt;script&gt;    export default &#123;        data () &#123;            return &#123;                columns14: [                    &#123;                        title: &#x27;Date&#x27;,                        key: &#x27;date&#x27;                    &#125;,                    &#123;                        title: &#x27;Name&#x27;,                        key: &#x27;name&#x27;                    &#125;,                    &#123;                        title: &#x27;Age&#x27;,                        key: &#x27;age&#x27;                    &#125;,                    &#123;                        title: &#x27;Address&#x27;,                        key: &#x27;address&#x27;                    &#125;                ],                data5: [                    &#123;                        name: &#x27;John Brown&#x27;,                        age: 18,                        address: &#x27;New York No. 1 Lake Park&#x27;,                        date: &#x27;2016-10-03&#x27;                    &#125;,                    &#123;                        name: &#x27;Jim Green&#x27;,                        age: 24,                        address: &#x27;London No. 1 Lake Park&#x27;,                        date: &#x27;2016-10-01&#x27;                    &#125;,                    &#123;                        name: &#x27;Joe Black&#x27;,                        age: 30,                        address: &#x27;Sydney No. 1 Lake Park&#x27;,                        date: &#x27;2016-10-02&#x27;                    &#125;,                    &#123;                        name: &#x27;Jon Snow&#x27;,                        age: 26,                        address: &#x27;Ottawa No. 2 Lake Park&#x27;,                        date: &#x27;2016-10-04&#x27;                    &#125;                ]            &#125;        &#125;,        methods: &#123;            handleSpan (&#123; row, column, rowIndex, columnIndex &#125;) &#123;                if (rowIndex === 0 &amp;&amp; columnIndex === 0) &#123;                    return [1, 2];                &#125; else if (rowIndex === 0 &amp;&amp; columnIndex === 1) &#123;                    return  [0, 0];                &#125;                if (rowIndex === 2 &amp;&amp; columnIndex === 0) &#123;                    return &#123;                        rowspan: 2,                        colspan: 1                    &#125;;                &#125; else if (rowIndex === 3 &amp;&amp; columnIndex === 0) &#123;                    return &#123;                        rowspan: 0,                        colspan: 0                    &#125;;                &#125;            &#125;        &#125;    &#125;&lt;/script&gt;\n\n\n\n官方文档直接合并。现有一个需求，第一列数据相同才合并，不相同则不合并。\n完整代码如下\n&lt;template&gt;  &lt;div&gt;    &lt;!--span-method 是 iView 4.0以后才有的属性，用于合并行/列--&gt;    &lt;Table :columns=&quot;columns&quot; :data=&quot;tableData&quot; :span-method=&quot;handleSpan&quot;&gt;&lt;/Table&gt;  &lt;/div&gt;&lt;/template&gt;&lt;script&gt;  const KEY_NAME = &quot;name&quot;;  const KEY_ROWSPAN = &quot;rowSpan&quot;;  export default &#123;    data() &#123;      return &#123;        resultData: [],        tableData: [          // 见下文数据tableData        ],        columns: [          // 见下文columns        ]      &#125;;    &#125;,    mounted() &#123;      // 挂载的时候处理数据      this.formatData();    &#125;,    methods: &#123;      // 根据名字相同的数据算出rowspan        formatData() &#123;        var k = 0;        while (k &lt; this.tableData.length) &#123;          this.tableData[k][KEY_ROWSPAN] = 1;          for (var i = k + 1; i &lt;= this.tableData.length - 1; i++) &#123;            if (              this.tableData[k][KEY_NAME] === this.tableData[i][KEY_NAME] &amp;&amp;              this.tableData[k][KEY_NAME] !== &quot;&quot;            ) &#123;              this.tableData[k][KEY_ROWSPAN]++;            &#125; else &#123;              break;            &#125;          &#125;          k = i;        &#125;        this.resultData = this.tableData;      &#125;,      // 合并行/列      handleSpan (&#123; row, column, rowIndex, columnIndex &#125;) &#123;        if (columnIndex === 0) &#123;          if (row[KEY_ROWSPAN]) &#123;            return &#123;              rowspan: row[KEY_ROWSPAN],              colspan: 1            &#125;;          &#125; else &#123;            return &#123;              rowspan: 0,              colspan: 0            &#125;;          &#125;        &#125; else &#123;          return  [1, 1];        &#125;      &#125;    &#125;,  &#125;;&lt;/script&gt;&lt;style&gt;&lt;/style&gt;\n\n\n\n数据tableData\n[    &#123;        name: &quot;赵伟&quot;,        gender: &quot;男&quot;,        birthday: &quot;1963-7-9&quot;,        height: &quot;183&quot;,        email: &quot;zhao@gmail.com&quot;,        tel: &quot;156*****1987&quot;,        hobby: &quot;钢琴、书法、唱歌&quot;,        address: &quot;上海市黄浦区金陵东路569号17楼&quot;,        win: 100,        loss: 20    &#125;,    &#123;        name: &quot;赵伟&quot;,        gender: &quot;男&quot;,        birthday: &quot;1963-7-9&quot;,        height: &quot;183&quot;,        email: &quot;zhao@gmail.com&quot;,        tel: &quot;156*****1987&quot;,        hobby: &quot;钢琴、书法、唱歌&quot;,        address: &quot;上海市黄浦区金陵东路569号17楼&quot;,        win: 100,        loss: 30    &#125;,    &#123;        name: &quot;赵伟&quot;,        gender: &quot;男&quot;,        birthday: &quot;1963-7-9&quot;,        height: &quot;183&quot;,        email: &quot;zhao@gmail.com&quot;,        tel: &quot;156*****1987&quot;,        hobby: &quot;钢琴、书法、唱歌&quot;,        address: &quot;上海市黄浦区金陵东路569号17楼&quot;,        win: 100,        loss: 40    &#125;,    &#123;        name: &quot;李伟&quot;,        gender: &quot;男&quot;,        birthday: &quot;2003-12-7&quot;,        height: &quot;166&quot;,        email: &quot;li@gmail.com&quot;,        tel: &quot;182*****1538&quot;,        hobby: &quot;钢琴、书法、唱歌&quot;,        address: &quot;上海市奉贤区南桥镇立新路12号2楼&quot;,        win: 100,        loss: 10    &#125;,    &#123;        name: &quot;孙伟&quot;,        gender: &quot;女&quot;,        birthday: &quot;1993-12-7&quot;,        height: &quot;186&quot;,        email: &quot;sun@gmail.com&quot;,        tel: &quot;161*****0097&quot;,        hobby: &quot;钢琴、书法、唱歌&quot;,        address: &quot;上海市崇明县城桥镇八一路739号&quot;,        win: 100,        loss: 0    &#125;,    &#123;        name: &quot;周伟&quot;,        gender: &quot;女&quot;,        birthday: &quot;1993-12-7&quot;,        height: &quot;188&quot;,        email: &quot;zhou@gmail.com&quot;,        tel: &quot;197*****1123&quot;,        hobby: &quot;钢琴、书法、唱歌&quot;,        address: &quot;上海市青浦区青浦镇章浜路24号&quot;,        win: 100,        loss: 20    &#125;,    &#123;        name: &quot;周伟&quot;,        gender: &quot;女&quot;,        birthday: &quot;1993-12-7&quot;,        height: &quot;188&quot;,        email: &quot;zhou@gmail.com&quot;,        tel: &quot;197*****1123&quot;,        hobby: &quot;钢琴、书法、唱歌&quot;,        address: &quot;上海市青浦区青浦镇章浜路24号&quot;,        win: 100,        loss: 30    &#125;,    &#123;        name: &quot;周伟&quot;,        gender: &quot;女&quot;,        birthday: &quot;1993-12-7&quot;,        height: &quot;188&quot;,        email: &quot;zhou@gmail.com&quot;,        tel: &quot;197*****1123&quot;,        hobby: &quot;钢琴、书法、唱歌&quot;,        address: &quot;上海市青浦区青浦镇章浜路24号&quot;,        win: 100,        loss: 20    &#125;,    &#123;        name: &quot;吴伟&quot;,        gender: &quot;男&quot;,        birthday: &quot;1993-12-7&quot;,        height: &quot;160&quot;,        email: &quot;wu@gmail.com&quot;,        tel: &quot;183*****6678&quot;,        hobby: &quot;钢琴、书法、唱歌&quot;,        address: &quot;上海市松江区乐都西路867-871号&quot;,        win: 100,        loss: 40    &#125;,    &#123;        name: &quot;冯伟&quot;,        gender: &quot;女&quot;,        birthday: &quot;1993-12-7&quot;,        height: &quot;168&quot;,        email: &quot;feng@gmail.com&quot;,        tel: &quot;133*****3793&quot;,        hobby: &quot;钢琴、书法、唱歌&quot;,        address: &quot;上海市金山区龙胜路143号一层&quot;,        win: 100,        loss: 50    &#125;]\n\n\n\ncolumns\n[    &#123;        title: &quot;姓名&quot;,        key: &quot;name&quot;    &#125;,    &#123;        title: &quot;性别&quot;,        key: &quot;gender&quot;    &#125;,    &#123;        title: &quot;手机号码&quot;,        key: &quot;tel&quot;    &#125;,    &#123;        title: &quot;出生日期&quot;,        key: &quot;birthday&quot;    &#125;,    &#123;        title: &quot;爱好&quot;,        key: &quot;hobby&quot;    &#125;,    &#123;        title: &quot;地址&quot;,        key: &quot;address&quot;    &#125;]\n\n","categories":["前端","Vue"],"tags":["Vue","iView"]},{"title":"自定义SpringBoot Starter","url":"/%E5%90%8E%E7%AB%AF/SpringBoot/%E8%87%AA%E5%AE%9A%E4%B9%89SpringBoot%20Starter/","content":"引言这篇文章的话我们就自己来实现一个SpringBoot的 starter吧。废话不多说我们还是直入主题吧。什么是Spring Boot Starter呢?我们直接来看看官网是怎么介绍的吧。\n\n❝\nStarters are a set of convenient dependency descriptors that you can include in your application. You get a one-stop shop for all the Spring and related technologies that you need without having to hunt through sample code and copy-paste loads of dependency descriptors. For example, if you want to get started using Spring and JPA for database access, include the spring-boot-starter-data-jpa dependency in your project.\n❞\n\n纳尼，一大堆的英文，这还有兴趣接着往下看吗？是不是看到这直接退出了。都到门口了，不进来喝杯茶再走嘛？看都看到这了还是接着继续往下看吧。我们先不解释这一段话是什么意思，我们可以看看starter的出现给我们解决了什么问题。我们还是以上述官网的例子来进行说明比如说我们需要在Spring 中适应JPA来操作数据库。在没有springBoot-starter之前，我们需要引入jpa的步骤\n\n通过maven 引入jdbc的依赖、以及jpa相关的各种依赖\n编写jpa相关的配置文件\n网上各种查询找资料进行调试，调试的过程对于新手可能会有点奔溃会遇到各种奇奇怪怪的问题，jar包冲突啊，这个jar包下载不下来，缺少某个jar包。\n终于在经历千辛万苦，哼次哼次的解决各种问题之后终于把项目跑起来了，然后把这次整合jpa遇到的问题，以及整合的步骤都一一的详细记录下来。方便下次在需要整合jpa的时候直接copy就好了。我们以前在没有starter之前是不是都是这么玩的。这样的缺点是不是也非常显著，比如过程复杂、需要不停的粘贴复制（不过这是程序员经常干的事情了，也不在乎多一两次了）、整合其它组件到自己的项目变的困难，效率低下。这也就造成了996的程序员比较多了(晚上就不能够回去69了)。\n\n\n我们可以看下SpringBoot 现在都为我们提供有哪些starter，我这边这截图了部分starter，更多的请点击https://github.com/spring-projects/spring-boot/tree/master/spring-boot-project/spring-boot-starters\n\nstarter的实现：虽然我们每个组件的starter实现各有差异，但是它们基本上都会使用到两个相同的内容：ConfigurationProperties和AutoConfiguration。因为Spring Boot提倡“「约定大于配置」”这一理念，所以我们使用ConfigurationProperties来保存我们的配置，并且这些配置都可以有一个默认值，即在我们没有主动覆写原始配置的情况下，默认值就会生效。除此之外，starter的ConfigurationProperties还使得所有的配置属性被聚集到一个文件中（一般在resources目录下的application.properties），这样我们就告别了Spring项目中XML地狱。starter的出现帮把我们把各种复杂的配置都封装起来了，让我们真正的可以达到了开箱即用。不仅降低了我们使用它的门槛，并且还大大提高了我们的开发效率。正如前面所说《SpringBoot自动装配》让我们有更多的时间去陪女朋友。\n命名规范如果你快有孩子了，出生前你比较急的一定是起个名字。孩子的姓名标识着你和你爱人的血统，一定不会起隔壁老王的姓氏，肯定会招来异样的眼光。在maven中，groupId代表着姓氏，artifactId代表着名字。Spring Boot也是有一个命名的建议的。所以名字是不能够随随便便取得，可以按照官方的建议来取。\n\n❝\nWhat’s in a name All official starters follow a similar naming pattern; spring-boot-starter-*, where * is a particular type of application. This naming structure is intended to help when you need to find a starter. The Maven integration in many IDEs lets you search dependencies by name. For example, with the appropriate Eclipse or STS plugin installed, you can press ctrl-space in the POM editor and type “spring-boot-starter” for a complete list. As explained in the “Creating Your Own Starter” section, third party starters should not start with spring-boot, as it is reserved for official Spring Boot artifacts. Rather, a third-party starter typically starts with the name of the project. For example, a third-party starter project called thirdpartyproject would typically be named thirdpartyproject-spring-boot-starter.\n❞\n\n大概意思是 官方的 starter 的命名格式为 spring-boot-starter-&#123;xxxx&#125; 比如spring-boot-starter-activemq第三方我们自己的命名格式为 &#123;xxxx&#125;-spring-boot-starter。比如mybatis-spring-boot-starter。如果我们忽略这种约定，是不是会显得我们写的东西不够“专业“。\n自定义Starter下面我们就来实现一个自定义的发送短信的starter，命名为sms-spring-boot-starter。\n「引入pom」&lt;dependency&gt;    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;    &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt;    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;    &lt;artifactId&gt;spring-boot-configuration-processor&lt;/artifactId&gt;    &lt;optional&gt;true&lt;/optional&gt;&lt;/dependency&gt;&lt;dependency&gt;    &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;    &lt;artifactId&gt;lombok&lt;/artifactId&gt;    &lt;version&gt;1.16.18&lt;/version&gt;    &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt;\n\n\n\n「编写配置文件」发短信我们需要配置一些账号信息，不同的短信供应商，账户信息是不一样的，所以我们需要定义一个XXXXProperties 来自动装配这些账户信息。下面我们就以腾讯云和阿里云两家供应商为例；\n@EnableConfigurationProperties(value = SmsProperties.class)@Configurationpublic class SmsAutoConfiguration  &#123;    /**     *  阿里云发送短信的实现类     * @param smsProperties     * @return     */    @Bean    public AliyunSmsSenderImpl aliYunSmsSender(SmsProperties smsProperties)&#123;       return new AliyunSmsSenderImpl(smsProperties.getAliyun());    &#125;    /**     * 腾讯云发送短信的实现类     * @param smsProperties     * @return     */    @Bean    public TencentSmsSenderImpl tencentSmsSender(SmsProperties smsProperties)&#123;        return new TencentSmsSenderImpl(smsProperties.getTencent());    &#125;&#125;\n\n如果需要在其他项目中使用发送短信功能的话，我们只需要在配置文件(application.yml）中配置SmsProperties 的属性信息就可以了。 比如：\nsms:  aliyun:    pass-word: 12345    user-name: java金融    sign: 阿里云    url: http://aliyun.com/send  tencent:    pass-word: 6666    user-name: java金融    sign: 腾讯云    url: http://tencent.com/send\n\n还记的@ConfigurationProperties注解里面是不是有个prefix 属性，我们配置的这个属性是sms，配置这个的主要一个作用的话是主要用来区别各个组件的参数。这里有个小知识点需要注意下当我们在配置文件输入sms我们的idea会提示这个sms有哪些属性可以配置，以及每个属性的注释都有标记，建议的话注释还是写英文，这样会显得你比较专业。\n这个提示的话，是需要引入下面这个jar的。\n &lt;dependency&gt;     &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;     &lt;artifactId&gt;spring-boot-configuration-processor&lt;/artifactId&gt;     &lt;optional&gt;true&lt;/optional&gt;&lt;/dependency&gt;\n\n引入这个jar之后，我们编译之后就会在META-INF文件夹下面生成一个spring-configuration-metadata.json的文件。我们可以看到这个文件其实 是根据SmsProperties类的成员属性来生成的。\n「编写自动配置类」@EnableConfigurationProperties(value = SmsProperties.class)@Configurationpublic class SmsAutoConfiguration  &#123;    /**     *  阿里云发送短信的实现类     * @param smsProperties     * @return     */    @Bean    public AliyunSmsSenderImpl aliYunSmsSender(SmsProperties smsProperties)&#123;       return new AliyunSmsSenderImpl(smsProperties.getAliyun());    &#125;    /**     * 腾讯云发送短信的实现类     * @param smsProperties     * @return     */    @Bean    public TencentSmsSenderImpl tencentSmsSender(SmsProperties smsProperties)&#123;        return new TencentSmsSenderImpl(smsProperties.getTencent());    &#125;&#125;\n\n\n\n编写我们的发送短信实现类：\npublic class AliyunSmsSenderImpl implements SmsSender &#123;    private SmsMessage smsMessage;    public AliyunSmsSenderImpl(SmsMessage smsProperties) &#123;        this.smsMessage = smsProperties;    &#125;    @Override    public boolean send(String message) &#123;        System.out.println(smsMessage.toString()+&quot;开始发送短信==》短信内容：&quot;+message);        return true;    &#125;&#125;\n\n\n\n「让starter生效」starter集成应用有两种方式：\n\n被动生效 我们首先来看下我们熟悉的方式，通过SpringBoot的SPI的机制来去加载我们的starter。我们需要在META-INF下新建一个spring.factories文件key为org.springframework.boot.autoconfigure.EnableAutoConfiguration， value是我们的SmsAutoConfiguration 全限定名（「记得去除前后的空格，否则会不生效」）。\norg.springframework.boot.autoconfigure.EnableAutoConfiguration=\\com.valten.sms.SmsAutoConfiguration\n\n\n\n主动生效 在starter组件集成到我们的Spring Boot应用时需要主动声明启用该starter才生效，通过自定义一个@Enable注解然后在把自动配置类通过Import注解引入进来。\n\n\n@Target(&#123;ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Import(&#123;SmsAutoConfiguration.class&#125;)public @interface EnableSms &#123;    &#125;\n\n使用的时候需要在启动类上面开启这个注解。\n「打包，部署到仓库」如果是本地的话，直接通过mvn install命令就可以了。如果需要部署到公司的仓库话，这个就不说了。\n「使用starter」新建一个新的SpringBoot项目引入我们刚写的starter\n&lt;dependency&gt;    &lt;groupId&gt;com.valten.sms&lt;/groupId&gt;    &lt;artifactId&gt;sms-spring-boot-starter&lt;/artifactId&gt;    &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;&lt;/dependency&gt;\n\n\n\n在项目配置文件配上短信账号信息\nsms:  aliyun:    pass-word: 12345    user-name: java金融    sign: 阿里云    url: http://aliyun.com/send  tencent:    pass-word: 6666    user-name: java金融    sign: 腾讯云    url: http://tencent.com/send\n\n\n\n测试代码\n@SpringBootApplication@EnableSmspublic class Application &#123;    public static void main(String[] args) &#123;        ConfigurableApplicationContext context = SpringApplication.run(Application.class, args);        AliyunSmsSenderImpl aliyunSmsSender = context.getBean(AliyunSmsSenderImpl.class);        aliyunSmsSender.send(&quot;用阿里云发送短信&quot;);        TencentSmsSenderImpl tencentSmsSender = context.getBean(TencentSmsSenderImpl.class);        tencentSmsSender.send(&quot;用腾讯云发送短信&quot;);    &#125;&#125;\n\n运行结果：\nSmsMessage&#123;userName=&#x27;java金融&#x27;, passWord=&#x27;12345&#x27;, sign=&#x27;阿里云&#x27;, url=&#x27;http://aliyun.com/send&#x27;&#125;开始发送短信==》短信内容：用阿里云发送短信SmsMessage&#123;userName=&#x27;java金融&#x27;, passWord=&#x27;6666&#x27;, sign=&#x27;腾讯云&#x27;, url=&#x27;http://tencent.com/send&#x27;&#125;开始发送短信==》短信内容：用腾讯云发送短信\n\n至此的话我们自定义的一个starter就已经完成了，这个starter只是一个演示的demo，代码有点粗糙,项目结构也有点问题。重点看下这个实现原理就好。赶紧动动小手去实现一个自己的starter吧。\n总结\nSpringBoot starter的出现，让我们项目中集成其他组件变得简单。它把简单给了别人，把复杂留给了自己。“牺牲小我，成就大我”的思想还是值得学习的。平时我们工作中，比如要开发一个组件、或者一个工具类，也应该尽可能的让使用方可以做到无脑使用，不要搞的太复杂，又能让使用者可以灵活扩展。\n\n","categories":["后端","SpringBoot"],"tags":["SpringBoot","Starter"]},{"title":"Nginx 反向代理配置","url":"/%E6%8A%80%E6%9C%AF%E6%95%99%E7%A8%8B/Nginx/Nginx%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86%E9%85%8D%E7%BD%AE/","content":" Nginx是一款轻量级的Web服务器、反向代理服务器，由于它的内存占用少，启动极快，高并发能力强，在互联网项目中广泛应用。 \n\n上图基本上说明了当下流行的技术架构，其中Nginx有点入口网关的味道。\n反向代理经常听人说到一些术语，如反向代理，那么什么是反向代理，什么又是正向代理呢？\n\n正向代理：\n\n\n反向代理：\n\n由于防火墙的原因，我们并不能直接访问谷歌，那么我们可以借助XXX来实现，这就是一个简单的正向代理的例子。这里你能够发现，正向代理“代理”的是客户端，而且客户端是知道目标的，而目标是不知道客户端是通过XXX访问的。\n当我们在外网访问百度的时候，其实会进行一个转发，代理到内网去，这就是所谓的反向代理，即反向代理“代理”的是服务器端，而且这一个过程对于客户端而言是透明的。\n\n\nlocation该指令用于匹配 URL。\n语法规则： location [=|~|~*|^~] /uri/ &#123; … &#125;\n\n= 开头表示精确匹配\n^~ 开头表示uri以某个常规字符串开头，理解为匹配 url路径即可。nginx不对url做编码，因此请求为/static/20%/aa，可以被规则^~ /static/ /aa匹配到（注意是空格）。以xx开头\n~ 开头表示区分大小写的正则匹配           以xx结尾\n~* 开头表示不区分大小写的正则匹配        以xx结尾\n!~和!~*分别为区分大小写不匹配及不区分大小写不匹配 的正则\n/ 通用匹配，任何请求都会匹配到。\n\n多个location配置的情况下匹配顺序为（参考资料而来，还未实际验证，试试就知道了，不必拘泥，仅供参考）：\n\n注意：如果 uri 包含正则表达式，则必须要有 ~ 或者 ~* 标识。\n\n首先精确匹配 = ，其次以xx开头匹配 ^~ ， 然后是按文件中顺序的正则匹配，最后是交给 / 通用匹配。\n当有匹配成功时候，停止匹配，按当前匹配规则处理请求。\nlocaltion实例location = / &#123;   #规则A&#125;location = /login &#123;   #规则B&#125;location ^~ /static/ &#123;   #规则C&#125;location ~ \\.(gif|jpg|png|js|css)$ &#123;   #规则D，注意：是根据括号内的大小写进行匹配。括号内全是小写，只匹配小写&#125;location ~* \\.png$ &#123;   #规则E&#125;location !~ \\.xhtml$ &#123;   #规则F&#125;location !~* \\.xhtml$ &#123;   #规则G&#125;location / &#123;   #规则H&#125;\n\n那么产生的效果如下：\n访问根目录/， 比如 http://localhost/  将匹配规则A\n访问 http://localhost/login 将匹配规则B，http://localhost/register 则匹配规则H\n访问 http://localhost/static/a.html 将匹配规则C\n访问 http://localhost/a.gif, http://localhost/b.jpg 将匹配规则D和规则E，但是规则D顺序优先，规则E不起作用， 而 http://localhost/static/c.png 则优先匹配到 规则C\n访问 http://localhost/a.PNG 则匹配规则E， 而不会匹配规则D，因为规则E不区分大小写。\n访问 http://localhost/a.xhtml 不会匹配规则F和规则G，\nhttp://localhost/a.XHTML不会匹配规则G，（因为!）。规则F，规则G属于排除法，符合匹配规则也不会匹配到，所以想想看实际应用中哪里会用到。\n访问 http://localhost/category/id/1111 则最终匹配到规则H，因为以上规则都不匹配，这个时候nginx转发请求给后端应用服务器，比如FastCGI（php），tomcat（jsp），nginx作为方向代理服务器存在。\n所以实际使用中，个人觉得至少有三个匹配规则定义，如下：\n#直接匹配网站根，通过域名访问网站首页比较频繁，使用这个会加速处理，官网如是说。#这里是直接转发给后端应用服务器了，也可以是一个静态首页# 第一个必选规则location = / &#123;    proxy_pass http://tomcat:8080/index&#125; # 第二个必选规则是处理静态文件请求，这是nginx作为http服务器的强项# 有两种配置模式，目录匹配或后缀匹配,任选其一或搭配使用location ^~ /static/ &#123;                              //以xx开头    root /webroot/static/;&#125;location ~* \\.(gif|jpg|jpeg|png|css|js|ico)$ &#123;     //以xx结尾    root /webroot/res/;&#125; #第三个规则就是通用规则，用来转发动态请求到后端应用服务器#非静态文件请求就默认是动态请求，自己根据实际把握location / &#123;    proxy_pass http://tomcat:8080/&#125;\n\n\n\nproxy_pass该指令用于设置被代理服务器的地址。可以是主机名称、IP地址加端口号的形式。\n语法如下：\nproxy_pass URL;\n\nURL 为被代理服务器的地址，可以包含传输协议、主机名称或IP地址加端口号，URI等。\nproxy_pass  http://www.123.com/url;\n\n\n\nproxy_pass实例在nginx中配置proxy_pass时，当在后面的url加上了/，相当于是绝对根路径，则nginx不会把location中匹配的路径部分代理走；如果没有/，则会把匹配的路径部分也给代理走。 \n下面四种情况分别用http://192.168.1.4/proxy/test.html 进行访问。 \n第一种：\nlocation /proxy/ &#123;     proxy_pass http://127.0.0.1:81/;&#125;\n\n 会被代理到  http://127.0.0.1:81/test.html\n第二种：\nlocation /proxy/ &#123;     proxy_pass http://127.0.0.1:81;&#125;\n\n 会被代理到  http://127.0.0.1:81/proxy/test.html  \n第三种：\nlocation /proxy/ &#123;     proxy_pass http://127.0.0.1:81/ftlynx/;&#125;\n\n 会被代理到  http://127.0.0.1:81/ftlynx/test.html\n第四种 (相对于第三种，最后少一个 / ) ：\nlocation /proxy/ &#123;     proxy_pass http://127.0.0.1:81/ftlynx;&#125;\n\n 会被代理到  http://127.0.0.1:81/ftlynxtest.html \nrewriterewrite功能就是，使用nginx提供的全局变量或自己设置的变量，结合正则表达式和标志位实现url重写以及重定向。rewrite只能放在server{},location{},if{}中，并且只能对域名后边的除去传递的参数外的字符串起作用，例如 http://seanlook.com/a/we/index.php?id=1&amp;u=str 只对/a/we/index.php重写。语法rewrite regex replacement [flag];\n如果相对域名或参数字符串起作用，可以使用全局变量匹配，也可以使用proxy_pass反向代理。\n表明看rewrite和location功能有点像，都能实现跳转，主要区别在于rewrite是在同一域名内更改获取资源的路径，而location是对一类路径做控制访问或反向代理，可以proxy_pass到其他机器。很多情况下rewrite也会写在location里，它们的执行顺序是：\n\n执行server块的rewrite指令\n执行location匹配\n执行选定的location中的rewrite指令\n\n如果其中某步URI被重写，则重新循环执行1-3，直到找到真实存在的文件；循环超过10次，则返回500 Internal Server Error错误。\nflag标志位\nlast : 相当于Apache的[L]标记，表示完成rewrite\nbreak : 停止执行当前虚拟主机的后续rewrite指令集\nredirect : 返回302临时重定向，地址栏会显示跳转后的地址\npermanent : 返回301永久重定向，地址栏会显示跳转后的地址\n\n因为301和302不能简单的只返回状态码，还必须有重定向的URL，这就是return指令无法返回301,302的原因了。这里 last 和 break 区别有点难以理解：\n\nlast一般写在server和if中，而break一般使用在location中\nlast不终止重写后的url匹配，即新的url会再从server走一遍匹配流程，而break终止重写后的匹配\nbreak和last都能组织继续执行后面的rewrite指令\n\nif判断指令语法为if(condition)&#123;...&#125;，对给定的条件condition进行判断。如果为真，大括号内的rewrite指令将被执行，if条件(conditon)可以是如下任何内容：\n\n当表达式只是一个变量时，如果值为空或任何以0开头的字符串都会当做false\n直接比较变量和内容时，使用=或!=\n~正则表达式匹配，~*不区分大小写的匹配，!~区分大小写的不匹配\n\n-f和!-f用来判断是否存在文件-d和!-d用来判断是否存在目录-e和!-e用来判断是否存在文件或目录-x和!-x用来判断文件是否可执行\n例如：\nif ($http_user_agent ~ MSIE) &#123;    rewrite ^(.*)$ /msie/$1 break;&#125; //如果UA包含&quot;MSIE&quot;，rewrite请求到/msid/目录下if ($http_cookie ~* &quot;id=([^;]+)(?:;|$)&quot;) &#123;    set $id $1; &#125; //如果cookie匹配正则，设置变量$id等于正则引用部分if ($request_method = POST) &#123;    return 405;&#125; //如果提交方法为POST，则返回状态405（Method not allowed）。return不能返回301,302if ($slow) &#123;    limit_rate 10k;&#125; //限速，$slow可以通过 set 指令设置if (!-f $request_filename)&#123;    break;    proxy_pass  http://127.0.0.1; &#125; //如果请求的文件名不存在，则反向代理到localhost 。这里的break也是停止rewrite检查if ($args ~ post=140)&#123;    rewrite ^ http://example.com/ permanent;&#125; //如果query string中包含&quot;post=140&quot;，永久重定向到example.comlocation ~* \\.(gif|jpg|png|swf|flv)$ &#123;    valid_referers none blocked www.jefflei.com www.leizhenfang.com;    if ($invalid_referer) &#123;        return 404;    &#125; //防盗链&#125;\n\n全局变量下面是可以用作if判断的全局变量\n\n$args ： #这个变量等于请求行中的参数，同$query_string\n$content_length ： 请求头中的Content-length字段。\n$content_type ： 请求头中的Content-Type字段。\n$document_root ： 当前请求在root指令中指定的值。\n$host ： 请求主机头字段，否则为服务器名称。\n$http_user_agent ： 客户端agent信息\n$http_cookie ： 客户端cookie信息\n$limit_rate ： 这个变量可以限制连接速率。\n$request_method ： 客户端请求的动作，通常为GET或POST。\n$remote_addr ： 客户端的IP地址。\n$remote_port ： 客户端的端口。\n$remote_user ： 已经经过Auth Basic Module验证的用户名。\n$request_filename ： 当前请求的文件路径，由root或alias指令与URI请求生成。\n$scheme ： HTTP方法（如http，https）。\n$server_protocol ： 请求使用的协议，通常是HTTP/1.0或HTTP/1.1。\n$server_addr ： 服务器地址，在完成一次系统调用后可以确定这个值。\n$server_name ： 服务器名称。\n$server_port ： 请求到达服务器的端口号。\n$request_uri ： 包含请求参数的原始URI，不包含主机名，如：”/foo/bar.php?arg=baz”。\n$uri ： 不带请求参数的当前URI，$uri不包含主机名，如”/foo/bar.html”。\n$document_uri ： 与$uri相同。\n\n例：http://localhost:88/test1/test2/test.php$host：localhost$server_port：88$request_uri：http://localhost:88/test1/test2/test.php$document_uri：/test1/test2/test.php$document_root：/var/www/html$request_filename：/var/www/html/test1/test2/test.php\n常用正则\n. ： 匹配除换行符以外的任意字符\n? ： 重复0次或1次\n+ ： 重复1次或更多次\n* ： 重复0次或更多次\n\\d ：匹配数字\n^ ： 匹配字符串的开始\n$ ： 匹配字符串的介绍\n&#123;n&#125; ： 重复n次\n&#123;n,&#125; ： 重复n次或更多次\n[c] ： 匹配单个字符c\n[a-z] ： 匹配a-z小写字母的任意一个\n\n小括号()之间匹配的内容，可以在后面通过$1来引用，$2表示的是前面第二个()里的内容。正则里面容易让人困惑的是\\转义特殊字符。\nrewrite实例例1：\nhttp &#123;    # 定义image日志格式    log_format imagelog &#x27;[$time_local] &#x27; $image_file &#x27; &#x27; $image_type &#x27; &#x27; $body_bytes_sent &#x27; &#x27; $status;    # 开启重写日志    rewrite_log on;    server &#123;        root /home/www;        location / &#123;                # 重写规则信息                error_log logs/rewrite.log notice;                 # 注意这里要用‘’单引号引起来，避免&#123;&#125;                rewrite &#x27;^/images/([a-z]&#123;2&#125;)/([a-z0-9]&#123;5&#125;)/(.*)\\.(png|jpg|gif)$&#x27; /data?file=$3.$4;                # 注意不能在上面这条规则后面加上“last”参数，否则下面的set指令不会执行                set $image_file $3;                set $image_type $4;        &#125;        location /data &#123;                # 指定针对图片的日志格式，来分析图片类型和大小                access_log logs/images.log mian;                root /data/images;                # 应用前面定义的变量。判断首先文件在不在，不在再判断目录在不在，如果还不在就跳转到最后一个url里                try_files /$arg_file /image404.html;        &#125;        location = /image404.html &#123;                # 图片不存在返回特定的信息                return 404 &quot;image not found\\n&quot;;        &#125;&#125;\n\n对形如/images/ef/uh7b3/test.png的请求，重写到/data?file=test.png，于是匹配到location /data，先看/data/images/test.png文件存不存在，如果存在则正常响应，如果不存在则重写tryfiles到新的image404 location，直接返回404状态码。\n例2：\nrewrite ^/images/(.*)_(\\d+)x(\\d+)\\.(png|jpg|gif)$ /resizer/$1.$4?width=$2&amp;height=$3? last;\n\n对形如/images/bla_500x400.jpg的文件请求，重写到/resizer/bla.jpg?width=500&amp;height=400地址，并会继续尝试匹配location。\n例3：\n# 多目录转成参数# abc.domian.com/sort/2 =&gt; abc.domian.com/index.php?act=sort&amp;name=abc&amp;id=2if ($host ~* (.*)\\.domain\\.com) &#123;    set $sub_name $1;       rewrite ^/sort\\/(\\d+)\\/?$ /index.php?act=sort&amp;cid=$sub_name&amp;id=$1 last;&#125;# 目录对换# /123456/xxxx -&gt; /xxxx?id=123456rewrite ^/(\\d+)/(.+)/ /$2?id=$1 last;# 使用ie的使用重定向到/nginx-ie目录下：if ($http_user_agent ~ MSIE) &#123;    rewrite ^(.*)$ /nginx-ie/$1 break;&#125;# 目录自动加 &quot;/&quot;if (-d $request_filename)&#123;    rewrite ^/(.*)([^/])$ http://$host/$1$2/ permanent;&#125;# 禁止htlocation ~/\\.ht &#123;    deny all;&#125;# 禁止多个目录location ~ ^/(cron|templates)/ &#123;    deny all;    break;&#125;# 禁止以/data开头的文件# 可以禁止/data/下多级目录下.log.txt等请求;location ~ ^/data &#123;    deny all;&#125;# 禁止单个目录# 不能禁止.log.txt能请求location /searchword/cron/ &#123;    deny all;&#125;# 禁止单个文件location ~ /data/sql/data.sql &#123;    deny all;&#125;# 给favicon.ico和robots.txt设置过期时间;# 这里为favicon.ico为99 天,robots.txt为7天并不记录404错误日志location ~(favicon.ico) &#123;    log_not_found off;    expires 99d;    break;&#125;location ~(robots.txt) &#123;    log_not_found off;    expires 7d;    break;&#125;# 设定某个文件的过期时间;这里为600秒，并不记录访问日志location ^~ /html/scripts/loadhead_1.js &#123;    access_log   off;    root /opt/lampp/htdocs/web;    expires 600;    break;&#125;# 文件反盗链并设置过期时间# 这里的return 412 为自定义的http状态码，默认为403，方便找出正确的盗链的请求# “rewrite ^/ http://leech.c1gstudio.com/leech.gif;”显示一张防盗链图片# “access_log off;”不记录访问日志，减轻压力# “expires 3d”所有文件3天的浏览器缓存location ~* ^.+\\.(jpg|jpeg|gif|png|swf|rar|zip|css|js)$ &#123;    valid_referers none blocked *.c1gstudio.com *.c1gstudio.net localhost 208.97.167.194;    if ($invalid_referer) &#123;        rewrite ^/ http://leech.c1gstudio.com/leech.gif;        return 412;        break;    &#125;    access_log   off;    root /opt/lampp/htdocs/web;    expires 3d;    break;&#125;# 只充许固定ip访问网站，并加上密码root  /opt/htdocs/www;allow   208.97.167.194;allow   222.33.1.2;allow   231.152.49.4;deny    all;auth_basic &quot;C1G_ADMIN&quot;;auth_basic_user_file htpasswd;# 将多级目录下的文件转成一个文件，增强seo效果# /job-123-456-789.html 指向/job/123/456/789.htmlrewrite ^/job-([0-9]+)-([0-9]+)-([0-9]+)\\.html$ /job/$1/$2/$3.html last;# 将根目录下某个文件夹指向2级目录# 如/shanghaijob/ 指向 /area/shanghai/# 如果你将last改成permanent，那么浏览器地址栏显是 /location/shanghai/rewrite ^/([0-9a-z]+)job/(.*)$ /area/$1/$2 last;# 上面例子有个问题是访问/shanghai 时将不会匹配rewrite ^/([0-9a-z]+)job$ /area/$1/ last;rewrite ^/([0-9a-z]+)job/(.*)$ /area/$1/$2 last;# 这样/shanghai 也可以访问了，但页面中的相对链接无法使用，# 如./list_1.html真实地址是/area/shanghia/list_1.html会变成/list_1.html,导至无法访问。# 那我加上自动跳转也是不行咯# (-d $request_filename)它有个条件是必需为真实目录，而我的rewrite不是的，所以没有效果if (-d $request_filename)&#123;    rewrite ^/(.*)([^/])$ http://$host/$1$2/ permanent;&#125;# 知道原因后就好办了，让我手动跳转吧rewrite ^/([0-9a-z]+)job$ /$1job/ permanent;rewrite ^/([0-9a-z]+)job/(.*)$ /area/$1/$2 last;# 文件和目录不存在的时候重定向：if (!-e $request_filename) &#123;    proxy_pass http://127.0.0.1;&#125;# 域名跳转server &#123;    listen       80;    server_name  jump.c1gstudio.com;    index index.html index.htm index.php;    root  /opt/lampp/htdocs/www;    rewrite ^/ http://www.c1gstudio.com/;    access_log  off;&#125;# 多域名转向server_name  www.c1gstudio.com www.c1gstudio.net;index index.html index.htm index.php;root  /opt/lampp/htdocs;if ($host ~ &quot;c1gstudio\\.net&quot;) &#123;    rewrite ^(.*) http://www.c1gstudio.com$1 permanent;&#125;# 三级域名跳转if ($http_host ~* &quot;^(.*)\\.i\\.c1gstudio\\.com$&quot;) &#123;    rewrite ^(.*) http://top.yingjiesheng.com$1;    break;&#125;# 域名镜向server &#123;    listen       80;    server_name  mirror.c1gstudio.com;    index index.html index.htm index.php;    root  /opt/lampp/htdocs/www;    rewrite ^/(.*) http://www.c1gstudio.com/$1 last;    access_log  off;&#125;\n\n\n\ntry_files\n其作用是按顺序检查文件是否存在，返回第一个找到的文件或文件夹(结尾加斜线表示为文件夹)，如果所有的文件或文件夹都找不到，会进行一个内部重定向到最后一个参数。\n需要注意的是，只有最后一个参数可以引起一个内部重定向，之前的参数只设置内部URI的指向。最后一个参数是回退URI且必须存在，否则会出现内部500错误。命名的location也可以使用在最后一个参数中。与rewrite指令不同，如果回退URI不是命名的location那么$args不会自动保留，如果你想保留$args，则必须明确声明。\n\nserver &#123;    listen 80;    server_name api.xxx.com;    root /mnt/try;        location / &#123;        add_header Content-Type &#x27;text/html; charset=utf-8&#x27;;        #echo $uri;        try_files $uri @default;    &#125;        location @default &#123;        root /mnt/default;    &#125;&#125;\n\n@default：定义一个location段，不能被外部请求所访问，只能用于nginx内部配置指令使用，比如 try_files、error_page。\n浏览器访问 http://api.xxx.com/abc/index.html 时，当前的$uri值为/abc/index.html\n# try_files作用：先尝试去/mnt/try目录下找abc目录下的index.html，如果有，直接返回，没有的话则跳转到@default部分（内部重定向）。在default部分会去/mnt/default目录下找abc目录下的index.html，有，直接返回，没有就返回404错误。try_files可以理解为实现rewrite的作用。\n多个前端项目放在同一个目录下\nserver &#123;    listen       80;    listen  [::]:80;    server_name  localhost;    #charset koi8-r;    #access_log  /var/log/nginx/host.access.log  main;       location / &#123;        root   /usr/share/nginx/html;        index  index.html index.htm;    &#125;    location /xzxt2-syt-web/ &#123;        alias   /usr/share/nginx/html/xzxt2-syt-web/;        index  index.html index.htm;        try_files $uri $uri/ /xzxt2-syt-web/index.html;    &#125;       location /xzxt2-zdkz-web/ &#123;        alias   /usr/share/nginx/html/xzxt2-zdkz-web/;        index  index.html index.htm;        try_files $uri $uri/ /xzxt2-zdkz-web/index.html;    &#125;    &#125;\n\n\n\n示例一：\n\nlocation /whsir/ &#123;    try_files $uri /images/default.gif;&#125;\n\n说明：\n1、访问www.example.com/whsir/123/321（文件不存在）时，此时看到的是default.gif图片，URL地址不变\n2、访问www.example.com/whsir/123.png（文件存在）时，此时看到的是123.png图片，URL地址不变\n总结：当images目录下文件不存在时，默认返回default.gif\n\n示例二：\n\nlocation /whsir/ &#123;    try_files $uri =403;&#125;\n\n说明：\n1、访问www.example.com/whsir/123.html（文件存在）时，此时看到的是123.html内容，URL地址不变\n2、访问www.example.com/whsir/21.html（文件不存在）时，此时看到的是403状态，URL地址不变\n总结：和示例一一样，只是将默认图片换成了403状态\n\n示例三：\n\nlocation /whsir/ &#123;    try_files $uri @ab;&#125;location @ab &#123;    rewrite ^/(.*)$ https://blog.whsir.com;&#125;\n\n说明：\n1、访问www.example.com/whsir/123.html（文件存在）时，此时看到的是123.html内容，URL地址不变\n2、访问www.example.com/whsir/21.html（文件不存在）时，此时跳转到吴昊博客，URL地址改变\n总结：当文件不存在时，会去查找@ab值，此时在location中定义@ab值跳转到吴昊博客\n\n示例四：\n\ntry_files $uri @pro;location @pro &#123;    proxy_set_header Host $host;    proxy_set_header X-Real-IP $remote_addr;    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;    proxy_pass https://blog.whsir.com;&#125;\n\n说明：\n1、访问www.example.com/123.html（文件存在）时，此时看到的是123.html内容，URL地址不变\n2、访问www.example.com/post-3647.html（文件不存在）时，此时看到的是吴昊博客的内容，URL地址不变\n总结：当前服务器上文件不存在时，会进行反向代理\n","categories":["技术教程","Nginx"],"tags":["Nginx","反向代理"]},{"title":"Docker构建SpringBoot镜像","url":"/%E5%90%8E%E7%AB%AF/SpringBoot/Docker%E6%9E%84%E5%BB%BASpringBoot%E9%95%9C%E5%83%8F/","content":"配置远程访问编辑docker服务配置文件sudo vim /lib/systemd/system/docker.service\n\n\n\n找到如下配置ExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock\n\n\n\n修改为ExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock -H tcp://0.0.0.0:2375\n\n\n\n重启docker网络sudo systemctl daemon-reload \n\n\n\n重启docker服务sudo systemctl restart docker\n\n\n\n测试浏览器访问http://192.168.40.104:2375/verion\n安装idea的docker插件安装完重启IDEA\n配置Dokcer Api配置新建Docker配置，修改主机ip为docker服务器ip，Connection successful表示连接成功\n\nDockerfile在根目录新建Dockerfile\nFROM java:8VOLUME /tmpCOPY target/spring-boot-helloworld-0.0.1-SNAPSHOT.jar demo.jarRUN bash -c &quot;touch /demo.jar&quot;ENTRYPOINT [&quot;java&quot;, &quot;-Djava.security.egd=file:/dev/./urandom&quot;,&quot;-jar&quot;, &quot;demo.jar&quot;]\n\n\n\ndocker插件配置pom.xml\n&lt;docker.image.prefix&gt;valten&lt;/docker.image.prefix&gt;&lt;!--使用docker-maven-plugin插件--&gt;&lt;plugin&gt;    &lt;groupId&gt;com.spotify&lt;/groupId&gt;    &lt;artifactId&gt;docker-maven-plugin&lt;/artifactId&gt;    &lt;version&gt;1.2.0&lt;/version&gt;    &lt;!--将插件绑定在某个phase执行--&gt;    &lt;executions&gt;        &lt;execution&gt;            &lt;id&gt;build-image&lt;/id&gt;            &lt;!--将插件绑定在package这个phase上。也就是说，执行mvn package ，\t\t\t\t就会自动执行mvn docker:build--&gt;            &lt;phase&gt;package&lt;/phase&gt;            &lt;goals&gt;                &lt;goal&gt;build&lt;/goal&gt;            &lt;/goals&gt;        &lt;/execution&gt;    &lt;/executions&gt;    &lt;configuration&gt;        &lt;!--指定生成的镜像名--&gt;        &lt;imageName&gt;$&#123;docker.image.prefix&#125;/$&#123;project.artifactId&#125;&lt;/imageName&gt;        &lt;!--指定标签--&gt;        &lt;imageTags&gt;            &lt;imageTag&gt;latest&lt;/imageTag&gt;        &lt;/imageTags&gt;        &lt;!-- 指定 Dockerfile 路径 $&#123;project.basedir&#125;：项目根路径下--&gt;        &lt;dockerDirectory&gt;$&#123;project.basedir&#125;&lt;/dockerDirectory&gt;        &lt;!--指定远程 docker api地址--&gt;        &lt;dockerHost&gt;http://192.168.40.104:2375&lt;/dockerHost&gt;        &lt;!--相当于Dockerfile--&gt;        &lt;!--&lt;baseImage&gt;java:8&lt;/baseImage&gt;--&gt;        &lt;!--&lt;entryPoint&gt;[&quot;java&quot;, &quot;-jar&quot;,&quot;/$&#123;project.build.finalName&#125;.jar&quot;]&lt;/entryPoint&gt;--&gt;        &lt;!-- 这里是复制 jar 包到 docker 容器指定目录配置 --&gt;        &lt;resources&gt;            &lt;resource&gt;                &lt;targetPath&gt;/&lt;/targetPath&gt;                &lt;!--jar 包所在的路径 此处配置的 即对应 target 目录--&gt;                &lt;directory&gt;$&#123;project.build.directory&#125;&lt;/directory&gt;                &lt;!-- 需要包含的 jar包 ，这里对应的是 Dockerfile中添加的文件名　--&gt;                &lt;include&gt;$&#123;project.build.finalName&#125;.jar&lt;/include&gt;            &lt;/resource&gt;        &lt;/resources&gt;    &lt;/configuration&gt;&lt;/plugin&gt;\n\n\n\nMaven编译构建构建镜像mvn clean package -Dmaven.test.skip=true\n\nmaven打包的同时就会生成镜像\n\n创建容器镜像右键新建容器container， Docker-&gt;Docker Image，指定镜像ID，容器名和端口映射\n\n运行\n测试http://192.168.40.104:27300/hello\nhello world !\nHelloWorldController@RestControllerpublic class HelloWorldController &#123;    @RequestMapping(&quot;hello&quot;)    public String sayHello() &#123;        return &quot;Hello World !&quot;;    &#125;    @RequestMapping(&quot;hi&quot;)    public String sayHi() &#123;        return &quot;Hi, EveryBody !&quot;;    &#125;&#125;\n\n\n\napplication.propertiesserver.port=27300\n\n","categories":["技术教程","Docker","后端","SpringBoot"],"tags":["Docker","SpringBoot"]},{"title":"Markdown 基础语法","url":"/%E6%8A%80%E6%9C%AF%E6%95%99%E7%A8%8B/Markdown/Markdown%20%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/","content":"一、标题在想要设置为标题的文字前面加#来表示一个#是一级标题，二个#是二级标题，以此类推。支持六级标题。\n注：标准语法一般在#后跟个空格再写文字，貌似简书不加空格也行。\n示例：\n# 这是一级标题## 这是二级标题### 这是三级标题#### 这是四级标题##### 这是五级标题###### 这是六级标题\n\n效果如下：\n这是一级标题这是二级标题这是三级标题这是四级标题这是五级标题这是六级标题二、字体\n加粗\n\n要加粗的文字左右分别用两个*号包起来\n\n斜体\n\n要倾斜的文字左右分别用一个*号包起来\n\n斜体加粗\n\n要倾斜和加粗的文字左右分别用三个*号包起来\n\n删除线\n\n要加删除线的文字左右分别用两个~~号包起来\n示例：\n**这是加粗的文字***这是倾斜的文字****这是斜体加粗的文字***~~这是加删除线的文字~~\n\n效果如下：\n这是加粗的文字这是倾斜的文字这是斜体加粗的文字这是加删除线的文字\n三、引用在引用的文字前加&gt;即可。引用也可以嵌套，如加两个&gt;&gt;三个&gt;&gt;&gt;n个…\n示例：\n&gt;这是引用的内容&gt;&gt;这是引用的内容&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;这是引用的内容\n\n效果如下：\n\n这是引用的内容\n\n这是引用的内容\n\n\n\n\n\n\n\n\n这是引用的内容\n\n\n\n\n\n\n\n\n\n\n四、分割线三个或者三个以上的 - 或者 * 都可以。\n示例：\n-------********\n\n效果如下：可以看到，显示效果是一样的。\n\n\n\n\n五、图片语法：\n![图片alt](图片地址 &#x27;&#x27;图片title&#x27;&#x27;)图片alt就是显示在图片下面的文字，相当于对图片内容的解释。图片title是图片的标题，当鼠标移到图片上时显示的内容。title可加可不加\n\n示例：\n![blockchain](https://ss0.bdstatic.com/70cFvHSh_Q1YnxGkpoWK1HF6hhy/it/u=702257389,1274025419&amp;fm=27&amp;gp=0.jpg &quot;区块链&quot;)\n\n效果如下：\n\n六、超链接语法：\n[超链接名](超链接地址 &quot;超链接title&quot;)title可加可不加\n\n示例：\n[简书](http://jianshu.com)[百度](http://baidu.com)\n\n效果如下：\n简书百度\n注：Markdown本身语法不支持链接在新页面中打开，如果想要在新页面中打开的话可以用html语言的a标签代替。\n&lt;a href=&quot;超链接地址&quot; target=&quot;_blank&quot;&gt;超链接名&lt;/a&gt;示例&lt;a href=&quot;https://www.jianshu.com/u/1f5ac0cf6a8b&quot; target=&quot;_blank&quot;&gt;简书&lt;/a&gt;\n\n\n\n七、列表无序列表语法：无序列表用 - + * 任何一种都可以\n- 列表内容+ 列表内容* 列表内容注意：- + * 跟内容之间都要有一个空格\n\n效果如下：\n\n列表内容\n列表内容\n列表内容\n\n有序列表语法：数字加点\n1. 列表内容2. 列表内容3. 列表内容注意：序号跟内容之间要有空格\n\n效果如下：\n\n列表内容\n列表内容\n列表内容\n\n八、表格语法：\n表头|表头|表头---|:--:|---:内容|内容|内容内容|内容|内容第二行分割表头和内容。- 有一个就行，为了对齐，多加了几个文字默认居左-两边加：表示文字居中-左边加：表示文字居左-右边加：表示文字居右注：原生的语法两边都要用 | 包起来。此处省略\n\n示例：\n姓名|技能|排行--|:--:|--:刘备|哭|大哥关羽|打|二哥张飞|骂|三弟\n\n效果如下：\n\n\n\n姓名\n技能\n排行\n\n\n\n刘备\n哭\n大哥\n\n\n关羽\n打\n二哥\n\n\n张飞\n骂\n三弟\n\n\n九、代码语法：单行代码：代码之间分别用一个反引号包起来\n`代码内容`\n\n代码块：代码之间分别用三个反引号包起来，且两边的反引号单独占一行\n(```)  代码...  代码...  代码...(```)\n\n\n注：为了防止转译，前后三个反引号处加了小括号，实际是没有的。这里只是用来演示，实际中去掉两边小括号即可。\n\n示例：\n单行代码\n`create database hero;`\n\n代码块\n(```)    function fun()&#123;         echo &quot;这是一句非常牛逼的代码&quot;;    &#125;    fun();(```)\n\n效果如下：\n单行代码\ncreate database hero;\n代码块\nfunction fun()&#123;  echo &quot;这是一句非常牛逼的代码&quot;;&#125;fun();\n\n\n\n十、流程图Mermaid 流程图graph TB\tA[Apple]--&gt;B&#123;Boy&#125;\tA---C(Cat)\tB.-&gt;D((Dog))\tC==喵==&gt;D\tstyle A fill:#2ff,fill-opacity:0.1,stroke:#faa,stroke-width:4px\tstyle D stroke:#000,stroke-width:8px;\n\n\n\n语法结构\n```mermaidgraph 方向节点以及节点连线（定义和连线步骤可以分开）（样式调整）```\n\n显示方向\n\nTB/TD（ top bottom/top down）表示从上到下\nBT（bottom top）表示从下到上\nRL（right left）表示从右到左\nLR（left right）表示从左到右\n\n节点类型\n    节点本身的展现形式，是通过不同括号来代表各自不同的形状，默认为矩形。\n\n默认节点： A\n矩形节点： B[矩形]\n圆角矩形节点： C(圆角矩形)\n圆形节点： D((圆形))\n非对称节点： E&gt;非对称]\n菱形节点： F{菱形}\n\nA矩形圆角矩形圆形非对称菱形\ngraph TD AB[矩形]C(圆角矩形)D((圆形))DE&gt;非对称]F&#123;菱形&#125;\n\n\n\n语法详解节点连线   线条本身的形式有多种，通过常规的英文格式的格式来标识，具体如下：\n\n箭头连接 A1- -&gt;B1\n开放连接 A2- - -B2\n虚线箭头连接 A3.-&gt;B3 或者 A3-.-&gt;B3\n虚线连接 A4.-B4 或者 A4-.-B4\n粗线箭头连接 A5==&gt;B5\n粗线开放连接 A6===B6\n标签虚线箭头连接 A7-.text.-&gt;B7\n\n\n标签开放连接 A8- -text- - -B8\n\ngraph TD A1--&gt;B1A2---B2A3.-&gt;B3A4-.-B4A5==&gt;B5A6===B6A7-.text.-B7A8--text---B8\n\n\n\nFlowchart 流程图st=&gt;start: 开始e=&gt;end: 结束op1=&gt;operation: 操作1 | pastop2=&gt;operation: 操作2 | currentop3=&gt;operation: 操作3 | futurepa=&gt;parallel: 多输出操作4 | approvedcond=&gt;condition: 确认？ | rejectedst-&gt;op1-&gt;condcond(true)-&gt;e\tcond(no)-&gt;op2(right)-&gt;op3-&gt;pa(path1,right)-&gt;op1pa(path2,left) -&gt;est@&gt;op1(&#123;&quot;stroke&quot;:&quot;Blue&quot;&#125;)@&gt;cond(&#123;&quot;stroke&quot;:&quot;Green&quot;&#125;)@&gt;e(&#123;&quot;stroke&quot;:&quot;Red&quot;,&quot;stroke-width&quot;:6,&quot;arrow-end&quot;:&quot;classic-wide-long&quot;&#125;)\n\n\n\n语法结构\n```flow定义节点连接节点（样式调整）\n```\n节点类型\n  目前官网提供7种节点，其实还有很多别的节点类型，但可能插件脚本还没支持。\n\n开始（椭圆形）：start\n结束（椭圆形）：end\n操作（矩形）：operation\n多输出操作（矩形）：parallel\n条件判断（菱形）：condition\n输入输出（平行四边形）：inputoutput\n\n\n预处理/子程序（圣旨形）：subroutine\n\n语法详解\n节点定义变量名=&gt;节点标识: 节点显示名\n节点连线\n变量名1-&gt;变量名2-&gt;…-&gt;变量名n\n连线样式\n  设置变量m和变量n之间连线的样式，具体样式由变量n后面key-value控制，需要两个变量之间有直接连线。语法中的连接符为（@&gt;）。\n变量名m@&gt;变量名n({“key”:”value”})\n关键字\n\nyes/true：condition类型变量连接时，用于分别表示yes条件的流向\n\nno/false：同上，表示否定条件的流向\n\nleft/right：表示连线出口在节点位置（默认下面是出口，如op3），可以跟condition变量一起用\n\ncond(yes,right)\n\npath1/path2/path3：parallel变量的三个出口路径（默认下面是出口）\n\n\n节点状态\n  为节点设置不同的状态，可以通过不同的颜色显示，其中状态包括下面6个，含义如英文所示，不过CSDN中好像目前还不支持：\n\npast\ncurrent\nfuture\napproved\nrejected\ninvalid\n\n","categories":["技术教程","Markdown"],"tags":["Markdown"]},{"title":"Win10系统使用Docker","url":"/%E6%8A%80%E6%9C%AF%E6%95%99%E7%A8%8B/Docker/Win10%E7%B3%BB%E7%BB%9F%E4%BD%BF%E7%94%A8Docker/","content":"安装菜鸟教程nginx下载最新的nginxdocker pull nginx\n\n\n\n启动nginx\n为了方便，把nginx配置文件、静态文件和日志映射到容器外面\n\nd:\\\\# 创建文件夹md \\docker-data\\nginx\\confmd \\docker-data\\nginx\\conf.dmd \\docker-data\\nginx\\logsmd \\docker-data\\nginx\\www# 等价于md \\docker-data\\nginx\\conf \\docker-data\\nginx\\conf.d \\docker-data\\nginx\\logs \\docker-data\\nginx\\www\n\n\n\n在启动nginx前要先创建nginx配置文件，不然会把配置文件当成文件夹\n可以先启动一个nginx，复制配置文件到服务器上\ndocker run --name nginx -p 8081:80 -d nginx# 复制容器 id 为 aacfa7df8232 的 nginx 容器的配置文件到服务器指定路径下docker cp aacfa7df8232:/etc/nginx/nginx.conf D:\\docker-data\\nginx\\conf\\docker cp aacfa7df8232:/etc/nginx/conf.d/default.conf D:\\docker-data\\nginx\\conf.d\\\n\n\n\n修改 D://docker-data/nginx/conf.d/default.conf 就可以了，因为D://docker-data/nginx/conf/已经通过include引入了default.conf\nserver &#123;    listen       80;    listen  [::]:80;    server_name  localhost;    #charset koi8-r;    #access_log  /var/log/nginx/host.access.log  main;    location / &#123;        root   /usr/share/nginx/html;        index  index.html index.htm;    &#125;    location ^~ /api/ &#123;        proxy_pass http://192.168.40.26:9090/;    &#125;    location ~ \\.zz$ &#123;        proxy_pass   http://192.168.40.26:9090;    &#125;    #error_page  404              /404.html;    # redirect server error pages to the static page /50x.html    #    error_page   500 502 503 504  /50x.html;    location = /50x.html &#123;        root   /usr/share/nginx/html;    &#125;&#125;\n\n\n\n启动nginx\n注意：把命令合成一行，此处只是为了看起来更直观\n\ndocker run --name nginx -p 81:80 -d -v D:\\docker-data\\nginx\\www:/usr/share/nginx/html -v D:\\docker-data\\nginx\\conf/nginx.conf:/etc/nginx/nginx.conf -v D:\\docker-data\\nginx\\conf.d/default.conf:/etc/nginx/conf.d/default.conf -v D:\\docker-data\\nginx\\logs:/var/log/nginx nginx\n\n\n\n进入nginx容器内部docker exec -it nginx /bin/bash\n\n\n\n设置开机自启docker update nginx --restart=always\n\n\n\nredis下载最新的redisdocker pull redis\n\n\n\n启动redis在启动redis前要先创建redis配置文件，不然会把配置文件当成文件夹\n# 创建配置文件文件夹d:\\\\# 创建文件夹md \\docker-data\\redis\\datamd \\docker-data\\redis\\conf# 等价于md \\docker-data\\redis\\data \\docker-data\\redis\\conf\n\n默认没有开启持久化，数据在内存中，重启服务器后数据会丢失，在配置文件中设置持久化\nvi D:\\docker-data\\redis\\conf\\redis.conf# 持久化 AOFappendonly yes\n\n启动redis\n注意：把命令合成一行，此处只是为了看起来更直观\n\ndocker run -p 6379:6379 --name redis -v D:\\docker-data\\redis\\data:/data -v D:\\docker-data\\redis\\conf\\redis.conf:/etc/redis/redis.conf -d redis redis-server /etc/redis/redis.conf\n\n\n\n进入redis客户端docker exec -it redis redis-cli\n\n\n\n设置开机自启docker update redis --restart=always\n\n\n\nmysql下载mysql5.7docker pull mysql:5.7\n\n\nmysql配置文件创建mysql配置文件\nd:\\\\# 创建文件夹md \\docker-data\\mysql\\datamd \\docker-data\\mysql\\confmd \\docker-data\\mysql\\log# 等价于md \\docker-data\\mysql\\data \\docker-data\\mysql\\conf \\docker-data\\mysql\\log\n\n新建配置文件\n# 新建配置文件vi D:\\docker-data\\mysql\\conf\\my.conf\n\n配置文件内容如下\n[client]default-character-set = utf8[mysql]default-character-set = utf8[mysqld]init_connect=&#x27; SET collation_connection = utf8_unicode_ci&#x27;init_connect=&#x27; SET NAMES utf8&#x27;character-set-server=utf8collation-server=utf8_unicode_ciskip-character-set-client-handshakeskip-name-resolve\n\n\n\n启动mysqldocker run -p 3306:3306 --name mysql -v D:\\docker-data\\mysql\\conf:/etc/mysql/ -v D:\\docker-data\\mysql\\log:/var/log/mysql -v D:\\docker-data\\mysql\\data:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=root -d mysql:5.7\n\n\n\n进入容器内部docker exec -it mysql /bin/bash\n\n重启mysqldocker restart mysql\n\n进入mysql容器内部，可以看到里面有在外面配置的配置文件my.conf\ndocker exec -it mysql /bin/bashcat /etc/mysql/my.conf\n\n设置开机自启docker update mysql --restart=always\n\n","categories":["技术教程","Docker"],"tags":["Docker","Win10"]},{"title":"Docker 中安装开发软件","url":"/%E6%8A%80%E6%9C%AF%E6%95%99%E7%A8%8B/Docker/Docker%20%E4%B8%AD%E5%AE%89%E8%A3%85%E5%BC%80%E5%8F%91%E8%BD%AF%E4%BB%B6/","content":"MySQL下载mysql5.7sudo docker pull mysql:5.7\n\n\n\nmysql配置文件创建mysql配置文件\nmkdir -p /mydata/mysql/confmkdir -p /mydata/mysql/datamkdir -p /mydata/mysql/log# 等价于mkdir -p /mydata/mysql/conf /mydata/mysql/data /mydata/mysql/log# 新建配置文件vi /mydata/mysql/conf/my.conf\n\n配置文件内容如下\n[client]default-character-set = utf8[mysql]default-character-set = utf8[mysqld]init_connect=&#x27; SET collation_connection = utf8_unicode_ci&#x27;init_connect=&#x27; SET NAMES utf8&#x27;character-set-server=utf8collation-server=utf8_unicode_ciskip-character-set-client-handshakeskip-name-resolve\n\n\n\n启动mysqldocker run -p 3306:3306 --name mysql \\  -v /mydata/mysql/conf:/etc/mysql/ \\  -v /mydata/mysql/log:/var/log/mysql \\  -v /mydata/mysql/data:/var/lib/mysql \\  -e MYSQL_ROOT_PASSWORD=root \\  -d mysql:5.7\n\n\n\n进入容器内部docker exec -it mysql /bin/bash\n\n\n重启mysql\ndocker restart mysql\n\n进入mysql容器内部，可以看到里面有在外面配置的配置文件my.conf\ndocker exec -it mysql /bin/bashcat /etc/mysql/my.conf\n\n\n\n设置开机自启docker update mysql --restart=always\n\n\n\nRedis下载最新的redisdocker pull redis\n\n\n\n启动redis在启动redis前要先创建redis配置文件，不然会把配置文件当成文件夹\n# 创建配置文件文件夹mkdir -p /mydata/redis/confmkdir -p /mydata/redis/data# 等价于mkdir -p /mydata/redis/conf /mydata/redis/data\n\n默认没有开启持久化，数据在内存中，重启服务器后数据会丢失，在配置文件中设置持久化\nvi /mydata/redis/conf/redis.conf# 持久化 AOFappendonly yes\n\n启动redis\ndocker run -p 6379:6379 --name redis \\-v /mydata/redis/data:/data \\-v /mydata/redis/conf/redis.conf:/etc/redis/redis.conf \\-d redis redis-server /etc/redis/redis.conf\n\n\n\n进入redis客户端docker exec -it redis redis-cli\n\n\n\n设置开机自启docker update redis --restart=always\n\n\n\nNginx下载最新的nginxdocker pull nginx\n\n\n\n启动nginx为了方便，把nginx配置文件、静态文件和日志映射到容器外面\n# 创建文件夹mkdir -p /docker-data/nginx/confmkdir -p /docker-data/nginx/conf.dmkdir -p /docker-data/nginx/logsmkdir -p /docker-data/nginx/www# 等价于mkdir -p /docker-data/nginx/conf \\         /docker-data/nginx/conf.d \\         /docker-data/nginx/logs \\         /docker-data/nginx/www\n\n\n\n在启动nginx前要先创建nginx配置文件，不然会把配置文件当成文件夹\n可以先启动一个nginx，复制配置文件到服务器上\ndocker run --name nginx -p 80:80 -d nginx# 复制容器 id 为 aacfa7df8232 的 nginx 容器的配置文件到服务器指定路径下docker cp aacfa7df8232:/etc/nginx/nginx.conf /docker-data/nginx/conf/docker cp aacfa7df8232:/etc/nginx/conf.d/default.conf /docker-data/nginx/conf.d/\n\n\n\n修改 /docker-data/nginx/conf.d/default.conf 就可以了，因为/docker-data/nginx/conf/已经通过include引入了default.conf\nserver &#123;    listen       80;    listen  [::]:80;    server_name  localhost;    #charset koi8-r;    #access_log  /var/log/nginx/host.access.log  main;    location / &#123;        root   /usr/share/nginx/html;        index  index.html index.htm;    &#125;    location ^~ /api/ &#123;        proxy_pass http://192.168.40.26:9090/;    &#125;    location ~ \\.zz$ &#123;        proxy_pass   http://192.168.40.26:9090;    &#125;    #error_page  404              /404.html;    # redirect server error pages to the static page /50x.html    #    error_page   500 502 503 504  /50x.html;    location = /50x.html &#123;        root   /usr/share/nginx/html;    &#125;&#125;\n\n\n\n启动nginx\ndocker run --name ngx -p 8081:80 -d --net bridge \\-v /docker-data/nginx/www:/usr/share/nginx/html \\-v /docker-data/nginx/conf/nginx.conf:/etc/nginx/nginx.conf \\-v /docker-data/nginx/conf.d/default.conf:/etc/nginx/conf.d/default.conf \\-v /docker-data/nginx/logs:/var/log/nginx \\nginx\n\n\n\n进入nginx容器内部docker exec -it nginx /bin/bash\n\n\n\n设置开机自启docker update nginx --restart=always\n\n","categories":["技术教程","Docker"],"tags":["Docker"]},{"title":"Vim 编辑器","url":"/%E6%8A%80%E6%9C%AF%E6%95%99%E7%A8%8B/Linux/Vim%E7%BC%96%E8%BE%91%E5%99%A8/","content":"Vim 的命令模式使用 Vim 编辑文件时，默认处于命令模式。此模式下，可使用方向键（上、下、左、右键）移动光标的位置，还可以对文件内容进行复制、粘贴、替换、删除等操作。\nVim 的输入模式在输入模式下，Vim 可以对文件执行写操作，类似于在 Windows 系统的文档中输入内容。\n使 Vim 进行输入模式的方式是在命令模式状态下输入 i、I、a、A、o、O 等插入命令（各指令的具体功能如表 3 所示），当编辑文件完成后按 Esc 键即可返回命令模式。\n\n\n\n快捷键\n功能描述\n\n\n\ni\n在当前光标所在位置插入随后输入的文本，光标后的文本相应向右移动\n\n\nI\n在光标所在行的行首插入随后输入的文本，行首是该行的第一个非空白字符，相当于光标移动到行首执行 i 命令\n\n\no\n在光标所在行的下面插入新的一行。光标停在空行首，等待输入文本\n\n\nO\n在光标所在行的上面插入新的一行。光标停在空行的行首，等待输入文本\n\n\na\n在当前光标所在位置之后插入随后输入的文本\n\n\nA\n在光标所在行的行尾插入随后输入的文本，相当于光标移动到行尾再执行a命令\n\n\n下图即为 Vim 处于输入模式状态下的示意图。\n\nVim 的编辑模式编辑模式用于对文件中的指定内容执行保存、查找或替换等操作。\n使 Vim 切换到编辑模式的方法是在命令模式状态下按“：”键，此时 Vim 窗口的左下方出现一个“：”符号，这是就可以输入相关指令进行操作了。\n指令执行后 Vim 会自动返回命令模式。如想直接返回命令模式，按 Esc 即可。\n下图为 Vim 进入编辑模式后的状态。\n\n对于新手来说，经常不知道自己处于什么模式。不论是自己忘了，还是不小心切换了模式，都可以按一次 Esc 键返回命令模式。如果你多按几次 Esc 键后听到”嘀————“的声音，则代表你已经处于命令模式了。\nVim 打开文件使用 Vim 打开文件很简单，例如在命令行模式下打开一个自己编写的文件 /test/vi.test，打开方法如下：\n[root@itxdl ~]# vim /test/vi.test\n\n刚打开文件时 Vim 处于命令模式，此时文件的下方会显示文件的一些信息，包括文件的总行数和字符数，以及当前光标所在的位置等，此时可以使用插入命令进入输入模式对文件进行编辑。\n除此之外，我们还可以利用下表中打开文件的命令格式，针对特定情形使用适当的打开方式，可以大大提高我们的效率。\n\n\n\nVi 使用的选项\n说 明\n\n\n\nvim filename\n打开或新建一个文件，并将光标置于第一行的首部\n\n\nvim -r filename\n恢复上次 vim 打开时崩溃的文件\n\n\nvim -R filename\n把指定的文件以只读方式放入 Vim 编辑器中\n\n\nvim + filename\n打开文件，并将光标置于最后一行的首部\n\n\nvi +n filename\n打开文件，并将光标置于第 n 行的首部\n\n\nvi +/pattern filename\n打幵文件，并将光标置于第一个与 pattern 匹配的位置\n\n\nvi -c command filename\n在对文件进行编辑前，先执行指定的命令\n\n\nVim 编辑文件同样，Vim 提供了大量的编辑快捷键，主要可分为以下几类。\nVim 插入文本从命令模式进入输入模式进行编辑，可以按下 I、i、O、o、A、a 等键来完成，使用不同的键，光标所处的位置不同，如表 3 所示。\n\n\n\n快捷键\n功能描述\n\n\n\ni\n在当前光标所在位置插入随后输入的文本，光标后的文本相应向右移动\n\n\nI\n在光标所在行的行首插入随后输入的文本，行首是该行的第一个非空白字符，相当于光标移动到行首执行 i 命令\n\n\no\n在光标所在行的下面插入新的一行。光标停在空行首，等待输入文本\n\n\nO\n在光标所在行的上面插入新的一行。光标停在空行的行首，等待输入文本\n\n\na\n在当前光标所在位置之后插入随后输入的文本\n\n\nA\n在光标所在行的行尾插入随后输入的文本，相当于光标移动到行尾再执行 a 命令\n\n\nVim 查找文本\n\n\n快捷键\n功能描述\n\n\n\n/abc\n从光标所在位置向前查找字符串 abc\n\n\n/^abc\n查找以 abc 为行首的行\n\n\n/abc$\n查找以 abc 为行尾的行\n\n\n?abc\n从光标所在为主向后查找字符串 abc\n\n\nn\n向同一方向重复上次的查找指令\n\n\nN\n向相反方向重复上次的查找指定\n\n\n例如，在 /etc/passwd.vi 文件中查找字符串 “root”，则运行命令如图所示。\n\n如果在文件中并没有找到所要查找的字符串，则在文件底部会出现 “Pattern not found” 提示，如图所示。\n\n在查找过程中需要注意的是，要查找的字符串是严格区分大小写的，如查找 “shenchao” 和 “ShenChao” 会得到不同的结果。\n如果想忽略大小写，则输入命令 :set ic；调整回来输入:set noic。\n如果在字符串中出现特殊符号，则需要加上转义字符 “&quot;。常见的特殊符号有 \\、*、?、$ 等。如果出现这些字符，例如，要查找字符串 “10$”，则需要在命令模式中输入 “/10$“。\nVim 删除文本\n\n\n快捷键\n功能描述\n\n\n\nx\n删除光标所在位置的字符\n\n\ndd\n删除光标所在行\n\n\nndd\n删除当前行（包括此行）后 n 行文本\n\n\ndG\n删除光标所在行一直到文件末尾的所有内容\n\n\nD\n删除光标位置到行尾的内容\n\n\n:a1,a2d\n函数从 a1 行到 a2 行的文本内容\n\n\n注意，被删除的内容并没有真正删除，都放在了剪贴板中。将光标移动到指定位置处，按下 “p” 键，就可以将刚才删除的内容又粘贴到此处。\nVim 复制和粘贴文本\n\n\n快捷键\n功能描述\n\n\n\np\n将剪贴板中的内容粘贴到光标后\n\n\nP（大写）\n将剪贴板中的内容粘贴到光标前\n\n\ny\n复制已选中的文本到剪贴板\n\n\nyy\n将光标所在行复制到剪贴板，此命令前可以加数字 n，可复制多行\n\n\nyw\n将光标位置的单词复制到剪贴板\n\n\nVim 其他常用快捷键某些情况下，可能需要把两行进行连接。比如说，下面的文件中有两行文本，现在需要将其合并成一行（实际上就是将两行间的换行符去掉）。可以直接在命令模式中按下 “J” 键，按下前后如图所示。\n\n\n注意光标得在要合并的上面那一行\n\n如果不小心误删除了文件内容，则可以通过 “u” 键来撤销刚才执行的命令。如果要撤销刚才的多次操作，可以多按几次 “u” 键。\nVim 保存退出文本Vim 的保存和退出是在编辑模式中进行的，其常用命令如下表所示。\n\n\n\n命令\n功能描述\n\n\n\n:wq\n保存并退出 Vim 编辑器\n\n\n:wq!\n保存并强制退出 Vim 编辑器\n\n\n:q\n不保存就退出 Vim 编辑器\n\n\n:q!\n不保存，且强制退出 Vim 编辑器\n\n\n:w\n保存但是不退出 Vim 编辑器\n\n\n:w!\n强制保存文本\n\n\n:w filename\n另存到 filename 文件\n\n\nx！\n保存文本，并退出 Vim 编辑器，更通用的一个 vim 命令\n\n\nZZ\n直接退出 Vim 编辑器\n\n\n需要注意的是，w! 和 `wq!1 等类似的指令，通常用于对文件没有写权限的时候（显示 readonly，如图 所示），但如果你是文件的所有者或者 root 用户，就可以强制执行。\n\n参考\nhttp://c.biancheng.net/linux_tutorial/40/\n","categories":["技术教程","Linux"],"tags":["Linux","Vim"]},{"title":"Lambda 表达式","url":"/%E5%90%8E%E7%AB%AF/Java/Lambda%E8%A1%A8%E8%BE%BE%E5%BC%8F/","content":"Studentimport java.io.Serializable;import java.util.Objects;public class Student implements Serializable &#123;    private Long id;    private String name;    private int age;    private String address;    public Student() &#123;    &#125;    public Student(Long id, String name, int age, String address) &#123;        this.id = id;        this.name = name;        this.age = age;        this.address = address;    &#125;    @Override    public String toString() &#123;        return &quot;Student&#123;&quot; +                &quot;id=&quot; + id +                &quot;, name=&#x27;&quot; + name + &#x27;\\&#x27;&#x27; +                &quot;, age=&quot; + age +                &quot;, address=&#x27;&quot; + address + &#x27;\\&#x27;&#x27; +                &#x27;&#125;&#x27;;    &#125;    @Override    public boolean equals(Object o) &#123;        if (this == o) return true;        if (o == null || getClass() != o.getClass()) return false;        Student student = (Student) o;        return age == student.age &amp;&amp;                Objects.equals(id, student.id) &amp;&amp;                Objects.equals(name, student.name) &amp;&amp;                Objects.equals(address, student.address);    &#125;    @Override    public int hashCode() &#123;        return Objects.hash(id, name, age, address);    &#125;        //省略setter/getter。。。&#125;\n\n\n\n使用场景过滤Student s1 = new Student(1L, &quot;肖战&quot;, 15, &quot;浙江&quot;);Student s2 = new Student(2L, &quot;王一博&quot;, 15, &quot;湖北&quot;);Student s3 = new Student(3L, &quot;杨紫&quot;, 17, &quot;北京&quot;);Student s4 = new Student(4L, &quot;李现&quot;, 17, &quot;浙江&quot;);List&lt;Student&gt; students = new ArrayList&lt;&gt;();students.add(s1);students.add(s2);students.add(s3);students.add(s4);//筛选年龄大于15岁的学生List &lt;Student&gt; stuList = students.stream()                                 .filter(s -&gt; s.getAge()&gt;15)                                 .collect(Collectors.toList());//筛选住在浙江省的学生List&lt;Student&gt; stuList2 = students.stream()                                 .filter(s -&gt; &quot;浙江&quot;.equals(s.getAddress()))                                 .collect(Collectors.toList());\n\n\n\n\n\n转换.map\nmap: 对于Stream中包含的元素使用给定的转换函数进行转换操作，新生成的Stream只包含转换生成的元素。这个方法有三个对于原始类型的变种方法，分别是：mapToInt，mapToLong和mapToDouble。这三个方法也比较好理解，比如mapToInt就是把原始Stream转换成一个新的Stream，这个新生成的Stream中的元素都是int类型。之所以会有这样三个变种方法，可以免除自动装箱/拆箱的额外消耗；\nStudent s1 = new Student(1L, &quot;肖战&quot;, 15, &quot;浙江&quot;);Student s2 = new Student(2L, &quot;王一博&quot;, 15, &quot;湖北&quot;);Student s3 = new Student(3L, &quot;杨紫&quot;, 17, &quot;北京&quot;);Student s4 = new Student(4L, &quot;李现&quot;, 17, &quot;浙江&quot;);List&lt;Student&gt; students = new ArrayList&lt;&gt;();students.add(s1);students.add(s2);students.add(s3);students.add(s4);//获取地址集合List&lt;String&gt; addresses1 = students.stream()                                 .map(Student::getAddress)                                 .collect(Collectors.toList());//在地址前面加上部分信息，只获取地址输出List&lt;String&gt; addresses = students.stream()                                 .map(s -&gt; &quot;住址:&quot; + s.getAddress())                                 .collect(Collectors.toList());//获取的地址以逗号隔开拼成字符串String addresses2 = students.stream()                            .map(Student::getAddress)                            .collect(Collectors.joining(&quot;,&quot;));//集合以逗号隔开拼成字符串String addresses3 = StringUtils.join(addresses1.toArray(), &quot;,&quot;);\n\n\n\n.mapToLong\nStudent s1 = new Student(1L, &quot;肖战&quot;, 15, &quot;浙江&quot;);Student s2 = new Student(2L, &quot;王一博&quot;, 15, &quot;湖北&quot;);Student s3 = new Student(3L, &quot;杨紫&quot;, 17, &quot;北京&quot;);Student s4 = new Student(4L, &quot;李现&quot;, 17, &quot;浙江&quot;);List&lt;Student&gt; students = new ArrayList&lt;&gt;();students.add(s1);students.add(s2);students.add(s3);students.add(s4);//年龄求和int sum = students.stream().mapToLong(Student::getAge).sum();\n\n\n\n\n\n.collect\nStudent s1 = new Student(1L, &quot;肖战&quot;, 15, &quot;浙江&quot;);Student s2 = new Student(2L, &quot;王一博&quot;, 15, &quot;湖北&quot;);Student s3 = new Student(3L, &quot;杨紫&quot;, 17, &quot;北京&quot;);Student s4 = new Student(4L, &quot;袁天罡&quot;, 17, &quot;浙江&quot;);Student s5 = new Student(4L, &quot;李淳风&quot;, 17, &quot;浙江&quot;);List&lt;Student&gt; students = new ArrayList&lt;&gt;();students.add(s1);students.add(s2);students.add(s3);students.add(s4);students.add(s5);//键相同，新的值不会覆盖旧的值Map&lt;Long, String&gt; map1 = students.stream()\t.collect(Collectors.toMap(Student::getId, Student::getName,                               (oldVal, newVal) -&gt; oldVal));//键相同，新的值会覆盖旧的值Map&lt;Long, String&gt; map2 = students.stream()    .collect(Collectors.toMap(Student::getId, Student::getName,                               (oldVal, newVal) -&gt; newVal));\n\n\n\nMap&lt;String, String&gt; map = new HashMap&lt;&gt;();map.put(&quot;a&quot;, &quot;路飞1&quot;);map.put(&quot;b&quot;, &quot;索隆23&quot;);map.put(&quot;c&quot;, &quot;三治456&quot;);map.put(&quot;d&quot;, &quot;布鲁克7890&quot;);//获取新的map，值为原来值的长度Map&lt;String, Integer&gt; map2 = map.entrySet().stream()    .collect(Collectors.toMap(Map.Entry::getKey, e -&gt; e.getValue().length()));//获取新的map，值为原来值的长度Map&lt;String, Integer&gt; map3 = map.entrySet().stream()    \t\t.collect(HashMap::new, (m, v)              -&gt; m.put(v.getKey(), v.getValue().length()),              HashMap::putAll);\n\n去重基本类型\n//简单字符串的去重List&lt;String&gt; list = Arrays.asList(&quot;111&quot;, &quot;222&quot;, &quot;333&quot;, &quot;111&quot;, &quot;222&quot;);list.stream().distinct().forEach(System.out::println);\n\n\n\n集合\n//引用对象的去重，引用对象要实现hashCode和equal方法，否则去重无效Student s1 = new Student(1L, &quot;肖战&quot;, 15, &quot;浙江&quot;);Student s2 = new Student(2L, &quot;王一博&quot;, 15, &quot;湖北&quot;);Student s3 = new Student(3L, &quot;杨紫&quot;, 17, &quot;北京&quot;);Student s4 = new Student(4L, &quot;李现&quot;, 17, &quot;浙江&quot;);Student s5 = new Student(1L, &quot;肖战&quot;, 15, &quot;浙江&quot;);List&lt;Student&gt; students = new ArrayList&lt;&gt;();students.add(s1);students.add(s2);students.add(s3);students.add(s4);students.add(s5);List &lt;Student&gt; students2 = students.stream().distinct().collect(Collectors.toList());\n\n\n\n排序默认排序\nList&lt;String&gt; list = Arrays.asList(&quot;333&quot;, &quot;222&quot;, &quot;111&quot;);list.stream().sorted().forEach(System.out::println);\n\n\n\n指定排序规则\nStudent s1 = new Student(1L, &quot;肖战&quot;, 15, &quot;浙江&quot;);Student s2 = new Student(2L, &quot;王一博&quot;, 15, &quot;湖北&quot;);Student s3 = new Student(3L, &quot;杨紫&quot;, 17, &quot;北京&quot;);Student s4 = new Student(4L, &quot;李现&quot;, 14, &quot;浙江&quot;);List&lt;Student&gt; students = new ArrayList&lt;&gt;();students.add(s1);students.add(s2);students.add(s3);students.add(s4);// 按id和年龄倒序排列students.stream()        .sorted((stu1, stu2) -&gt; Long.compare(stu2.getId(), stu1.getId()))        .sorted((stu1, stu2) -&gt; Integer.compare(stu2.getAge(), stu1.getAge()))        .collect(Collectors.toList());students.stream()    // 按年龄升序排序，相同年龄按id降序排序    .sorted((stu1, stu2) -&gt; Long.compare(stu2.getId(), stu1.getId()))    .sorted(Comparator.comparingInt(Student::getAge))    .forEach(System.out::println);students.stream()    // 按年龄升序排序，相同年龄按id降序排序    .sorted(Comparator.comparingLong(Student::getId).reversed())    .sorted(Comparator.comparingInt(Student::getAge))    .forEach(System.out::println);students.stream()    // 按年龄升序排序，相同年龄按id升序排序    .sorted(Comparator.comparingInt(Student::getAge).thenComparingLong(Student::getId))    .forEach(System.out::println);students.stream()    // 按年龄升序排序，相同年龄按id升序排序，反向取值，即按年龄排序，年龄相同按id升序    .sorted(Comparator.comparingInt(Student::getAge)            .reversed()            .thenComparingLong(Student::getId)            .reversed())    .forEach(System.out::println);\n\n\n\n截取截取前N个\n//集合limit，返回前几个元素List&lt;String&gt; list = Arrays.asList(&quot;333&quot;, &quot;222&quot;, &quot;111&quot;);list.stream().limit(2).forEach(System.out::println);\n\n\n\n跳过前N个\n//集合skip，删除前n个元素List&lt;String&gt; list = Arrays.asList(&quot;333&quot;, &quot;222&quot;, &quot;111&quot;);list.stream().skip(2).forEach(System.out::println);\n\n\n\n聚合//集合reduce,将集合中每个元素聚合成一条数据List&lt;String&gt; list = Arrays.asList(&quot;欢&quot;, &quot;迎&quot;, &quot;你&quot;);String appendStr = list.stream().reduce(&quot;北京&quot;, (a, b) -&gt; a + b);\n\n\n\n极值Student s1 = new Student(1L, &quot;肖战&quot;, 14, &quot;浙江&quot;);Student s2 = new Student(2L, &quot;王一博&quot;, 15, &quot;湖北&quot;);Student s3 = new Student(3L, &quot;杨紫&quot;, 17, &quot;北京&quot;);Student s4 = new Student(4L, &quot;李现&quot;, 17, &quot;浙江&quot;);List&lt;Student&gt; students = new ArrayList&lt;&gt;();students.add(s1);students.add(s2);students.add(s3);students.add(s4);// 求年龄最小的学生Student minS = students.stream()                       .min(Comparator.comparingInt(Student::getAge))                       .orElse(new Student(0L, null, 0, null));\n\n\n\n匹配\n anyMatch：Stream 中任意一个元素符合传入的 predicate，返回 true allMatch：Stream 中全部元素符合传入的 predicate，返回 true noneMatch：Stream 中没有一个元素符合传入的 predicate，返回 true\n\nStudent s1 = new Student(1L, &quot;肖战&quot;, 15, &quot;浙江&quot;);Student s2 = new Student(2L, &quot;王一博&quot;, 15, &quot;湖北&quot;);Student s3 = new Student(3L, &quot;杨紫&quot;, 17, &quot;北京&quot;);Student s4 = new Student(4L, &quot;李现&quot;, 17, &quot;浙江&quot;);List&lt;Student&gt; students = new ArrayList&lt;&gt;();students.add(s1);students.add(s2);students.add(s3);students.add(s4);boolean anyMatch = students.stream()    .anyMatch(s -&gt; &quot;湖北&quot;.equals(s.getAddress()));if (anyMatch) &#123;    System.out.println(&quot;有湖北人&quot;);&#125;boolean allMatch = students.stream()    .allMatch(s -&gt; s.getAge() &gt;= 15);if (allMatch) &#123;    System.out.println(&quot;所有学生都满15周岁&quot;);&#125;boolean noneMatch = students.stream()    .noneMatch(s -&gt; &quot;杨洋&quot;.equals(s.getName()));if (noneMatch) &#123;    System.out.println(&quot;没有叫杨洋的同学&quot;);&#125;\n\n\n\n分组Student s1 = new Student(1L, &quot;肖战&quot;, 15, &quot;浙江&quot;);Student s2 = new Student(2L, &quot;王一博&quot;, 15, &quot;湖北&quot;);Student s3 = new Student(3L, &quot;杨紫&quot;, 17, &quot;北京&quot;);Student s4 = new Student(4L, &quot;李现&quot;, 17, &quot;浙江&quot;);Student s5 = new Student(5L, &quot;肖战&quot;, 17, &quot;浙江&quot;);Student s6 = new Student(6L, &quot;肖战&quot;, 15, &quot;浙江&quot;);List&lt;Student&gt; students = new ArrayList&lt;&gt;();students.add(s1);students.add(s2);students.add(s3);students.add(s4);students.add(s5);students.add(s6);// 按照姓名和年龄分组Map&lt;String, Map&lt;Integer, List&lt;Student&gt;&gt;&gt; groupMap = students.stream()    .collect(Collectors.groupingBy(Student::getName, Collectors.groupingBy(Student::getAge)));\n\n结果如下：\n&#123;    &quot;肖战&quot;: &#123;        &quot;15&quot;: [            &#123;                &quot;address&quot;: &quot;浙江&quot;,                &quot;age&quot;: 15,                &quot;id&quot;: 1,                &quot;name&quot;: &quot;肖战&quot;            &#125;,            &#123;                &quot;address&quot;: &quot;浙江&quot;,                &quot;age&quot;: 15,                &quot;id&quot;: 6,                &quot;name&quot;: &quot;肖战&quot;            &#125;        ],        &quot;17&quot;: [            &#123;                &quot;address&quot;: &quot;浙江&quot;,                &quot;age&quot;: 17,                &quot;id&quot;: 5,                &quot;name&quot;: &quot;肖战&quot;            &#125;        ]    &#125;    ...&#125;\n\n\n\n","categories":["后端","Java"],"tags":["Java","Java8","Lambda"]},{"title":"Oracle 自定义函数","url":"/%E6%95%B0%E6%8D%AE%E5%BA%93/Oracle/Oracle%E8%87%AA%E5%AE%9A%E4%B9%89%E5%87%BD%E6%95%B0/","content":"计算两个日期间工作日create or replace function f_pd_gzr_days(v_kssj in date, v_jssj in date)  return number is  v_days     number := 0;  v_days_all number := 0;  v_days_jjr number := 0;  v_real_kssj date  := v_kssj;  v_real_jssj date  := v_jssj;  v_kssj_jjr number := 0;  v_jssj_jjr number := 0;begin  -- 计算两个日期之间的天数  if v_kssj &gt;= v_jssj then -- 如果起始时间大于结束时间，将起始时间与结束时间替换    select v_real_kssj, v_real_jssj into v_real_jssj, v_real_kssj from dual;  end if;    begin           -- 如果开始时间是节假日，开始时间改为当日24点    select count(1) into v_kssj_jjr      from sys_holiday     where to_date(holiday, &#x27;yyyy/mm/dd&#x27;) = trunc(v_real_kssj);            if v_kssj_jjr != 0 then       v_real_kssj := trunc(v_real_kssj + 1);     end if;            -- 如果结束时间是节假日，结束时间改为当日零点    select count(1) into v_jssj_jjr      from sys_holiday     where to_date(holiday, &#x27;yyyy/mm/dd&#x27;) = trunc(v_real_jssj);            if v_jssj_jjr != 0 then       v_real_jssj := trunc(v_real_jssj);     end if;            -- 计算两日期间相隔天数     v_days_all := v_real_jssj - v_real_kssj;         select count(1) into v_days_jjr      from sys_holiday     where to_date(holiday, &#x27;yyyy-mm-dd hh24:mi:ss&#x27;) &gt;= v_real_kssj       and to_date(holiday, &#x27;yyyy-mm-dd hh24:mi:ss&#x27;) &lt; v_real_jssj;           exception    when others then      v_days := 0;  end;    v_days := v_days_all - v_days_jjr;  return v_days;exception  when others then    return 0;end f_pd_gzr_days;\n\n\n\n计算若干工作日之后的日期create or replace function f_get_after_day(v_kssj date, v_delay number)return date isv_real_kssj date  := v_kssj;v_real_jssj date;v_kssj_jjr number := 0;v_jssj_jjr number := 0;v_days_jjr number := 0;begin  -- 如果开始时间是节假日，开始时间改为当日24点  select count(1) into v_kssj_jjr    from sys_holiday   where to_date(holiday, &#x27;yyyy/mm/dd&#x27;) = trunc(v_real_kssj);            if v_kssj_jjr != 0 then     v_real_kssj := trunc(v_real_kssj + 1);   end if;     v_real_jssj := v_real_kssj + v_delay;         -- 如果结束时间是节假日，结束时间改为次日  select count(1) into v_jssj_jjr    from sys_holiday   where to_date(holiday, &#x27;yyyy/mm/dd&#x27;) = trunc(v_real_jssj);              if v_jssj_jjr != 0 then     v_real_jssj := v_real_jssj + 1;     -- 计算两日期之间节假日的天数, 减去结束日期    select count(1) - 1 into v_days_jjr from sys_holiday    where to_date(holiday, &#x27;yyyy-mm-dd hh24:mi:ss&#x27;) &gt;= v_real_kssj      and to_date(holiday, &#x27;yyyy-mm-dd hh24:mi:ss&#x27;) &lt; v_real_jssj;   else    -- 计算两日期之间节假日的天数    select count(1) into v_days_jjr from sys_holiday    where to_date(holiday, &#x27;yyyy-mm-dd hh24:mi:ss&#x27;) &gt;= v_real_kssj      and to_date(holiday, &#x27;yyyy-mm-dd hh24:mi:ss&#x27;) &lt; v_real_jssj;   end if;      if v_days_jjr !=0 then    -- 迭代    v_real_jssj := f_get_after_day(v_real_jssj,v_days_jjr);  end if;return v_real_jssj;end f_get_after_day;\n\n\n\n十进制转三十六进制CREATE OR REPLACE FUNCTION FN_10_TO_36(V_NUM NUMBER)RETURN VARCHAR IS RESULT VARCHAR(800);  NUM   NUMBER;  TMP  NUMBER;  TEMP  NUMBER;BEGINNUM := V_NUM;TMP := TRUNC(NUM / 36);   WHILE NUM &gt; 0 LOOP    TEMP := MOD(NUM, 36);    IF TEMP &lt; 10 THEN      RESULT := TEMP || RESULT;    ELSE      RESULT := CHR(TEMP + 55) || RESULT;    END IF;    NUM := TMP;    TMP := TRUNC(NUM / 36);  END LOOP;  IF V_NUM &lt;= 0 THEN     return V_NUM;     END IF;return RESULT;end;\n\n\n\n获取拼音码CREATE OR REPLACE FUNCTION F_TRANS_PINYIN_CAPITAL(P_NAME IN VARCHAR2)  RETURN VARCHAR2 AS  V_COMPARE VARCHAR2(100);  V_RETURN  VARCHAR2(4000);  FUNCTION F_NLSSORT(P_WORD IN VARCHAR2) RETURN VARCHAR2 AS  BEGIN    RETURN NLSSORT(P_WORD, &#x27;NLS_SORT=SCHINESE_PINYIN_M&#x27;);  END;BEGIN  FOR I IN 1 .. LENGTH(P_NAME) LOOP    V_COMPARE := F_NLSSORT(SUBSTR(P_NAME, I, 1));    IF V_COMPARE &gt;= F_NLSSORT(&#x27;吖&#x27;) AND V_COMPARE &lt;= F_NLSSORT(&#x27;驁&#x27;) THEN      V_RETURN := V_RETURN || &#x27;a&#x27;;    ELSIF V_COMPARE &gt;= F_NLSSORT(&#x27;八&#x27;) AND V_COMPARE &lt;= F_NLSSORT(&#x27;簿&#x27;) THEN      V_RETURN := V_RETURN || &#x27;b&#x27;;    ELSIF V_COMPARE &gt;= F_NLSSORT(&#x27;嚓&#x27;) AND V_COMPARE &lt;= F_NLSSORT(&#x27;錯&#x27;) THEN      V_RETURN := V_RETURN || &#x27;c&#x27;;    ELSIF V_COMPARE &gt;= F_NLSSORT(&#x27;咑&#x27;) AND V_COMPARE &lt;= F_NLSSORT(&#x27;鵽&#x27;) THEN      V_RETURN := V_RETURN || &#x27;d&#x27;;    ELSIF V_COMPARE &gt;= F_NLSSORT(&#x27;妸&#x27;) AND V_COMPARE &lt;= F_NLSSORT(&#x27;樲&#x27;) THEN      V_RETURN := V_RETURN || &#x27;e&#x27;;    ELSIF V_COMPARE &gt;= F_NLSSORT(&#x27;发&#x27;) AND V_COMPARE &lt;= F_NLSSORT(&#x27;猤&#x27;) THEN      V_RETURN := V_RETURN || &#x27;f&#x27;;    ELSIF V_COMPARE &gt;= F_NLSSORT(&#x27;旮&#x27;) AND V_COMPARE &lt;= F_NLSSORT(&#x27;腂&#x27;) THEN      V_RETURN := V_RETURN || &#x27;g&#x27;;    ELSIF V_COMPARE &gt;= F_NLSSORT(&#x27;妎&#x27;) AND V_COMPARE &lt;= F_NLSSORT(&#x27;夻&#x27;) THEN      V_RETURN := V_RETURN || &#x27;h&#x27;;    ELSIF V_COMPARE &gt;= F_NLSSORT(&#x27;丌&#x27;) AND V_COMPARE &lt;= F_NLSSORT(&#x27;攈&#x27;) THEN      V_RETURN := V_RETURN || &#x27;j&#x27;;    ELSIF V_COMPARE &gt;= F_NLSSORT(&#x27;咔&#x27;) AND V_COMPARE &lt;= F_NLSSORT(&#x27;穒&#x27;) THEN      V_RETURN := V_RETURN || &#x27;k&#x27;;    ELSIF V_COMPARE &gt;= F_NLSSORT(&#x27;垃&#x27;) AND V_COMPARE &lt;= F_NLSSORT(&#x27;擽&#x27;) THEN      V_RETURN := V_RETURN || &#x27;l&#x27;;    ELSIF V_COMPARE &gt;= F_NLSSORT(&#x27;嘸&#x27;) AND V_COMPARE &lt;= F_NLSSORT(&#x27;椧&#x27;) THEN      V_RETURN := V_RETURN || &#x27;m&#x27;;    ELSIF V_COMPARE &gt;= F_NLSSORT(&#x27;拏&#x27;) AND V_COMPARE &lt;= F_NLSSORT(&#x27;瘧&#x27;) THEN      V_RETURN := V_RETURN || &#x27;n&#x27;;    ELSIF V_COMPARE &gt;= F_NLSSORT(&#x27;筽&#x27;) AND V_COMPARE &lt;= F_NLSSORT(&#x27;漚&#x27;) THEN      V_RETURN := V_RETURN || &#x27;o&#x27;;    ELSIF V_COMPARE &gt;= F_NLSSORT(&#x27;妑&#x27;) AND V_COMPARE &lt;= F_NLSSORT(&#x27;曝&#x27;) THEN      V_RETURN := V_RETURN || &#x27;p&#x27;;    ELSIF V_COMPARE &gt;= F_NLSSORT(&#x27;七&#x27;) AND V_COMPARE &lt;= F_NLSSORT(&#x27;裠&#x27;) THEN      V_RETURN := V_RETURN || &#x27;q&#x27;;    ELSIF V_COMPARE &gt;= F_NLSSORT(&#x27;亽&#x27;) AND V_COMPARE &lt;= F_NLSSORT(&#x27;鶸&#x27;) THEN      V_RETURN := V_RETURN || &#x27;r&#x27;;    ELSIF V_COMPARE &gt;= F_NLSSORT(&#x27;仨&#x27;) AND V_COMPARE &lt;= F_NLSSORT(&#x27;蜶&#x27;) THEN      V_RETURN := V_RETURN || &#x27;s&#x27;;    ELSIF V_COMPARE &gt;= F_NLSSORT(&#x27;侤&#x27;) AND V_COMPARE &lt;= F_NLSSORT(&#x27;籜&#x27;) THEN      V_RETURN := V_RETURN || &#x27;t&#x27;;    ELSIF V_COMPARE &gt;= F_NLSSORT(&#x27;屲&#x27;) AND V_COMPARE &lt;= F_NLSSORT(&#x27;鶩&#x27;) THEN      V_RETURN := V_RETURN || &#x27;w&#x27;;    ELSIF V_COMPARE &gt;= F_NLSSORT(&#x27;夕&#x27;) AND V_COMPARE &lt;= F_NLSSORT(&#x27;鑂&#x27;) THEN      V_RETURN := V_RETURN || &#x27;x&#x27;;    ELSIF V_COMPARE &gt;= F_NLSSORT(&#x27;丫&#x27;) AND V_COMPARE &lt;= F_NLSSORT(&#x27;韻&#x27;) THEN      V_RETURN := V_RETURN || &#x27;y&#x27;;    ELSIF V_COMPARE &gt;= F_NLSSORT(&#x27;帀&#x27;) AND V_COMPARE &lt;= F_NLSSORT(&#x27;咗&#x27;) THEN      V_RETURN := V_RETURN || &#x27;z&#x27;;    ELSE V_RETURN := V_RETURN || SUBSTR(P_NAME, I, 1);    END IF;  END LOOP;  RETURN UPPER(V_RETURN);END;\n\n","categories":["数据库","Oracle"],"tags":["Oracle"]},{"title":"Vagrant安装虚拟机","url":"/%E6%8A%80%E6%9C%AF%E6%95%99%E7%A8%8B/Vagrant/Vagrant%E5%AE%89%E8%A3%85%E8%99%9A%E6%8B%9F%E6%9C%BA/","content":"软件准备下载、安装Virtual Box https://www.virtualbox.org/wiki/Downloads\n下载、安装Vagrant https://www.vagrantup.com/downloads.html\n查看是否安装成功\n挂载虚拟机并启动1、在线直接从vagrant镜像仓库https://app.vagrantup.com/boxes/search下载镜像并启动\nvagrant init centos/7vagrant up\n\n\n\n2、离线vagrant 下载很慢，可以离线下载下来再进行挂载\n\n这里有centos的镜像 http://cloud.centos.org/centos/7/vagrant/x86_64/images/，选择需要的版本用迅雷下载\n\n下载好之后，执行命令\nvagrant box add centos7 C:\\Vagrant\\source\\CentOS-7-x86_64-Vagrant-1905_01.VirtualBox.boxvagrant init centos7\n\n然后再执行 vagrant up即可，启动完成看到下面的内容，\n\n然后就可以愉快的vagrant ssh登录了\n\n默认有两个用户\nroot/vagrant\nvagrant/vagrant\n\n设置固定IP使用ipconfig查看物理机ip地址，可以看到VirtualBox Host-Only Network的IPV4地址为192.168.56.1，修改Vagrantfile第35行，使在同一个网段\nconfig.vm.network &quot;private_network&quot;, ip: &quot;192.168.56.10&quot;\n\n重启虚拟机vagrant reload，\n测试：ping 192.168.56.10\n遇到的问题ping不通百度修改网卡配置，设置DNS，使永久生效，我的虚拟机有两个网卡eth0和eth1，修改eth1\nvi /etc/sysconfig/network-scripts/ifcfg-eth1# 添加：DNS1=114.114.114.114DNS2=8.8.8.8\n\n也可以\necho DNS1=8.8.8.8 &gt;&gt; /etc/sysconfig/network-scripts/ifcfg-eth1echo DNS2=114.114.114.114 &gt;&gt; /etc/sysconfig/network-scripts/ifcfg-eth1\n\n\n这两行DNS配置追加到网卡配置里\n\n重启网卡\nsystemctl restart network\n\n\n\nssh远程连接报错新建的虚拟机通过私有网络ssh报错，无法登录\nDisconnected: No supported authentication methods available(server sent:public key)\n可以通过修改配置文件\nvi /etc/ssh/sshd_config# 将 PasswordAuthentication 修改 no 为 yesPasswordAuthentication yes\n\n\n\n然后重启服务\nsudo systemctl restart sshd\n\n","categories":["技术教程","Vagrant"],"tags":["Vagrant","虚拟机"]},{"title":"Docker的使用","url":"/%E6%8A%80%E6%9C%AF%E6%95%99%E7%A8%8B/Docker/Docker%E7%9A%84%E4%BD%BF%E7%94%A8/","content":"背景环境(切换/配置)麻烦项目（产品）过程中，有如下3个环境：\n\n研发写代码的环境叫做开发环境。\n测试进行验证的环境叫做测试环境。\n用户部署使用的环境叫做生产环境。\n\n其实在很多时候，大量的时间浪费在了环境上。\n\n如果我现在重装了系统，我想要跑我的jar包，我得去安装一下JDK、Tomcat、MySQL等，并配置各种环境变量才能跑起来。\n\n好不容易开发环境没问题了，但是到测试环境就是各种bug。\n\n好不容易在测试环境验证通过了，但是在生产环境就各种出错。\n\n\n应用之间需要隔离比如有两个web应用，这两个应用部署在同一台服务器上，那可能会出现什么问题？\n\n如果一个应用出现了问题，导致CPU占100%。那另一个应用也会受到影响，跟着一起宕机了。\n\n这两个应用是不同技术栈的应用，比如一个jdk，一个php。这两个应用各种的依赖软件都安装在同一个服务器上，可能就会造成各种冲突/无法兼容，这可能调试就非常麻烦了。\n\n\n使用Docker 进行解决\n将一整套环境打包封装成镜像，无需重复配置环境，解决环境带来的种种问题。从开发的角度来看就是三步走：构建，发布，运行。其中关键步骤就是构建环节，即打包镜像文件。从测试和运维的角度来看，那就只有两步：复制，运行。有了这个镜像，那么想复制到哪运行都可以，完全和平台无关了。\nDocker容器间是进程隔离的，相互之间互不影响\nDocker的性能几乎和原生系统无异，并且系统支持量很高。\n\n概述Docker 是一个开源的应用容器引擎，让开发者可以打包他们的应用以及依赖包到一个可移植的镜像中，然后发布到任何流行的 Linux或Windows 机器上，也可以实现虚拟化。容器是完全使用沙箱机制，相互之间不会有任何接口。\n\nDocker是容器虚拟化技术，可以有多个容器（可以不同功能）且相互隔离，互不影响。容器没有自己的内核，直接运行于宿主主机的内核。\n\nDocker优点\n简化程序： Docker 让开发者可以打包他们的应用以及依赖包到一个可移植的容器中，然后发布到任何流行的 Linux 机器上，便可以实现虚拟化。Docker改变了虚拟化的方式，使开发者可以直接将自己的成果放入Docker中进行管 理。方便快捷已经是 Docker的最大优势，过去需要用数天乃至数周的任务，在Docker容器的处理下，只需要数秒就 能完成。\n\n避免选择恐惧症： 如果你有选择恐惧症，还是资深患者。Docker 帮你打包你的纠结！比如 Docker 镜像；Docker 镜 像中包含了运行环境和配置，所以 Docker 可以简化部署多种应用实例工作。比如 Web 应用、后台应用、数据库应 用、大数据应用比如 Hadoop 集群、消息队列等等都可以打包成一个镜像部署。 \n\n节省开支： 一方面，云计算时代到来，使开发者不必为了追求效果而配置高额的硬件，Docker 改变了高性能必然高 价格的思维定势。Docker 与云的结合，让云空间得到更充分的利用。不仅解决了硬件管理的问题，也改变了虚拟化 的方式。\n\n\n容器和虚拟机\nDocker 在容器的基础上，进行了进一步的封装，从文件系统、网络互联到进程隔离等等，极大的简化了容器的创建和维护。使得 Docker 技术比虚拟机技术更为轻便、快捷。\n\n\nDocker 安装Docker 提供了两个版本：社区版 (CE) 和企业版 (EE)。 \n操作系统要求 以Centos7为例，且Docker 要求操作系统必须为64位，且centos内核版本为3.1及以上。 \n查看系统内核版本信息： \nuname -r\n\n\n\n准备卸载旧版本： \nsudo yum remove docker \\                docker-client \\                docker-client-latest \\                docker-common \\                docker-latest \\                docker-latest-logrotate \\                docker-logrotate \\                docker-engine\n\n\n\n安装依赖软件包\nsudo yum install -y yum-utils\n\n\n\n设置yum源\nsudo yum-config-manager --add-repo \\https://download.docker.com/linux/centos/docker-ce.repo\n\n\n\n安装安装最新版本docker-ce、docker-ce-cli和containerd.io\nsudo yum install docker-ce docker-ce-cli containerd.io# 安装完成之后可以使用命令查看sudo docker version\n\n\n\n如果要安装指定版本，可以查看仓库中所有docker版本，然后选择特定版本安装\nsudo yum list docker-ce --showduplicates | sort -rdocker-ce.x86_64      3:18.09.1-3.el7                 docker-ce-stabledocker-ce.x86_64      3:18.09.0-3.el7                 docker-ce-stabledocker-ce.x86_64      18.06.1.ce-3.el7                docker-ce-stable...docker-ce-cli.x86_64  1:19.03.8-3.el7                 @docker-ce-stabledocker-ce-cli.x86_64  1:19.03.7-3.el7                 docker-ce-stabledocker-ce-cli.x86_64  1:19.03.6-3.el7                 docker-ce-stable...sudo yum install docker-ce-18.09.1 docker-ce-cli-19.03.8 containerd.io\n\n\n\n配置镜像加速这里使用阿里云的免费镜像加速服务，也可以使用其他如时速云、网易云等 \nsudo mkdir -p /etc/docker# 配置自己的加速器地址sudo tee /etc/docker/daemon.json &lt;&lt;-&#x27;EOF&#x27;&#123;  &quot;registry-mirrors&quot;: [&quot;https://2lz3pdx1.mirror.aliyuncs.com&quot;]&#125;EOF# 通知systemd重载此配置文件；sudo systemctl daemon-reload# 重启docker服务sudo systemctl restart docker\n\n\n\n启动sudo systemctl start docker\n\n\n\n设置开机自启sudo systemctl enable docker\n\n\n\nDocker 常用操作输入 docker 可以查看Docker的命令用法，输入 docker COMMAND –help 查看指定命令详细用法。 \n镜像常用操作查找镜像：docker search 关键词#搜索docker hub网站镜像的详细信息\n\n\n\n下载镜像：docker pull 镜像名:TAG# Tag表示版本，有些镜像的版本显示latest，为最新版本\n\n\n\n查看镜像：docker images# 查看本地所有镜像\n\n\n\n删除镜像：docker rmi -f 镜像ID或者镜像名:TAG# 删除指定本地镜像# -f 表示强制删除\n\n删除所有镜像\ndocker rmi $(docker images -q)\n\n\n\n导出镜像docker save mynginx -o /exp/mynginx.tardocker rmi mynginx # 删除 mynginx 镜像docker images # 查看镜像，可以看到 mynginx 已经不见了\n\n\n\n导入镜像docker load -i /exp/mynginx.tardocker images # 查看镜像，可以看到 mynginx 被加载进来了\n\n\n\n获取元信息：docker inspect 镜像ID或者镜像名:TAG# 获取镜像的元信息，详细信息\n\n\n\n容器常用操作运行：docker run --name 容器名 -i -t -p 主机端口:容器端口 -d -v 主机目录:容器目录:ro 镜像ID或镜像名:TAG# --name 指定容器名，可自定义，不指定自动命名# -i 以交互模式运行容器# -t 分配一个伪终端，即命令行，通常-it组合来使用# -p 指定映射端口，讲主机端口映射到容器内的端口# -d 后台运行容器# -v 指定挂载主机目录到容器目录，默认为rw读写模式，ro表示只读\n\n\n\n容器列表：docker ps -a -q# docker ps查看正在运行的容器# -a 查看所有容器（运行中、未运行）# -q 只查看容器的ID\n\n\n\n启动容器：docker start 容器ID或容器名\n\n\n\n停止容器：docker stop 容器ID或容器名\n\n停止所有容器\ndocker stop $(docker ps -aq)\n\n\n\n删除容器：docker rm -f 容器ID或容器名# -f 表示强制删除\n\n删除所有容器\ndocker rm $(docker ps -aq)\n\n\n\n查看日志：docker logs 容器ID或容器名\n\n\n\n进入正在运行容器：docker exec -it 容器ID或者容器名 /bin/bash# 进入正在运行的容器并且开启交互模式终端# /bin/bash是固有写法，作用是因为docker后台必须运行一个进程，否则容器就会退出，在这里表示启动容器后启动 bash。# 也可以用docker exec在运行中的容器执行命令，比如打开redis客户端 redis-cli\n\n\n\n拷贝文件：docker cp 主机文件路径 容器ID或容器名:容器路径 # 主机中文件拷贝到容器中docker cp 容器ID或容器名:容器路径 主机文件路径 # 容器中文件拷贝到主机中\n\n\n\n获取容器元信息：docker inspect 容器ID或容器名\n\n\n\n\nDocker 生成镜像有时候从Docker镜像仓库中下载的镜像不能满足要求，我们可以基于一个基础镜像构建一个自己的镜像 两种方式： \n\n更新镜像：使用 docker commit 命令\n\n构建镜像：使用 docker build 命令，需要创建Dockerfile文件\n\n\n更新镜像先使用基础镜像创建一个容器，然后对容器内容进行更改，然后使用 docker commit 命令提交为一个新的镜像（以 tomcat为例）。 \n根据基础镜像，创建容器docker run --name mytomcat -p 80:8080 -d tomcat\n\n\n\n修改容器内容docker exec -it mytomcat /bin/bashcd webapps/ROOTrm -f index.jspecho hello world &gt; index.htmlexit\n\n\n\n提交为新镜像docker commit -m=&quot;描述消息&quot; -a=&quot;作者&quot; 容器ID或容器名 镜像名:TAG# 例:# docker commit -m=&quot;修改了首页&quot; -a=&quot;valten&quot; mytomcat huaan/tomcat:v1.0\n\n\n\n使用新镜像运行容器docker run --name tom -p 8080:8080 -d huaan/tomcat:v1.0\n\n\n\n\n\n构建镜像先使用Dockerfile修改基础镜像，然后使用 docker build命令构建一个新的镜像。 \n准备1.把你的springboot项目打包成可执行jar包 \n2.把jar包上传到Linux服务器\n构建创建Dockerfile文件\nvi Dockerfile# Dockerfile 文件内容# 指定基础镜像，本地没有会从dockerHub pull下来FROM java:8#作者MAINTAINER huaan# 把可执行jar包复制到基础镜像的根目录下ADD luban.jar /luban.jar# 镜像要暴露的端口，如要使用端口，在执行docker run命令时使用-p生效EXPOSE 80# 在镜像运行为容器后执行的命令ENTRYPOINT [&quot;java&quot;,&quot;-jar&quot;,&quot;/luban.jar&quot;]\n\n\n\n使用 docker build 命令构建镜像，基本语法\ndocker build -t huaan/mypro:v1 .# -f指定Dockerfile文件的路径# -t指定镜像名字和TAG# .指当前目录，这里实际上需要一个上下文路径\n\n\n\n运行运行自己的springboot镜像\ndocker run --name pro -p 80:80 -d 镜像名:TAG\n\n\n\nDockerfileDockerfile\n在Docker中创建镜像最常用的方式，就是使用Dockerfile。Dockerfile是一个Docker镜像的描述文件，我们可以理解成火箭发射的A、B、C、D…的步骤。Dockerfile其内部包含了一条条的指令，每一条指令构建一层，因此每一条指令的内容，就是描述该层应当如何构建。\n\nDockerfile结构大致分为四个部分:\n\n基础镜像信息\n维护者信息\n镜像操作指令\n容器启动时执行指令。\n\nDockerfile每行支持一条指令，每条指令可以带多个参数，支持使用以#号开头的注释。\n\nFROMFROM指令是最重要的一个并且必须为Dockerfile文件开篇的第一个非注释行，用于为镜像文件构建过程指定基础镜 像，后续的指令运行于此基础镜像提供的运行环境 这个基础镜像可以是任何可用镜像，默认情况下docker build会从本地仓库找指定的镜像文件，如果不存在就会从 Docker Hub上拉取 。\n语法：\nFROM &lt;image&gt;FROM &lt;image&gt;:&lt;tag&gt;FROM &lt;image&gt;@&lt;digest&gt;\n\n\n\nMAINTAINERDockerfile的制作者提供的本人详细信息 Dockerfile不限制MAINTAINER出现的位置，但是推荐放到FROM指令之后。 \n语法：\nMAINTAINER &lt;name&gt;\n\nname可以是任何文本信息，一般用作者名称或者邮箱\nCOPY用于从宿主机复制文件到创建的新镜像文件 \n语法：\nCOPY &lt;src&gt;...&lt;dest&gt;COPY [&quot;&lt;src&gt;&quot;,...&quot;&lt;dest&gt;&quot;]# &lt;src&gt;：要复制的源文件或者目录，可以使用通配符# &lt;dest&gt;：目标路径，即正在创建的image的文件系统路径；建议&lt;dest&gt;使用绝对路径，否则COPY指令则以WORKDIR为其起始路径\n\n注意：如果你的路径中有空白字符，通常会使用第二种格式 \n规则： \n\n&lt;src&gt;必须是build上下文中的路径，不能是其父目录中的文件 \n\n如果&lt;src&gt;是目录，则其内部文件或子目录会被递归复制，但&lt;src&gt;目录自身不会被复制 \n\n如果指定了多个&lt;src&gt;，或在&lt;src&gt;中使用了通配符，则&lt;dest&gt;必须是一个目录，必须以/符号结尾 \n\n如果&lt;dest&gt;不存在，将会被自动创建，包括其父目录路径\n\n\nADD基本用法和COPY指令一样，ADD支持使用TAR文件和URL路径 \n语法： \nADD &lt;src&gt;...&lt;dest&gt;ADD [&quot;&lt;src&gt;&quot;,...&quot;&lt;dest&gt;&quot;]\n\n规则： \n\n和COPY规则相同 \n如果&lt;src&gt;为URL并且&lt;dest&gt;没有以/结尾，则&lt;src&gt;指定的文件将被下载到&lt;dest&gt;\n如果&lt;src&gt;是一个本地系统上压缩格式的tar文件，它会展开成一个目录；但是通过URL获取的tar文件不会自动 展开 \n如果&lt;src&gt;有多个，直接或间接使用了通配符指定多个资源，则&lt;dest&gt;必须是目录并且以/结尾\n\nWORKDIR用于为Dockerfile中所有的RUN、CMD、ENTRYPOINT、COPY和ADD指定设定工作目录，只会影响当前WORKDIR 之后的指令。 \n语法： \nWORKDIR &lt;dirpath&gt;\n\n在Dockerfile文件中，WORKDIR可以出现多次，路径可以是相对路径，但是它是相对于前一个WORKDIR指令指定的 路径 另外，WORKDIR可以是ENV指定定义的变量\nVOLUME用来创建挂载点，可以挂载宿主机上的卷或者其他容器上的卷 \n语法： \nVOLUME &lt;mountpoint&gt;VOLUME [&quot;&lt;mountpoint&gt;&quot;]\n\n不能指定宿主机当中的目录，宿主机挂载的目录是自动生成的 \nEXPOSE用于给容器打开指定要监听的端口以实现和外部通信 语法：\nEXPOSE &lt;port&gt;[/&lt;protocol&gt;] [&lt;port&gt;[/&lt;protocol&gt;]...]\n\n&lt;protocol&gt;用于指定传输层协议，可以是TCP或者UDP，默认是TCP协议 \nEXPOSE可以一次性指定多个端口，例如： EXPOSE 80/tcp 80/udp\nENV用来给镜像定义所需要的环境变量，并且可以被Dockerfile文件中位于其后的其他指令(如ENV、ADD、COPY等)所调 用，调用格式：$variable_name或者${variable_name} \n语法：\nENV &lt;key&gt; &lt;value&gt;ENV &lt;key&gt;=&lt;value&gt;...\n\n第一种格式中，  之后的所有内容都会被视为&lt;value&gt;的组成部分，所以一次只能设置一个变量 \n第二种格式可以一次设置多个变量，如果&lt;value&gt;当中有空格可以使用\\进行转义或者对&lt;value&gt;加引号进行标识； 另外\\也可以用来续行\nARG用法同ENV \n语法： \nARG &lt;name&gt;[=&lt;default value&gt;]\n\n指定一个变量，可以在docker build创建镜像的时候，使用--build-arg =&lt;varname&gt;=&lt;value&gt;来指定参数\nRUN用来指定docker build过程中运行指定的命令 \n语法： \nRUN &lt;command&gt;RUN [&quot;&lt;executable&gt;&quot;,&quot;&lt;param1&gt;&quot;,&quot;&lt;param2&gt;&quot;]\n\n第一种格式里面的参数一般是一个shell命令，以 /bin/sh -c 来运行它 \n第二种格式中的参数是一个JSON格式的数组，当中&lt;executable&gt;是要运行的命令，后面是传递给命令的选项或者 参数；但是这种格式不会用/bin/sh -c来发起，所以常见的shell操作像变量替换和通配符替换不会进行；如果你运 行的命令依赖shell特性，可以替换成类型以下的格式\nRUN [&quot;/bin/bash&quot;,&quot;-c&quot;,&quot;&lt;executable&gt;&quot;,&quot;&lt;param1&gt;&quot;]\n\n\n\nCMD容器启动时运行的命令 \n语法： \nCMD &lt;command&gt;CMD [&quot;&lt;executable&gt;&quot;,&quot;&lt;param1&gt;&quot;,&quot;&lt;param2&gt;&quot;]CMD [&quot;&lt;param1&gt;&quot;,&quot;&lt;param2&gt;&quot;]\n\n前两种语法和RUN相同 \n第三种语法用于为ENTRYPOINT指令提供默认参数 \nRUN和CMD区别： \n\nRUN指令运行于镜像文件构建过程中，CMD则运行于基于Dockerfile构建出的新镜像文件启动为一个容器的时候 \n\nCMD指令的主要目的在于给启动的容器指定默认要运行的程序，且在运行结束后，容器也将终止；不过，CMD 命令可以被docker run的命令行选项给覆盖 \n\nDockerfile中可以存在多个CMD指令，但是只有最后一个会生效\n\n\nENTRYPOINT类似于CMD指令功能，用于给容器指定默认运行程序 \n语法：\nENTRYPOINT&lt;command&gt;ENTRYPOINT[&quot;&lt;executable&gt;&quot;,&quot;&lt;param1&gt;&quot;,&quot;&lt;param2&gt;&quot;]\n\n\n和CMD不同的是ENTRYPOINT启动的程序不会被docker run命令指定的参数所覆盖，而且，这些命令行参数会被当 做参数传递给ENTRYPOINT指定的程序(但是，docker run命令的–entrypoint参数可以覆盖ENTRYPOINT) \n\ndocker run命令传入的参数会覆盖CMD指令的内容并且附加到ENTRYPOINT命令最后作为其参数使用 \n\n同样，Dockerfile中可以存在多个ENTRYPOINT指令，但是只有最后一个会生效 \n\nDockerfile中如果既有CMD又有ENTRYPOINT，并且CMD是一个完整可执行命令，那么谁在最后谁生效\n\n\nONBUILD用来在Dockerfile中定义一个触发器 \n语法：\nONBUILD &lt;instruction&gt;\n\n\nDockerfile用来构建镜像文件，镜像文件也可以当成是基础镜像被另外一个Dockerfile用作FROM指令的参数 在后面这个Dockerfile中的FROM指令在构建过程中被执行的时候，会触发基础镜像里面的ONBUILD指令 \n\nONBUILD不能自我嵌套，ONBUILD不会触发FROM和MAINTAINER指令 \n\n在ONBUILD指令中使用ADD和COPY要小心，因为新构建过程中的上下文在缺少指定的源文件的时候会失败\n\n\nLABEL给镜像指定各种元数据 \n语法：\nLABEL &lt;key&gt;=&lt;value&gt; &lt;key&gt;=&lt;value&gt; &lt;key&gt;=&lt;value&gt;...\n\n一个Dockerfile可以写多个LABEL，但是不推荐这么做，Dockerfile每一条指令都会生成一层镜像，如果LABEL太长可 以使用\\符号换行。构建的镜像会继承基础镜像的LABEL，并且会去掉重复的，但如果值不同，则后面的值会覆盖前 面的值。 \nDocker 三剑客Docker machineDocker Machine 是一种可以让您在虚拟主机上安装 Docker 的工具，并可以使用 docker-machine 命令来管理主机。\nDocker Machine 也可以集中管理所有的 docker 主机，比如快速的给 100 台服务器安装上 docker。\nDocker Machine 管理的虚拟主机可以是实体机器上的，也可以是云供应商，如阿里云，腾讯云，AWS等。\n使用 docker-machine 命令，您可以启动，检查，停止和重新启动托管主机，也可以升级 Docker 客户端和守护程序，以及配置 Docker 客户端与您的主机进行通信。\n安装curl -L https://github.com/docker/machine/releases/download/v0.12.0/docker-machine-`uname -s`-`uname -m` &gt; /tmp/docker-machinechmod +x /tmp/docker-machinesudo mv /tmp/docker-machine /usr/local/bin/docker-machine\n\n安装完毕以后用docker-machine –v查看版本\n常用命令1、列出可用的机器（ ls ）\ndocker-machine ls\n\n\n\n2、创建机器（ create ）\ndocker-machine create --driver virtualbox test\n\n\n–driver：指定用来创建机器的驱动类型，这里是 virtualbox\n\n3、查看机器的 ip（ ip ）\ndocker-machine ip test\n\n\n\n4、停止机器（ stop ）\ndocker-machine stop test\n\n\n\n5、启动机器（ start ）\ndocker-machine start test\n\n\n\n6、进入机器（ ssh ）\ndocker-machine ssh test\n\n\n\n用途使用 Docker Machine 方便在不同的环境中使用 Docker ，比如：Win/Mac。\n使用 Docker Machine 方便在云环境下批量部署 Docker环境，比如：私有云，公有云下批量安装Docker环境。\nDocker ComposeCompose 项目是Docker官方的开源项目，负责实现Docker容器集群的快速编排。\n我们知道使用Dockerfile模板文件可以让用户很方便的定义一个单独的应用容器，但是在工作中，经常会碰到需要多个容器相互配合来完成的某项任务的情况，例如工作中的web服务容器本身，往往会在后端加上数据库容器，服务发现容器，服务网关容器等。\nCompose 就是来做这个事情的，它允许用户通过一个单独的docker-compose.yml模板文件(YAML格式)来定义一组相关联的应用容器为一个项目(project)\nCompose 中有两个重要的概念：\n服务(service)：一个应用的容器，实际上可以包括若干运行相同镜像的容器实例。\n项目(project)：由一组关联的应用容器组成的一个完整业务单元，在docker-compose.yml中定义。\n安装：curl -L https://github.com/docker/compose/releases/download/1.23.0-rc2/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-composechmod +x /usr/local/bin/docker-compose\n\n安装完毕以后用docker-compose version查看版本\nDocker SwarmDocker Swarm 和 Docker Compose 一样，都是 Docker 官方容器编排项目，但不同的是，Docker Compose 是一个在单个服务器或主机上创建多个容器的工具，而Docker Swarm 则可以在多个服务器或主机上创建容器集群服务，对于微服务的部署，显然 Docker Swarm 会更加适合。\nDocker Swarm 包含两方面：\n\n企业级的 Docker 安全集群\n\n微服务应用编排引擎\n\n\n集群方面：Swarm 将一个或多个 Docker 节点组织起来，使得用户能够以集群方式管理它们，可以自如地添加或删除节点。\n编排方面：Swarm 提供了一套丰富的 API 使得部署和管理复杂的微服务应用变得易如反掌。通过将应用定义在声明式配置文件中，就可以使用原生的 Docker 命令完成部署。\n此外，甚至还可以执行滚动升级、回滚以及扩缩容操作，同样基于简单的命令即可完成。\n以往，Docker Swarm 是一个基于 Docker 引擎之上的独立产品。\n自 Docker 1.12 版本之后，它已经完全集成在 Docker 引擎中，执行一条命令即可启用。\n集群管理: docker swarm 子命令有 init, join, leave, update （docker swarm --help）节点管理: docker node子 命令有 accept, promote, demote, inspect, update, tasks, ls, rm （docker node --help）配置管理: docker config 子命令有 create, inspect, ls, rm （docker config--help）服务管理: docker service 子命令有 create, inspect, update, remove, tasks, ls, rm, ps （docker service--help）堆栈管理: docker stack 子命令有 deploy, services, ps, rm （docker stack--help）\n\n","categories":["技术教程","Docker"],"tags":["Docker"]},{"title":"Maven整合SSM框架","url":"/%E5%90%8E%E7%AB%AF/SpringMVC/Maven%E6%95%B4%E5%90%88SSM%E6%A1%86%E6%9E%B6/","content":"前言前段时间，需要验证一个东西，需要用到SSM框架，手头上没有现成的整合好的，就自己整合了一个。\n在写代码之前我们先了解一下这三个框架分别是干什么的？相信大以前也看过不少这些概念，我这就用大白话来讲，如果之前有了解过可以跳过这一大段，直接看代码！\n\nSpringMVC：它用于web层，相当于controller（等价于传统的servlet和struts的action），用来处理用户请求。举个例子，用户在地址栏输入http://网站域名/login，那么springmvc就会拦截到这个请求，并且调用controller层中相应的方法，（中间可能包含验证用户名和密码的业务逻辑，以及查询数据库操作，但这些都不是springmvc的职责），最终把结果返回给用户，并且返回相应的页面（当然也可以只返回json/xml等格式数据）。springmvc就是做前面和后面过程的活，与用户打交道！！\n\n\nSpring：太强大了，以至于我无法用一个词或一句话来概括它。但与我们平时开发接触最多的估计就是IOC容器，它可以装载bean（也就是我们java中的类，当然也包括service dao里面的），有了这个机制，我们就不用在每次使用这个类的时候为它初始化，很少看到关键字new。另外spring的aop，事务管理等等都是我们经常用到的。\n\n\nMyBatis：如果你问我它跟鼎鼎大名的Hibernate有什么区别？我只想说，他更符合我的需求。第一，它能自由控制sql，这会让有数据库经验的人（当然不是说我啦捂脸）编写的代码能搞提升数据库访问的效率。第二，它可以使用xml的方式来组织管理我们的sql，因为一般程序出错很多情况下是sql出错，别人接手代码后能快速找到出错地方，甚至可以优化原来写的sql。\n\n开发环境搭建:\nIDEA 2019.3\nMAVEN 3.6.0\nJdk 1.8.0_181\nTomcat  8.0.39\nMySQL 5.7.20\n\n创建项目【File】-&gt;【New】-&gt;【Project】-&gt;【Maven】-&gt;【Create from archetype】-&gt;【maven-archetype-webapp】\n\n项目结构创建好的项目后添加必要的目录，结构如下\n\n添加依赖&lt;dependencies&gt;    &lt;!-- spring --&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework&lt;/groupId&gt;        &lt;artifactId&gt;spring-core&lt;/artifactId&gt;        &lt;version&gt;$&#123;org.springframework.version&#125;&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework&lt;/groupId&gt;        &lt;artifactId&gt;spring-beans&lt;/artifactId&gt;        &lt;version&gt;$&#123;org.springframework.version&#125;&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework&lt;/groupId&gt;        &lt;artifactId&gt;spring-context&lt;/artifactId&gt;        &lt;version&gt;$&#123;org.springframework.version&#125;&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework&lt;/groupId&gt;        &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt;        &lt;version&gt;$&#123;org.springframework.version&#125;&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework&lt;/groupId&gt;        &lt;artifactId&gt;spring-tx&lt;/artifactId&gt;        &lt;version&gt;$&#123;org.springframework.version&#125;&lt;/version&gt;    &lt;/dependency&gt;    &lt;!-- spring web --&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework&lt;/groupId&gt;        &lt;artifactId&gt;spring-web&lt;/artifactId&gt;        &lt;version&gt;$&#123;org.springframework.version&#125;&lt;/version&gt;    &lt;/dependency&gt;    &lt;!--spring mvc--&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework&lt;/groupId&gt;        &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt;        &lt;version&gt;$&#123;org.springframework.version&#125;&lt;/version&gt;    &lt;/dependency&gt;    &lt;!-- aop --&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework&lt;/groupId&gt;        &lt;artifactId&gt;spring-aop&lt;/artifactId&gt;        &lt;version&gt;$&#123;org.springframework.version&#125;&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework&lt;/groupId&gt;        &lt;artifactId&gt;spring-aspects&lt;/artifactId&gt;        &lt;version&gt;$&#123;org.springframework.version&#125;&lt;/version&gt;    &lt;/dependency&gt;    &lt;!--postgresql--&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.postgresql&lt;/groupId&gt;        &lt;artifactId&gt;postgresql&lt;/artifactId&gt;        &lt;version&gt;9.4.1212&lt;/version&gt;    &lt;/dependency&gt;    &lt;!-- mysql --&gt;    &lt;dependency&gt;        &lt;groupId&gt;mysql&lt;/groupId&gt;        &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;        &lt;version&gt;5.1.47&lt;/version&gt;        &lt;scope&gt;runtime&lt;/scope&gt;    &lt;/dependency&gt;    &lt;!--数据库连接池druid--&gt;    &lt;dependency&gt;        &lt;groupId&gt;com.alibaba&lt;/groupId&gt;        &lt;artifactId&gt;druid&lt;/artifactId&gt;        &lt;version&gt;1.0.11&lt;/version&gt;    &lt;/dependency&gt;    &lt;!-- mybatis --&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.mybatis&lt;/groupId&gt;        &lt;artifactId&gt;mybatis&lt;/artifactId&gt;        &lt;version&gt;3.3.0&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.mybatis&lt;/groupId&gt;        &lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt;        &lt;version&gt;1.2.3&lt;/version&gt;    &lt;/dependency&gt;    &lt;!--json支持--&gt;    &lt;dependency&gt;        &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt;        &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt;        &lt;version&gt;2.5.4&lt;/version&gt;    &lt;/dependency&gt;    &lt;!--fastjson --&gt;    &lt;dependency&gt;        &lt;groupId&gt;com.alibaba&lt;/groupId&gt;        &lt;artifactId&gt;fastjson&lt;/artifactId&gt;        &lt;version&gt;1.1.39&lt;/version&gt;    &lt;/dependency&gt;    &lt;!--slf4j--&gt;    &lt;dependency&gt;        &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt;        &lt;artifactId&gt;logback-classic&lt;/artifactId&gt;        &lt;version&gt;1.1.1&lt;/version&gt;    &lt;/dependency&gt;&lt;/dependencies&gt;\n\n\n\n\n\n配置文件jdbc.properties在resources文件夹里新建一个jdbc.properties文件。\n# mysqljdbc.driver=com.mysql.jdbc.Driverjdbc.url=jdbc:mysql://localhost:3306/test?useUnicode=true&amp;characterEncoding=utf-8jdbc.username=rootjdbc.password=123456# postgresqljdbc.driver.pg=org.postgresql.Driverjdbc.url.pg=jdbc:postgresql://127.0.0.1:5432/testjdbc.username.pg=rootjdbc.password.pg=123456#  切换数据源 postgresql mysqldataSource: postgresqljdbc.initialSize=3jdbc.maxActive=1000jdbc.minIdle=0jdbc.maxWait=6000jdbc.removeAbandoned=truejdbc.removeAbandonedTimeout=1800jdbc.timeBetweenEvictionRunsMillis=60000jdbc.minEvictableIdleTimeMillis=25200000jdbc.validationQuery=select 1jdbc.testWhileIdle=falsejdbc.testOnBorrow=falsejdbc.testOnReturn=false\n\n\n\n\n\nmybatis-config,xml&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;!DOCTYPE configuration PUBLIC &quot;-//mybatis.org//DTD SQL Map Config 3.0//EN&quot;        &quot;http://mybatis.org/dtd/mybatis-3-config.dtd&quot;&gt;&lt;!-- |   plugins在配置文件中的位置必须符合要求，否则会报错，顺序如下: |   properties?, settings?, |   typeAliases?, typeHandlers?, |   objectFactory?,objectWrapperFactory?, |   plugins?, |   environments?, databaseIdProvider?, mappers? |--&gt;&lt;configuration&gt;    &lt;!--     | 全局配置设置     |     | 可配置选项                   默认值,     描述     |     | aggressiveLazyLoading       true,     当设置为‘true’的时候，懒加载的对象可能被任何懒属性全部加载。否则，每个属性都按需加载。     | multipleResultSetsEnabled   true,     允许和不允许单条语句返回多个数据集（取决于驱动需求）     | useColumnLabel              true,     使用列标签代替列名称。不同的驱动器有不同的作法。参考一下驱动器文档，或者用这两个不同的选项进行测试一下。     | useGeneratedKeys            false,    允许JDBC 生成主键。需要驱动器支持。如果设为了true，这个设置将强制使用被生成的主键，有一些驱动器不兼容不过仍然可以执行。     | autoMappingBehavior         PARTIAL,  指定MyBatis 是否并且如何来自动映射数据表字段与对象的属性。PARTIAL将只自动映射简单的，没有嵌套的结果。FULL 将自动映射所有复杂的结果。     | defaultExecutorType         SIMPLE,   配置和设定执行器，SIMPLE 执行器执行其它语句。REUSE 执行器可能重复使用prepared statements 语句，BATCH执行器可以重复执行语句和批量更新。     | defaultStatementTimeout     null,     设置一个时限，以决定让驱动器等待数据库回应的多长时间为超时     | --&gt;    &lt;settings&gt;        &lt;!-- 使用jdbc的getGeneratedKeys获取数据库自增主键值 --&gt;        &lt;setting name=&quot;useGeneratedKeys&quot; value=&quot;true&quot; /&gt;        &lt;!-- 使用列别名替换列名 默认:true --&gt;        &lt;setting name=&quot;useColumnLabel&quot; value=&quot;true&quot; /&gt;        &lt;!-- 开启驼峰命名转换:Table&#123;create_time&#125; -&gt; Entity&#123;createTime&#125; --&gt;        &lt;setting name=&quot;mapUnderscoreToCamelCase&quot; value=&quot;true&quot; /&gt;        &lt;!-- 这个配置使全局的映射器启用或禁用缓存 --&gt;        &lt;setting name=&quot;cacheEnabled&quot; value=&quot;true&quot;/&gt;        &lt;!-- 全局启用或禁用延迟加载。当禁用时，所有关联对象都会即时加载 --&gt;        &lt;setting name=&quot;lazyLoadingEnabled&quot; value=&quot;true&quot;/&gt;        &lt;setting name=&quot;multipleResultSetsEnabled&quot; value=&quot;true&quot;/&gt;        &lt;setting name=&quot;defaultExecutorType&quot; value=&quot;REUSE&quot;/&gt;        &lt;setting name=&quot;defaultStatementTimeout&quot; value=&quot;25000&quot;/&gt;        &lt;!-- 让控制台打印sql语句，注释掉则没有 --&gt;        &lt;setting name=&quot;logImpl&quot; value=&quot;STDOUT_LOGGING&quot;/&gt;        &lt;setting name=&quot;callSettersOnNulls&quot; value=&quot;true&quot;/&gt;    &lt;/settings&gt;&lt;/configuration&gt;\n\n\n\n\n\nspring-context.xml&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;       xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;       xmlns:context=&quot;http://www.springframework.org/schema/context&quot;       xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans   http://www.springframework.org/schema/beans/spring-beans-4.0.xsd   http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd&quot;&gt;    &lt;!-- 采用注释的方式配置bean --&gt;    &lt;context:annotation-config/&gt;    &lt;!-- 配置要扫描的包 --&gt;    &lt;context:component-scan base-package=&quot;com.valten&quot;&gt;        &lt;context:exclude-filter type=&quot;annotation&quot;                                expression=&quot;org.springframework.stereotype.Controller&quot;/&gt;    &lt;/context:component-scan&gt;    &lt;!-- 读入配置属性文件 --&gt;    &lt;context:property-placeholder location=&quot;classpath:jdbc.properties&quot; /&gt;    &lt;!--mybatis配置--&gt;    &lt;import resource=&quot;classpath*:spring/spring-mybatis.xml&quot;/&gt;&lt;/beans&gt;\n\n\n\n\n\nspring-servlet.xml&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;       xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;       xmlns:context=&quot;http://www.springframework.org/schema/context&quot;       xmlns:mvc=&quot;http://www.springframework.org/schema/mvc&quot;       xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot;       xmlns:task=&quot;http://www.springframework.org/schema/task&quot;       xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans       http://www.springframework.org/schema/beans/spring-beans.xsd       http://www.springframework.org/schema/context       http://www.springframework.org/schema/context/spring-context.xsd       http://www.springframework.org/schema/mvc       http://www.springframework.org/schema/mvc/spring-mvc.xsd       http://www.springframework.org/schema/aop       http://www.springframework.org/schema/aop/spring-aop.xsd       http://www.springframework.org/schema/task       http://www.springframework.org/schema/task/spring-task-3.0.xsd&quot;&gt;    &lt;!-- 配置SpringMVC --&gt;    &lt;!-- 开启SpringMVC注解模式 --&gt;    &lt;!-- 简化配置：        (1)自动注册DefaultAnootationHandlerMapping,AnotationMethodHandlerAdapter        (2)提供一些列：数据绑定，数字和日期的format @NumberFormat, @DateTimeFormat, xml,json默认读写支持    --&gt;    &lt;mvc:annotation-driven/&gt;    &lt;!--true：使用cglib库；false：使用JDK动态代理--&gt;    &lt;aop:aspectj-autoproxy proxy-target-class=&quot;true&quot;/&gt;    &lt;!-- 自动扫描，完成bean创建和自动依赖注入--&gt;    &lt;context:component-scan base-package=&quot;com.valten&quot;&gt;        &lt;context:include-filter type=&quot;annotation&quot;                                expression=&quot;org.springframework.stereotype.Controller&quot; /&gt;    &lt;/context:component-scan&gt;    &lt;!--避免IE执行AJAX时，返回JSON出现下载文件 --&gt;    &lt;bean id=&quot;mappingJacksonHttpMessageConverter&quot;          class=&quot;org.springframework.http.converter.json.MappingJackson2HttpMessageConverter&quot;&gt;        &lt;property name=&quot;supportedMediaTypes&quot;&gt;            &lt;list&gt;                &lt;value&gt;text/html;charset=UTF-8&lt;/value&gt;            &lt;/list&gt;        &lt;/property&gt;    &lt;/bean&gt;    &lt;!-- 启动SpringMVC的注解功能，完成请求和注解POJO的映射 --&gt;    &lt;bean class=&quot;org.springframework.web.servlet.mvc.annotation.AnnotationMethodHandlerAdapter&quot;&gt;        &lt;property name=&quot;messageConverters&quot;&gt;            &lt;list&gt;                &lt;bean class=&quot;org.springframework.http.converter.ByteArrayHttpMessageConverter&quot;/&gt;                &lt;ref bean=&quot;mappingJacksonHttpMessageConverter&quot;/&gt;  &lt;!-- JSON转换器 --&gt;            &lt;/list&gt;        &lt;/property&gt;    &lt;/bean&gt;    &lt;!-- 对模型视图名称的解析,即在模型视图名称添加前后缀 --&gt;    &lt;bean id=&quot;viewResolver&quot; class=&quot;org.springframework.web.servlet.view.InternalResourceViewResolver&quot;&gt;        &lt;!-- 查找视图页面的前缀和后缀 --&gt;        &lt;property name=&quot;prefix&quot; value=&quot;/&quot;/&gt;        &lt;property name=&quot;suffix&quot; value=&quot;.html&quot;/&gt;    &lt;/bean&gt;    &lt;!-- 总错误处理--&gt;    &lt;bean id=&quot;exceptionResolver&quot; class=&quot;org.springframework.web.servlet.handler.SimpleMappingExceptionResolver&quot;&gt;        &lt;property name=&quot;defaultStatusCode&quot; value=&quot;500&quot;/&gt;        &lt;property name=&quot;warnLogCategory&quot;                  value=&quot;org.springframework.web.servlet.handler.SimpleMappingExceptionResolver&quot;/&gt;    &lt;/bean&gt;    &lt;!-- 静态资源默认servlet配置    (1)加入对静态资源的处理：js,gif,png    (2)允许使用&quot;/&quot;做整体映射    --&gt;    &lt;mvc:default-servlet-handler/&gt;    &lt;!--定时器配置--&gt;    &lt;task:executor id=&quot;executor&quot; pool-size=&quot;5&quot;/&gt;    &lt;task:scheduler id=&quot;scheduler&quot; pool-size=&quot;10&quot;/&gt;    &lt;task:annotation-driven executor=&quot;executor&quot; scheduler=&quot;scheduler&quot;/&gt;&lt;/beans&gt;\n\n\n\n\n\nspring-mybatis.xml&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;       xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;       xmlns:tx=&quot;http://www.springframework.org/schema/tx&quot;       xsi:schemaLocation=&quot;        http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.0.xsd        http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-4.0.xsd&quot;&gt;    &lt;!-- mysql 数据源配置--&gt;    &lt;bean name=&quot;mysql&quot; class=&quot;com.alibaba.druid.pool.DruidDataSource&quot; init-method=&quot;init&quot; destroy-method=&quot;close&quot;&gt;        &lt;!-- 数据库基本配置 --&gt;        &lt;property name=&quot;driverClassName&quot; value=&quot;$&#123;jdbc.driver&#125;&quot;/&gt;        &lt;property name=&quot;url&quot; value=&quot;$&#123;jdbc.url&#125;&quot;/&gt;        &lt;property name=&quot;username&quot; value=&quot;$&#123;jdbc.username&#125;&quot;/&gt;        &lt;property name=&quot;password&quot; value=&quot;$&#123;jdbc.password&#125;&quot;/&gt;        &lt;!-- 初始化连接数量 --&gt;        &lt;property name=&quot;initialSize&quot; value=&quot;$&#123;jdbc.initialSize&#125;&quot;/&gt;        &lt;!-- 最大并发连接数量 --&gt;        &lt;property name=&quot;maxActive&quot; value=&quot;$&#123;jdbc.maxActive&#125;&quot;/&gt;        &lt;!-- 最小空闲连接数 --&gt;        &lt;property name=&quot;minIdle&quot; value=&quot;$&#123;jdbc.minIdle&#125;&quot;/&gt;        &lt;!-- 配置获取连接等待超时的时间 --&gt;        &lt;property name=&quot;maxWait&quot; value=&quot;$&#123;jdbc.maxWait&#125;&quot;/&gt;        &lt;!-- 超过时间限制是否回收 --&gt;        &lt;property name=&quot;removeAbandoned&quot; value=&quot;$&#123;jdbc.removeAbandoned&#125;&quot;/&gt;        &lt;!-- 超过时间限制多长 --&gt;        &lt;property name=&quot;removeAbandonedTimeout&quot; value=&quot;$&#123;jdbc.removeAbandonedTimeout&#125;&quot;/&gt;        &lt;!-- 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒 --&gt;        &lt;property name=&quot;timeBetweenEvictionRunsMillis&quot; value=&quot;$&#123;jdbc.timeBetweenEvictionRunsMillis&#125;&quot;/&gt;        &lt;!-- 配置一个连接在池中最小生存的时间，单位是毫秒 --&gt;        &lt;property name=&quot;minEvictableIdleTimeMillis&quot; value=&quot;$&#123;jdbc.minEvictableIdleTimeMillis&#125;&quot;/&gt;        &lt;!-- 用来检测连接是否有效的sql，要求是一个查询语句--&gt;        &lt;property name=&quot;validationQuery&quot; value=&quot;$&#123;jdbc.validationQuery&#125;&quot;/&gt;        &lt;!-- 申请连接的时候检测 --&gt;        &lt;property name=&quot;testWhileIdle&quot; value=&quot;$&#123;jdbc.testWhileIdle&#125;&quot;/&gt;        &lt;!-- 申请连接时执行validationQuery检测连接是否有效，配置为true会降低性能 --&gt;        &lt;property name=&quot;testOnBorrow&quot; value=&quot;$&#123;jdbc.testOnBorrow&#125;&quot;/&gt;        &lt;!-- 归还连接时执行validationQuery检测连接是否有效，配置为true会降低性能  --&gt;        &lt;property name=&quot;testOnReturn&quot; value=&quot;$&#123;jdbc.testOnReturn&#125;&quot;/&gt;        &lt;property name=&quot;logAbandoned&quot; value=&quot;true&quot;/&gt;        &lt;!-- 配置监控统计拦截的filters，wall用于防止sql注入，stat用于统计分析 --&gt;        &lt;property name=&quot;filters&quot; value=&quot;stat&quot;/&gt;    &lt;/bean&gt;    &lt;!-- postgresql 数据源配置--&gt;    &lt;bean name=&quot;postgresql&quot; class=&quot;com.alibaba.druid.pool.DruidDataSource&quot; init-method=&quot;init&quot; destroy-method=&quot;close&quot;&gt;        &lt;!-- 数据库基本配置 --&gt;        &lt;property name=&quot;driverClassName&quot; value=&quot;$&#123;jdbc.driver.pg&#125;&quot;/&gt;        &lt;property name=&quot;url&quot; value=&quot;$&#123;jdbc.url.pg&#125;&quot;/&gt;        &lt;property name=&quot;username&quot; value=&quot;$&#123;jdbc.username.pg&#125;&quot;/&gt;        &lt;property name=&quot;password&quot; value=&quot;$&#123;jdbc.password.pg&#125;&quot;/&gt;        &lt;!-- 初始化连接数量 --&gt;        &lt;property name=&quot;initialSize&quot; value=&quot;$&#123;jdbc.initialSize&#125;&quot;/&gt;        &lt;!-- 最大并发连接数量 --&gt;        &lt;property name=&quot;maxActive&quot; value=&quot;$&#123;jdbc.maxActive&#125;&quot;/&gt;        &lt;!-- 最小空闲连接数 --&gt;        &lt;property name=&quot;minIdle&quot; value=&quot;$&#123;jdbc.minIdle&#125;&quot;/&gt;        &lt;!-- 配置获取连接等待超时的时间 --&gt;        &lt;property name=&quot;maxWait&quot; value=&quot;$&#123;jdbc.maxWait&#125;&quot;/&gt;        &lt;!-- 超过时间限制是否回收 --&gt;        &lt;property name=&quot;removeAbandoned&quot; value=&quot;$&#123;jdbc.removeAbandoned&#125;&quot;/&gt;        &lt;!-- 超过时间限制多长 --&gt;        &lt;property name=&quot;removeAbandonedTimeout&quot; value=&quot;$&#123;jdbc.removeAbandonedTimeout&#125;&quot;/&gt;        &lt;!-- 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒 --&gt;        &lt;property name=&quot;timeBetweenEvictionRunsMillis&quot; value=&quot;$&#123;jdbc.timeBetweenEvictionRunsMillis&#125;&quot;/&gt;        &lt;!-- 配置一个连接在池中最小生存的时间，单位是毫秒 --&gt;        &lt;property name=&quot;minEvictableIdleTimeMillis&quot; value=&quot;$&#123;jdbc.minEvictableIdleTimeMillis&#125;&quot;/&gt;        &lt;!-- 用来检测连接是否有效的sql，要求是一个查询语句--&gt;        &lt;property name=&quot;validationQuery&quot; value=&quot;$&#123;jdbc.validationQuery&#125;&quot;/&gt;        &lt;!-- 申请连接的时候检测 --&gt;        &lt;property name=&quot;testWhileIdle&quot; value=&quot;$&#123;jdbc.testWhileIdle&#125;&quot;/&gt;        &lt;!-- 申请连接时执行validationQuery检测连接是否有效，配置为true会降低性能 --&gt;        &lt;property name=&quot;testOnBorrow&quot; value=&quot;$&#123;jdbc.testOnBorrow&#125;&quot;/&gt;        &lt;!-- 归还连接时执行validationQuery检测连接是否有效，配置为true会降低性能  --&gt;        &lt;property name=&quot;testOnReturn&quot; value=&quot;$&#123;jdbc.testOnReturn&#125;&quot;/&gt;        &lt;property name=&quot;logAbandoned&quot; value=&quot;true&quot;/&gt;        &lt;!-- 配置监控统计拦截的filters，wall用于防止sql注入，stat用于统计分析 --&gt;        &lt;property name=&quot;filters&quot; value=&quot;stat&quot;/&gt;    &lt;/bean&gt;    &lt;bean id=&quot;vendorProperties&quot;          class=&quot;org.springframework.beans.factory.config.PropertiesFactoryBean&quot;&gt;        &lt;property name=&quot;properties&quot;&gt;            &lt;props&gt;                &lt;prop key=&quot;PostgreSQL&quot;&gt;postgresql&lt;/prop&gt;                &lt;prop key=&quot;MySQL&quot;&gt;mysql&lt;/prop&gt;            &lt;/props&gt;        &lt;/property&gt;    &lt;/bean&gt;    &lt;bean id=&quot;databaseIdProvider&quot; class=&quot;org.apache.ibatis.mapping.VendorDatabaseIdProvider&quot;&gt;        &lt;property name=&quot;properties&quot; ref=&quot;vendorProperties&quot;/&gt;    &lt;/bean&gt;    &lt;!-- MyBatis SqlSessionFactoryBean 配置 --&gt;    &lt;bean id=&quot;sqlSessionFactory&quot; class=&quot;org.mybatis.spring.SqlSessionFactoryBean&quot;&gt;        &lt;property name=&quot;dataSource&quot; ref=&quot;$&#123;dataSource&#125;&quot;/&gt;        &lt;!-- 自动扫描Mapping.xml文件 --&gt;        &lt;property name=&quot;mapperLocations&quot; value=&quot;classpath:mapper/**/*.xml&quot;/&gt;        &lt;!-- 配置MyBaties全局配置文件:mybatis-config.xml --&gt;        &lt;property name=&quot;configLocation&quot; value=&quot;classpath:mybatis-config.xml&quot;/&gt;        &lt;!-- 扫描model包 xml中parameterType就可以使用类名，不用全路径 --&gt;        &lt;property name=&quot;typeAliasesPackage&quot; value=&quot;com.valten.**.model&quot;/&gt;        &lt;!--多种数据库切换--&gt;        &lt;property name=&quot;databaseIdProvider&quot; ref=&quot;databaseIdProvider&quot; /&gt;    &lt;/bean&gt;    &lt;!-- 加载 mapper.xml对应的接口 配置文件 --&gt;    &lt;bean id=&quot;mapperScannerConfigurer&quot; class=&quot;org.mybatis.spring.mapper.MapperScannerConfigurer&quot;&gt;        &lt;!-- 给出需要扫描mapper接口包 --&gt;        &lt;property name=&quot;basePackage&quot; value=&quot;com.valten.**.dao&quot;/&gt;        &lt;!-- 注入sqlSessionFactory --&gt;        &lt;property name=&quot;sqlSessionFactoryBeanName&quot; value=&quot;sqlSessionFactory&quot;/&gt;    &lt;/bean&gt;    &lt;!-- (事务管理)transaction manager, use JtaTransactionManager for global tx --&gt;    &lt;bean id=&quot;transactionManager&quot; class=&quot;org.springframework.jdbc.datasource.DataSourceTransactionManager&quot;&gt;        &lt;property name=&quot;dataSource&quot; ref=&quot;$&#123;dataSource&#125;&quot;/&gt;    &lt;/bean&gt;    &lt;!--基于注解的方式使用事务配置声明 --&gt;    &lt;tx:annotation-driven transaction-manager=&quot;transactionManager&quot;/&gt;&lt;/beans&gt;\n\n\n\n\n\nlogback.xml 我们在项目中经常会使用到日志，所以这里还有配置日志xml，在resources文件夹里新建logback.xml文件，所给出的日志输出格式也是最基本的控制台输出，大家有兴趣查看logback官方文档。 \n&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;configuration debug=&quot;true&quot;&gt;    &lt;!-- 应用名称 --&gt;    &lt;property name=&quot;APP_NAME&quot; value=&quot;logtest&quot;/&gt;    &lt;!--日志文件的保存路径,首先查找系统属性-Dlog.dir,如果存在就使用其；否则，在当前目录下创建名为logs目录做日志存放的目录 --&gt;    &lt;property name=&quot;LOG_HOME&quot; value=&quot;$&#123;log.dir:-logs&#125;/$&#123;APP_NAME&#125;&quot;/&gt;    &lt;!-- 日志输出格式 --&gt;    &lt;property name=&quot;ENCODER_PATTERN&quot;              value=&quot;%d&#123;yyyy-MM-dd  HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;80&#125; - %msg%n&quot;/&gt;    &lt;contextName&gt;$&#123;APP_NAME&#125;&lt;/contextName&gt;    &lt;!-- 控制台日志：输出全部日志到控制台 --&gt;    &lt;appender name=&quot;STDOUT&quot; class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt;        &lt;encoder class=&quot;ch.qos.logback.classic.encoder.PatternLayoutEncoder&quot;&gt;            &lt;Pattern&gt;$&#123;ENCODER_PATTERN&#125;&lt;/Pattern&gt;        &lt;/encoder&gt;    &lt;/appender&gt;    &lt;!-- 文件日志：输出全部日志到文件 --&gt;    &lt;appender name=&quot;FILE&quot;              class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt;        &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;&gt;            &lt;fileNamePattern&gt;$&#123;LOG_HOME&#125;/output.%d&#123;yyyy-MM-dd&#125;.log&lt;/fileNamePattern&gt;            &lt;maxHistory&gt;7&lt;/maxHistory&gt;        &lt;/rollingPolicy&gt;        &lt;encoder class=&quot;ch.qos.logback.classic.encoder.PatternLayoutEncoder&quot;&gt;            &lt;pattern&gt;$&#123;ENCODER_PATTERN&#125;&lt;/pattern&gt;        &lt;/encoder&gt;    &lt;/appender&gt;    &lt;!-- 错误日志：用于将错误日志输出到独立文件 --&gt;    &lt;appender name=&quot;ERROR_FILE&quot;              class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt;        &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;&gt;            &lt;fileNamePattern&gt;$&#123;LOG_HOME&#125;/error.%d&#123;yyyy-MM-dd&#125;.log&lt;/fileNamePattern&gt;            &lt;maxHistory&gt;7&lt;/maxHistory&gt;        &lt;/rollingPolicy&gt;        &lt;encoder class=&quot;ch.qos.logback.classic.encoder.PatternLayoutEncoder&quot;&gt;            &lt;pattern&gt;$&#123;ENCODER_PATTERN&#125;&lt;/pattern&gt;        &lt;/encoder&gt;        &lt;filter class=&quot;ch.qos.logback.classic.filter.ThresholdFilter&quot;&gt;            &lt;level&gt;WARN&lt;/level&gt;        &lt;/filter&gt;    &lt;/appender&gt;    &lt;!-- 独立输出的同步日志 --&gt;    &lt;appender name=&quot;SYNC_FILE&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt;        &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;&gt;            &lt;fileNamePattern&gt;$&#123;LOG_HOME&#125;/sync.%d&#123;yyyy-MM-dd&#125;.log&lt;/fileNamePattern&gt;            &lt;maxHistory&gt;7&lt;/maxHistory&gt;        &lt;/rollingPolicy&gt;        &lt;encoder class=&quot;ch.qos.logback.classic.encoder.PatternLayoutEncoder&quot;&gt;            &lt;pattern&gt;$&#123;ENCODER_PATTERN&#125;&lt;/pattern&gt;        &lt;/encoder&gt;    &lt;/appender&gt;    &lt;logger name=&quot;log.sync&quot; level=&quot;DEBUG&quot; addtivity=&quot;true&quot;&gt;        &lt;appender-ref ref=&quot;SYNC_FILE&quot;/&gt;    &lt;/logger&gt;    &lt;root&gt;        &lt;level value=&quot;DEBUG&quot;/&gt;        &lt;appender-ref ref=&quot;STDOUT&quot;/&gt;        &lt;appender-ref ref=&quot;FILE&quot;/&gt;        &lt;appender-ref ref=&quot;ERROR_FILE&quot;/&gt;    &lt;/root&gt;&lt;/configuration&gt;\n\n\n\n\n\nweb.xml&lt;web-app xmlns=&quot;http://xmlns.jcp.org/xml/ns/javaee&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;         xsi:schemaLocation=&quot;http://xmlns.jcp.org/xml/ns/javaee                      http://xmlns.jcp.org/xml/ns/javaee/web-app_3_1.xsd&quot;         version=&quot;3.1&quot; metadata-complete=&quot;true&quot;&gt;    &lt;!-- 编码过滤器 --&gt;    &lt;filter&gt;        &lt;filter-name&gt;encodingFilter&lt;/filter-name&gt;        &lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt;        &lt;async-supported&gt;true&lt;/async-supported&gt;        &lt;init-param&gt;            &lt;param-name&gt;encoding&lt;/param-name&gt;            &lt;param-value&gt;UTF-8&lt;/param-value&gt;        &lt;/init-param&gt;    &lt;/filter&gt;    &lt;filter-mapping&gt;        &lt;filter-name&gt;encodingFilter&lt;/filter-name&gt;        &lt;url-pattern&gt;/*&lt;/url-pattern&gt;    &lt;/filter-mapping&gt;    &lt;!-- 如果是用mvn命令生成的xml，需要修改servlet版本为3.1 --&gt;    &lt;!-- 配置DispatcherServlet --&gt;    &lt;servlet&gt;        &lt;servlet-name&gt;springmvc&lt;/servlet-name&gt;        &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt;        &lt;!-- 配置springMVC需要加载的配置文件            spring-dao.xml,spring-service.xml,spring-web.xml            Mybatis - &gt; spring -&gt; springmvc         --&gt;        &lt;init-param&gt;            &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt;            &lt;param-value&gt;classpath:spring/spring-*.xml&lt;/param-value&gt;        &lt;/init-param&gt;    &lt;/servlet&gt;    &lt;servlet-mapping&gt;        &lt;servlet-name&gt;springmvc&lt;/servlet-name&gt;        &lt;!-- 默认匹配所有的请求 --&gt;        &lt;url-pattern&gt;/&lt;/url-pattern&gt;    &lt;/servlet-mapping&gt;    &lt;!-- 访问根路径时的默认访问页面，从上到下匹配 --&gt;    &lt;welcome-file-list&gt;        &lt;welcome-file&gt;/index.jsp&lt;/welcome-file&gt;        &lt;welcome-file&gt;/index.html&lt;/welcome-file&gt;        &lt;welcome-file&gt;/reg.html&lt;/welcome-file&gt;    &lt;/welcome-file-list&gt;&lt;/web-app&gt;\n\n\n\n配置文件结构图如下\n\n附上源码地址：https://gitee.com/valten/valten-databaseIdProvider-master.git\n参考：\nhttps://blog.csdn.net/qq598535550/article/details/51703190\nhttps://www.jianshu.com/p/db57d92bffb7\n","categories":["后端","Maven","Mybatis","Spring","SpringMVC"],"tags":["Maven","Spring","SpringMVC","Mybatis"]},{"title":"Mybatis静态切换数据源","url":"/%E5%90%8E%E7%AB%AF/Mybatis/Mybatis%E9%9D%99%E6%80%81%E5%88%87%E6%8D%A2%E6%95%B0%E6%8D%AE%E6%BA%90/","content":"概述本人最近接到一个任务，将一个系统改成同时兼容Oracle和PostgreSQL(原来是仅支持Oracle)。虽然大部分的sql语句通用，但是还有许多语法存在差异，所以我们可以通过mybatis自身提供的databaseIdProvider解决这个问题，这里记录一下过程。\n\ndatabaseId属性： 如果配置了 databaseIdProvider，MyBatis 会加载所有的不带 databaseId 或匹配当前 databaseId 的语句；如果带或者不带的语句都有，则不带的会被忽略。新增，修改和删除都有这个属性。\n\n配置pom依赖&lt;dependency&gt;    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;    &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!--oracle--&gt;&lt;dependency&gt;    &lt;groupId&gt;com.oracle&lt;/groupId&gt;    &lt;artifactId&gt;ojdbc6&lt;/artifactId&gt;    &lt;version&gt;11.2.0.3&lt;/version&gt;&lt;/dependency&gt;&lt;!--postgresql--&gt;&lt;dependency&gt;    &lt;groupId&gt;org.postgresql&lt;/groupId&gt;    &lt;artifactId&gt;postgresql&lt;/artifactId&gt;    &lt;version&gt;9.4.1212&lt;/version&gt;&lt;/dependency&gt;&lt;!-- 集成mybatis --&gt;&lt;dependency&gt;    &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt;    &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt;    &lt;version&gt;1.3.1&lt;/version&gt;&lt;/dependency&gt;&lt;!--fastjson--&gt;&lt;dependency&gt;    &lt;groupId&gt;com.alibaba&lt;/groupId&gt;    &lt;artifactId&gt;fastjson&lt;/artifactId&gt;    &lt;version&gt;1.2.16&lt;/version&gt;&lt;/dependency&gt;&lt;!-- druid数据库连接池组件 --&gt;&lt;dependency&gt;    &lt;groupId&gt;com.alibaba&lt;/groupId&gt;    &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt;    &lt;version&gt;1.1.10&lt;/version&gt;&lt;/dependency&gt;\n\n\n\n\n配置文件通过配置文件开启mysql支持或者postgresql支持\napplication.yml# 切换对应的环境 postgresql mysqlspring:  profiles:    active: postgresql# mybatis配置mybatis:  mapper-locations: classpath:mapper/**/*.xml  type-aliases-package: com.valten.**.model# showSql 控制台打印sql日志logging:  level:    com:      valten:        dao: debug\n\n\n\n\napplication-mysql.yml# 端口server:  port: 8001# 数据源配置spring:  datasource:    hikari:      jdbc-url: jdbc:mysql://127.0.0.1:3306/test?&amp;useSSL=false      driver-class-name: com.mysql.jdbc.Driver      username: root      password: 123456\n\n\n\n\n\napplication-postgresql.yml# 端口server:  port: 8002# 数据源配置spring:  datasource:    hikari:      jdbc-url: jdbc:postgresql://127.0.0.1:5432/test      driver-class-name: org.postgresql.Driver      username: root      password: 123456\n\n\n注意 SpringBoot1和2的数据原配置写法区别 \n\n数据源配置类@Configurationpublic class DataSourceConfig &#123;    @Value(&quot;$&#123;mybatis.mapper-locations&#125;&quot;)    private String mapperLocations;    @Primary    @Bean(name = &quot;dataSource&quot;)    @ConfigurationProperties(&quot;spring.datasource.hikari&quot;)    public DataSource dataSource() &#123;        return DataSourceBuilder.create().build();    &#125;    @Bean    public JdbcTemplate jdbcTemplate() &#123;        return new JdbcTemplate(dataSource());    &#125;    @Bean    public DatabaseIdProvider databaseIdProvider() &#123;        DatabaseIdProvider databaseIdProvider = new VendorDatabaseIdProvider();        Properties p = new Properties();        p.setProperty(&quot;Oracle&quot;, &quot;oracle&quot;);        p.setProperty(&quot;MySQL&quot;, &quot;mysql&quot;);        p.setProperty(&quot;PostgreSQL&quot;, &quot;postgresql&quot;);        p.setProperty(&quot;DB2&quot;, &quot;db2&quot;);        p.setProperty(&quot;SQL Server&quot;, &quot;sqlserver&quot;);        databaseIdProvider.setProperties(p);        return databaseIdProvider;    &#125;    @Primary    @Bean    public SqlSessionFactoryBean sqlSessionFactoryBean(@Qualifier(&quot;dataSource&quot;) DataSource dataSource) throws Exception &#123;        SqlSessionFactoryBean factoryBean = new SqlSessionFactoryBean();        factoryBean.setDataSource(dataSource);        factoryBean.setDatabaseIdProvider(databaseIdProvider());        factoryBean.setMapperLocations(new PathMatchingResourcePatternResolver().getResources(mapperLocations));        return factoryBean;    &#125;&#125;\n\n\n\n\nUserMapper.xml&lt;select id=&quot;selectByPrimaryKey&quot; parameterType=&quot;java.lang.String&quot; resultMap=&quot;BaseResultMap&quot;&gt;      select      &lt;if test=&quot;_databaseId == &#x27;oracle&#x27;&quot;&gt;        account      &lt;/if&gt;      &lt;if test=&quot;_databaseId == &#x27;postgresql&#x27;&quot;&gt;        dep_code      &lt;/if&gt;      from SYS_USER      where ID = #&#123;id,jdbcType=CHAR&#125;&lt;/select&gt;\n\n\n\n附上源码地址：https://gitee.com/valten/valten-databaseIdProvider-master.git\n","categories":["后端","Mybatis"],"tags":["Mybatis","databaseIdProvider","数据源"]},{"title":"Oracle数据泵使用","url":"/%E6%95%B0%E6%8D%AE%E5%BA%93/Oracle/Oracle%E6%95%B0%E6%8D%AE%E6%B3%B5%E4%BD%BF%E7%94%A8/","content":"Oracle导出数据库推荐使用数据泵的方式，导出工具expdp，导入工具是impdp。 使用数据泵导出数据需要配置Oracle Directory，配置方是如下：\n-- 1. 查看Oracle的directories，管理员登录系统：select * from dba_directories;-- 2. 创建directory：create or replace directory dump_dir as &#x27;/home/oracle/dmps/&#x27;;-- 3. 将读写权限分配给用户：grant read,write on directory dump_dir to users;\n\n使用数据泵导出命令：\n# 导出所有表expdp username/passwd file=xxx.dmp directory=dump_dir log=xxx.log# 导出指定表 tables=tab1,tab2,...expdp username/passwd file=xxx.dmp directory=dump_dir tables=sys_dict,sys_user,sys_role log=xxx.log# 只导出表结构 content=metadata_onlyexpdp username/passwd file=xxx.dmp directory=dump_dir content=metadata_only log=xxx.log# 还可以并行导出expdp username/passwd file=xxx_U%.dmp directory=dump_dir parallel=4 filesize=10G log=xxx.log\n\n使用数据泵导入命令：\nimpdp hv2_yw_r/hv2_yw_r directory=DUMP_DIR dumpfile=ywv2-0109.dmp fromuser=ywv2 touser=hv2_yw_r remap_tablespace=tb_hczzywv2_data:tb_hczzyw_data, tb_hczzywv2_index:tb_hczzyw_index\n\n\nremap_tablespace意思是，将tb_hczzywv2_data、tb_hczzywv2_index表空间转换到tb_hczzyw_data、tb_hczzyw_index\n\n","categories":["数据库","Oracle"],"tags":["Oracle","数据泵"]},{"title":"Oracle相关","url":"/%E6%95%B0%E6%8D%AE%E5%BA%93/Oracle/Oracle%E7%9B%B8%E5%85%B3/","content":"数据迁移空表不能导出\nOracle从11g开始有一个新的特性，当表中从未拥有过数据，那么不分配segment，以节省空间。当使用数据泵导出数据的时候，需要注意，如果表未分配segment，那么无法导出。\n\n-- 单张表alter table sys_log allocate extent;  -- 查询出所有数据量为零的表select table_name from user_tables where num_rows=0;select&#x27;alter table &#x27;||table_name||&#x27; allocate extent;&#x27;from user_tables where num_rows=0;\n\n执行生成的sql\n数据泵的使用数据泵的使用\n表空间相关操作-- 创建数据表空间CREATE TABLESPACE TBS_HCZZZYV2_DATA DATAFILE&#x27;/u01/app/oracle/oradata/hisign/tbs_hczzzy_data_01.dbf&#x27; SIZE 20000m--AUTOEXTEND ON NEXT 100m MAXSIZE UNLIMITEDLOGGING ONLINEEXTENT MANAGEMENT LOCAL AUTOALLOCATEBLOCKSIZE 8KSEGMENT SPACE MANAGEMENT AUTOFLASHBACK ON;-- 扩展表空间ALTER TABLESPACE TBS_HCZZZYV2_DATAADD DATAFILE &#x27;/u01/app/oracle/oradata/hisign/tbs_hczzzy_data_02.dbf&#x27;SIZE 20000m AUTOEXTEND ON NEXT 100m MAXSIZE UNLIMITED;-- 创建索引表空间CREATE TABLESPACE TBS_HCZZYWV2_INDEX DATAFILE &#x27;/u01/app/oracle/oradata/hisign/tbs_hczzyw_index_01.dbf&#x27; SIZE 20000m --AUTOEXTEND ON NEXT 100m MAXSIZE UNLIMITEDLOGGING ONLINEEXTENT MANAGEMENT LOCAL AUTOALLOCATEBLOCKSIZE 8KSEGMENT SPACE MANAGEMENT AUTOFLASHBACK ON;-- 扩展表空间ALTER TABLESPACE TBS_HCZZYWV2_INDEXADD DATAFILE &#x27;/u01/app/oracle/oradata/hisign/tbs_hczzyw_index_02.dbf&#x27;SIZE 20000m --AUTOEXTEND ON NEXT 100m MAXSIZE UNLIMITED;-- 创建临时表空间CREATE TEMPORARY TABLESPACE TBS_HCZZYWV2_TMP TEMPFILE &#x27;/u01/app/oracle/oradata/hisign/tbs_hczzyw_tmp_01.dbf&#x27; SIZE 20000m --AUTOEXTEND ON NEXT 100m MAXSIZE UNLIMITEDTABLESPACE GROUP &#x27;&#x27;EXTENT MANAGEMENT LOCAL UNIFORM SIZE 1M;-- 扩展表空间ALTER TABLESPACE TBS_HCZZYWV2_TMPADD TEMPFILE &#x27;/u01/app/oracle/oradata/hisign/tbs_hczzyw_tmp_02.dbf&#x27;SIZE 20000m --AUTOEXTEND ON NEXT 100m MAXSIZE UNLIMITED;-- 删除指定表空间drop tablespace TBS_MPP_SYSTEM including contents and datafiles;-- 创建用户，指定默认表空间CREATE USER ywv2 IDENTIFIED BY ywv2 DEFAULT TABLESPACE TBS_HCZZYWV2_DATATEMPORARY TABLESPACE TBS_HCZZYWV2_TMPPROFILE DEFAULT ACCOUNT UNLOCK;-- 查询表空间使用情况select a.tablespace_name as name,       total,       free,       total - free as used,       round(free / sum(total) over(PARTITION BY a.tablespace_name), 4) * 100 freeRate,       round((total - free) / sum(total) over(PARTITION BY a.tablespace_name), 4) * 100 usedRate  from (select tablespace_name, sum(bytes) / 1024 / 1024 as total          from dba_data_files         group by tablespace_name) a,       (select tablespace_name, sum(bytes) / 1024 / 1024 as free          from dba_free_space         group by tablespace_name) b where a.tablespace_name = b.tablespace_name order by a.tablespace_name\n\n\n\n用户、权限相关-- 创建用户，指定默认表空间CREATE USER zyv2 IDENTIFIED BY zyv2 DEFAULT TABLESPACE TBS_HCZZZYV2_DATATEMPORARY TABLESPACE TBS_HCZZZYV2_TMPPROFILE DEFAULT ACCOUNT UNLOCK;&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD:source/_posts/Oracle相关.md-- 给用户赋权=======--修改用户密码sqlplus / as sysdbaALTER USER XXX IDENTIFIED BY NEWPWD;--给用户赋权&gt;&gt;&gt;&gt;&gt;&gt;&gt; 851b8daea073711bbc846417be4868bc5c1a2cb2:source/_posts/Oracle相关随笔.mdGRANT CONNECT,RESOURCE,CREATE DATABASE LINK,CREATE VIEW,CREATE SYNONYM TO zyv2;-- 创建用户并授权CREATE USER CSIFMIS IDENTIFIED BY CSIFMIS;GRANT CREATE USER,DROP USER,ALTER USER ,CREATE ANY VIEW ,DROP ANY VIEW,EXP_FULL_DATABASE,IMP_FULL_DATABASE,DBA,CONNECT,RESOURCE,CREATE SESSION TO CSIFMIS;-- oracle授权表权限给用户命令：grant xxx权限 on Table to USERgrant select,insert,update,delete,all on 表名 to 用户名例如：将test表的查询权限赋予tom这个用户grant select on test to tom------------------------------------- 授权grant select on tb_xw_jjxx to h2yw;select * from user_tables;select &#x27;grant select on &#x27;||table_name||&#x27; to h2yw&#x27; from user_tables;-- 收回授权revoke select on tb_xw_jjxx from h2yw;\n\n\n\nExcel批量生成sql=CONCATENATE(&quot;update SIMPLE_CASE c set c.occurrcode = &#x27;&quot;,J2,&quot;&#x27; WHERE C.JJBH=&#x27;&quot;,A2,&quot;&#x27;;&quot;)=CONCATENATE(&quot;insert into operate_type values(sys_guid(),&#x27;&quot;,B2,&quot;&#x27; ,&#x27;&quot;,C2,&quot;&#x27;,&#x27;&quot;,D2,&quot;&#x27; ,&#x27;&quot;,E2,&quot;&#x27;);&quot;)\n\n\n\n# sqlinsert into sys_dict (id, dict_level, dict_key, parent_key, root_key, dict_value1, remark, del)               values (sys_guid(), &#x27;1&#x27;, &#x27;&quot;,A254,&quot;&#x27;, &#x27;ZDLXDM&#x27;, &#x27;ZDLXDM&#x27;, &#x27;&quot;,B254,&quot;&#x27;, &#x27;&quot;,C254,&quot;&#x27;, &#x27;0&#x27;);# excel函数=CONCATENATE(&quot;&quot;)\n\n\n\n\n\n命令行导入导出dmp# 导入dmpimp CSIFMIS/CSIFMIS@192.168.41.73：1521/csifmis \\file=C:\\csifmis.dmp log=C:\\csifmis.log full=y ignore=y# 导出dmpexp CSIFMIS/CSIFMIS@192.168.41.73：1521/csifmis \\file=C:\\csifmis.dmp log=C:\\csifmis.log buffer=65536 full=y# 导出指定表exp CSIFMIS/CSIFMIS@192.168.41.73：1521/csifmis \\file=C:\\csifmis.dmp tables=(table1,table2)# rows=n 只导出表结构不导出数据exp CSIFMIS/CSIFMIS@192.168.41.73：1521/csifmis \\file=C:\\csifmis.dmp log=C:\\csifmis.log rows=n\n\n\n\n递归查询-- 本条记录的id是下一条记录的父id,遍历子节点SELECT T.CID, T.CNAME, T.PARENT_ID, LEVEL FROM Z_ORG TSTART WITH T.CNAME = &#x27;加利福尼亚州&#x27;CONNECT BY PRIOR T.CID = T.PARENT_IDORDER BY LEVEL ASC-- 本条记录的父id是下一条记录的id,遍历根节点SELECT T.CID, T.CNAME, T.PARENT_ID, LEVEL FROM Z_ORG TSTART WITH T.CNAME = &#x27;加利福尼亚州&#x27;CONNECT BY PRIOR T.PARENT_ID = T.CIDORDER BY LEVEL ASC\n\n\nstart with 子句：遍历起始条件，有个小技巧，如果要查父结点，这里可以用子结点的列，反之亦然。\n\n\nconnect by 子句：连接条件。关键词prior，prior跟父节点列parentid放在一起，就是往父结点方向遍历;prior跟子结点列subid放在一起，则往叶子结点方向遍历，\n\n\nparentid、subid 两列谁放在“=”前都无所谓，关键是prior跟谁在一起。\n\n\norder by 子句：排序，不用多说。\n\n锁表-- 1.查看数据库被锁的表select a.object_name,      b.session_id,      c.serial#,      c.program,      c.username,      c.command,      c.machine,      c.lockwait from all_objects a, v$locked_object b, v$session cwhere a.object_id = b.object_id  and c.sid = b.session_id;-- 2.查看表被锁的原因select l.session_id sid,            s.serial#,            l.locked_mode,            l.oracle_username,            s.user#,            l.os_user_name,            s.machine,            s.terminal,            a.sql_text,            a.action from v$sqlarea a, v$session s, v$locked_object lwhere l.session_id = s.sid        and s.prev_sql_addr = a.addressorder by sid, s.serial#;-- 3.解除被锁定的表alter system kill session &#x27;SID,SERIAL#&#x27;;\n\n\n\n用户过期设置查看要过期用户使用的profile文件\nselect username, profile from dba_users；\n\n查看指定的概要文件密码有效期\nselect * from dba_profiles where profile=&#x27;DEFAULT&#x27; and resource_name=&#x27;PASSWORD_LIFE_TIME&#x27;；\n\n将密码有效期修改为无限制\nalter profile default limit password_life_time unlimited；\n\n解锁被锁定的账户\nALTER USER DXZP_HENAN ACCOUNT UNLOCK;\n\n设置尝试输入次数\nalter profile DEFAULT limit FAILED_LOGIN_ATTEMPTS 10;\n\n或者不限制输入次数\nalter profile DEFAULT limit FAILED_LOGIN_ATTEMPTS UNLIMITED;\n\n\n\n字符集编码查看Oracle数据库的编码：\nselect * from nls_database_parameters where parameter =&#x27;NLS_CHARACTERSET&#x27;;\n\n\n\n查看Oracle客户端编码：\nselect * from nls_instance_parameters where parameter=&#x27;NLS_LANGUAGE&#x27;;\n\n\n\n常用查询查询Oracle目录：select * from dba_directories；\n\n\n\n查询数据文件：select * from dba_data_files；\n\n\n\n查询表空间文件：select username, temporary_tablespace from dba_users；\n\n\n\ndba_users查询所有用户信息：select * from dba_users;\n\n\n\n查询所有表空间的大小：select tablespace_name, sum(bytes)/1024/1024 from dba_data_files group by tablespace_name;\n\n\n\n查询空闲表空间的大小：select tablespace_name, sum(bytes)/1024/1024 from dba_free_space group by tablespace_name;\n\n\n\n查询当前用户能访问到的表：select * from user_tables；\n\n\n\n查询Oracle用户表：select * from user_all_tables;\n\n\n\n查询Oracle用户下的视图：select * from user_views;\n\n\n\n查询用户下的函数和存储过程select * from user_source;\n\n\n\n查询当前用户连接：select * from v$Session；\n\n\n\n查询用户下的角色：select * from user_role_privs；\n\n\n\n查询当前用户权限：select * from session_privs;\n\n\n\nORA异常ORA-12514: TNS: no listener\n问题描述：用pl/sql客户端登陆远程Oracle数据库的时候，提示。在服务器登陆是可以的，但是远程客户端无法登陆。\n\n\n解决方案：将服务端的listener.ora中的HOST=127.0.0.1改为HOST=计算机名称，重启listener服务\n\nORA-00119 ORA-00230在一次服务器出问题，重启之后，启动Oracle的时候发现无法启动数据库实例，提示信息：\nORA-00119: invalid specification for system parameter LOCAL_LISTENERORA-00130: invalid listener address (ADDRESS=(PROTOCOL=TCP)(HOST=orcl11g)(PORT=1521))\n\n查找问题发现是由于hosts修改了，名称与hostname及network配置不一致，修改hostname及network，改为与hosts中一致，问题解决。\nORA-12535：TNS operation timed out tips原因：请求操作在超时时间范围内未完成\n使用tnsping &lt;servicename&gt; 来确定：\n\n验证名字解析，网络服务名；\n\n远程的listener是否已经启动；\n\n\ntnsping可以测试与远程数据库连接是否正常\n","categories":["数据库","Oracle"],"tags":["Oracle"]}]